<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="The yt Project" />
  <meta name="author" content="Matthew Turk" />
  <meta name="author" content="Nathan J Goldbaum" />
  <meta name="author" content="John A. ZuHone" />
  <meta name="author" content="Cameron Hummels" />
  <meta name="author" content="Suoqing Ji" />
  <meta name="author" content="Meagan Lang" />
  <meta name="author" content="Madicken Munk" />
  <meta name="author" content="Britton Smith" />
  <meta name="author" content="Kacper Kowalik" />
  <meta name="author" content="Miguel de Val-Borro" />
  <meta name="author" content="Jared W. Coughlin" />
  <meta name="author" content="Corentin Cadiou" />
  <meta name="author" content="Michael Zingale" />
  <meta name="author" content="Leigh Orf" />
  <meta name="author" content="Kelton Halbert" />
  <meta name="author" content="Clément Robert" />
  <meta name="author" content="Christopher Havlin" />
  <meta name="author" content="Stephanie Tonnesen" />
  <meta name="author" content="Add Yourself" />
  <meta name="dcterms.date" content="2021-04-14" />
  <meta name="keywords" content="markdown, publishing, manubot" />
  <title>Introducing yt 3.0: Analysis and Visualization of Volumetric Data</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <!--
  Manubot generated metadata rendered from header-includes-template.html.
  Suggest improvements at https://github.com/manubot/manubot/blob/main/manubot/process/header-includes-template.html
  -->
  <meta name="dc.format" content="text/html" />
  <meta name="dc.title" content="Introducing yt 3.0: Analysis and Visualization of Volumetric Data" />
  <meta name="citation_title" content="Introducing yt 3.0: Analysis and Visualization of Volumetric Data" />
  <meta property="og:title" content="Introducing yt 3.0: Analysis and Visualization of Volumetric Data" />
  <meta property="twitter:title" content="Introducing yt 3.0: Analysis and Visualization of Volumetric Data" />
  <meta name="dc.date" content="2021-04-14" />
  <meta name="citation_publication_date" content="2021-04-14" />
  <meta name="dc.language" content="en-US" />
  <meta name="citation_language" content="en-US" />
  <meta name="dc.relation.ispartof" content="Manubot" />
  <meta name="dc.publisher" content="Manubot" />
  <meta name="citation_journal_title" content="Manubot" />
  <meta name="citation_technical_report_institution" content="Manubot" />
  <meta name="citation_author" content="The yt Project" />
  <meta name="citation_author_institution" content="NumFOCUS" />
  <meta name="citation_author_orcid" content="XXXX-XXXX-XXXX-XXXX" />
  <meta name="twitter:creator" content="@yt_astro" />
  <meta name="citation_author" content="Matthew Turk" />
  <meta name="citation_author_institution" content="School of Information Sciences, University of Illinois at Urbana-Champaign" />
  <meta name="citation_author_institution" content="Department of Astronomy, University of Illinois at Urbana-Champaign" />
  <meta name="citation_author_orcid" content="0000-0002-5294-0198" />
  <meta name="twitter:creator" content="@powersoffour" />
  <meta name="citation_author" content="Nathan J Goldbaum" />
  <meta name="citation_author_institution" content="National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign" />
  <meta name="citation_author_orcid" content="0000-0001-5557-267X" />
  <meta name="twitter:creator" content="@njgoldbaum" />
  <meta name="citation_author" content="John A. ZuHone" />
  <meta name="citation_author_institution" content="Harvard-Smithsonian Center for Astrophysics" />
  <meta name="citation_author_orcid" content="0000-0003-3175-2347" />
  <meta name="twitter:creator" content="@astrojaz" />
  <meta name="citation_author" content="Cameron Hummels" />
  <meta name="citation_author_institution" content="Department of Theoretical Astrophysics, California Institute of Technology" />
  <meta name="citation_author_orcid" content="0000-0002-3817-8133" />
  <meta name="citation_author" content="Suoqing Ji" />
  <meta name="citation_author_institution" content="Physics Department, University of California Santa Barbara" />
  <meta name="citation_author_orcid" content="0000-0001-9658-0588" />
  <meta name="citation_author" content="Meagan Lang" />
  <meta name="citation_author_institution" content="National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign" />
  <meta name="citation_author_orcid" content="0000-0002-2058-2816" />
  <meta name="citation_author" content="Madicken Munk" />
  <meta name="citation_author_institution" content="National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign" />
  <meta name="citation_author_orcid" content="0000-0003-0117-5366" />
  <meta name="citation_author" content="Britton Smith" />
  <meta name="citation_author_institution" content="University of Edinburgh" />
  <meta name="citation_author_orcid" content="0000-0002-6804-630X" />
  <meta name="citation_author" content="Kacper Kowalik" />
  <meta name="citation_author_institution" content="National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign" />
  <meta name="citation_author_orcid" content="0000-0003-1709-3744" />
  <meta name="citation_author" content="Miguel de Val-Borro" />
  <meta name="citation_author_institution" content="Planetary Science Institute" />
  <meta name="citation_author_orcid" content="000-0002-0455-9384" />
  <meta name="citation_author" content="Jared W. Coughlin" />
  <meta name="citation_author_institution" content="National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign" />
  <meta name="citation_author_orcid" content="0000-0002-4373-4114" />
  <meta name="citation_author" content="Corentin Cadiou" />
  <meta name="citation_author_institution" content="Department of Physics and Astrophysics, University College London" />
  <meta name="citation_author_institution" content="Institut d&#39;Astrophysique de Paris" />
  <meta name="citation_author_orcid" content="0000-0003-2285-0332" />
  <meta name="twitter:creator" content="@cphyc" />
  <meta name="citation_author" content="Michael Zingale" />
  <meta name="citation_author_institution" content="Stony Brook University" />
  <meta name="citation_author_orcid" content="0000-0001-8401-030X" />
  <meta name="citation_author" content="Leigh Orf" />
  <meta name="citation_author_institution" content="Space Science and Engineering Center, University of Wisconsin - Madison" />
  <meta name="citation_author_orcid" content="0000-0002-2677-6427" />
  <meta name="citation_author" content="Kelton Halbert" />
  <meta name="citation_author_institution" content="Cooperative Institute for Meteorological Satellite Studies, The University of Wisconsin, Madison" />
  <meta name="citation_author_orcid" content="0000-0001-6898-2731" />
  <meta name="citation_author" content="Clément Robert" />
  <meta name="citation_author_institution" content="Observatoire de la Côte d&#39;Azur, Université de Nice" />
  <meta name="citation_author_orcid" content="0000-0001-8629-7068" />
  <meta name="citation_author" content="Christopher Havlin" />
  <meta name="citation_author_institution" content="School of Information Sciences, University of Illinois at Urbana-Champaign" />
  <meta name="citation_author_orcid" content="0000-0003-0585-8236" />
  <meta name="citation_author" content="Stephanie Tonnesen" />
  <meta name="citation_author_institution" content="Center for Computational Astrophysics, Flatiron Institute" />
  <meta name="citation_author_orcid" content="0000-0002-8710-9206" />
  <meta name="citation_author" content="Add Yourself" />
  <meta name="citation_author_institution" content="Your University" />
  <meta name="citation_author_orcid" content="XXXX-XXXX-XXXX-XXXX" />
  <link rel="canonical" href="https://yt-project.github.io/yt-4.0-paper/" />
  <meta property="og:url" content="https://yt-project.github.io/yt-4.0-paper/" />
  <meta property="twitter:url" content="https://yt-project.github.io/yt-4.0-paper/" />
  <meta name="citation_fulltext_html_url" content="https://yt-project.github.io/yt-4.0-paper/" />
  <meta name="citation_pdf_url" content="https://yt-project.github.io/yt-4.0-paper/manuscript.pdf" />
  <link rel="alternate" type="application/pdf" href="https://yt-project.github.io/yt-4.0-paper/manuscript.pdf" />
  <link rel="alternate" type="text/html" href="https://yt-project.github.io/yt-4.0-paper/v/119d05fb61610c16f0d9bd6345e7f58e5465483c/" />
  <meta name="manubot_html_url_versioned" content="https://yt-project.github.io/yt-4.0-paper/v/119d05fb61610c16f0d9bd6345e7f58e5465483c/" />
  <meta name="manubot_pdf_url_versioned" content="https://yt-project.github.io/yt-4.0-paper/v/119d05fb61610c16f0d9bd6345e7f58e5465483c/manuscript.pdf" />
  <meta property="og:type" content="article" />
  <meta property="twitter:card" content="summary_large_image" />
  <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />
  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" />
  <meta name="theme-color" content="#ad1457" />
  <!-- end Manubot generated metadata -->
</head>
<body>
<!-- d3 plugin -->

<script
    src="https://cdnjs.cloudflare.com/ajax/libs/d3/6.2.0/d3.min.js"
    integrity="sha512-C2RveGuPIWqkaLAluvoxyiaN1XYNe5ss11urhZWZYBUA9Ydgj+hfGKPcxCzTwut1/fmjEZR7Ac35f2aycT8Ogw=="
    crossorigin="anonymous"
>
    // /////////////////////////
    // DESCRIPTION
    // /////////////////////////

    // This third-party plugin 'D3' allows you to create complex, dynamic,
    // interactive, data-driven visualizations in SVG.

    // https://d3js.org/
</script>
<header id="title-block-header">
<h1 class="title">Introducing yt 3.0: Analysis and Visualization of Volumetric Data</h1>
</header>
<p><small><em>
This manuscript
(<a href="https://yt-project.github.io/yt-4.0-paper/v/119d05fb61610c16f0d9bd6345e7f58e5465483c/">permalink</a>)
was automatically generated
from <a href="https://github.com/yt-project/yt-4.0-paper/tree/119d05fb61610c16f0d9bd6345e7f58e5465483c">yt-project/yt-4.0-paper@119d05f</a>
on April 14, 2021.
</em></small></p>
<h2 id="authors">Authors</h2>
<ul>
<li><p><strong>The yt Project</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/XXXX-XXXX-XXXX-XXXX">XXXX-XXXX-XXXX-XXXX</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/yt-project">yt-project</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/yt_astro">yt_astro</a><br>
<small>
NumFOCUS
· Funded by Grant XXXXXXXX
</small></p></li>
<li><p><strong>Matthew Turk</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-5294-0198">0000-0002-5294-0198</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/MatthewTurk">MatthewTurk</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/powersoffour">powersoffour</a><br>
<small>
School of Information Sciences, University of Illinois at Urbana-Champaign; Department of Astronomy, University of Illinois at Urbana-Champaign
· Funded by Grant XXXXXXXX
</small></p></li>
<li><p><strong>Nathan J Goldbaum</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-5557-267X">0000-0001-5557-267X</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/ngoldbaum">ngoldbaum</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/njgoldbaum">njgoldbaum</a><br>
<small>
National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign
· Funded by Grant XXXXXXX
</small></p></li>
<li><p><strong>John A. ZuHone</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-3175-2347">0000-0003-3175-2347</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/jzuhone">jzuhone</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/astrojaz">astrojaz</a><br>
<small>
Harvard-Smithsonian Center for Astrophysics
</small></p></li>
<li><p><strong>Cameron Hummels</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-3817-8133">0000-0002-3817-8133</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/chummels">chummels</a><br>
<small>
Department of Theoretical Astrophysics, California Institute of Technology
· Funded by Grant XXXXXXX
</small></p></li>
<li><p><strong>Suoqing Ji</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-9658-0588">0000-0001-9658-0588</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/jisuoqing">jisuoqing</a><br>
<small>
Physics Department, University of California Santa Barbara
· Funded by Grant XXXXXXX
</small></p></li>
<li><p><strong>Meagan Lang</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-2058-2816">0000-0002-2058-2816</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/langmm">langmm</a><br>
<small>
National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign
· Funded by Grant XXXXXXX
</small></p></li>
<li><p><strong>Madicken Munk</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-0117-5366">0000-0003-0117-5366</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/munkm">munkm</a><br>
<small>
National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign
· Funded by Grant XXXXXXX
</small></p></li>
<li><p><strong>Britton Smith</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-6804-630X">0000-0002-6804-630X</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/brittonsmith">brittonsmith</a><br>
<small>
University of Edinburgh
</small></p></li>
<li><p><strong>Kacper Kowalik</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-1709-3744">0000-0003-1709-3744</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/Xarthisius">Xarthisius</a><br>
<small>
National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign
· Funded by Grant XXXXXXX
</small></p></li>
<li><p><strong>Miguel de Val-Borro</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/000-0002-0455-9384">000-0002-0455-9384</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/migueldvb">migueldvb</a><br>
<small>
Planetary Science Institute
</small></p></li>
<li><p><strong>Jared W. Coughlin</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-4373-4114">0000-0002-4373-4114</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/jcoughlin11">jcoughlin11</a><br>
<small>
National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign
· Funded by Grant XXXXXXX
</small></p></li>
<li><p><strong>Corentin Cadiou</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-2285-0332">0000-0003-2285-0332</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/cphyc">cphyc</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/cphyc">cphyc</a><br>
<small>
Department of Physics and Astrophysics, University College London; Institut d’Astrophysique de Paris
</small></p></li>
<li><p><strong>Michael Zingale</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-8401-030X">0000-0001-8401-030X</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/zingale">zingale</a><br>
<small>
Stony Brook University
</small></p></li>
<li><p><strong>Leigh Orf</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-2677-6427">0000-0002-2677-6427</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/leighorf">leighorf</a><br>
<small>
Space Science and Engineering Center, University of Wisconsin - Madison
</small></p></li>
<li><p><strong>Kelton Halbert</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-6898-2731">0000-0001-6898-2731</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/keltonhalbert">keltonhalbert</a><br>
<small>
Cooperative Institute for Meteorological Satellite Studies, The University of Wisconsin, Madison
</small></p></li>
<li><p><strong>Clément Robert</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-8629-7068">0000-0001-8629-7068</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/neutrinoceros">neutrinoceros</a><br>
<small>
Observatoire de la Côte d’Azur, Université de Nice
</small></p></li>
<li><p><strong>Christopher Havlin</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-0585-8236">0000-0003-0585-8236</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/chrishavlin">chrishavlin</a><br>
<small>
School of Information Sciences, University of Illinois at Urbana-Champaign
· Funded by Grant XXXXXXX
</small></p></li>
<li><p><strong>Stephanie Tonnesen</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-8710-9206">0000-0002-8710-9206</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/stonnes">stonnes</a><br>
<small>
Center for Computational Astrophysics, Flatiron Institute
</small></p></li>
<li><p><strong>Add Yourself</strong><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/XXXX-XXXX-XXXX-XXXX">XXXX-XXXX-XXXX-XXXX</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/yournamehere">yournamehere</a><br>
<small>
Your University
· Funded by Grant XXXXXXXX
</small></p></li>
</ul>
<h2 class="page_break_before" id="abstract">Abstract</h2>
<p>We present the current version of the <code>yt</code> software package.
<code>yt</code> is an open-source, community-developed platform for analysis of volumetric data, with readers for several dozen data formats, indexing systems for gridded data, adaptive mesh refinement data, unstructured mesh data, discrete and particle formats, and octree-based data, as well as the combination of these.
We describe the systems implemented in <code>yt</code> to facilitate a “science-first” approach to data analysis, wherein the emphasis is on the meaning and interpretation of the data as opposed to its discretization or layout.</p>
<h1 id="authorship-policy">Authorship Policy</h1>
<p>We note that the author list for this paper is, by design, extensive.
We have separated the authors into those that contributed to the text (whose names are ordered <strong>somehow TBD</strong>) and those that are members of the <code>yt</code> community.
The authors from each group have been indicated in the respective author affiliations.</p>
<p>This paper was developed collaboratively, using the Manubot <span class="citation" data-cites="cTN2TQIL">[<a href="#ref-cTN2TQIL" role="doc-biblioref">1</a>]</span> system for collaborating on and reviewing contributed text.</p>
<blockquote>
<p>To add yourself to the author list, please follow the instructions in our
<a href="https://github.com/yt-project/yt-4.0-paper/blob/master/README.md#authorship-policy">README</a>.</p>
</blockquote>
<h2 id="sec:introduction">Introduction</h2>
<p>The process of transforming data into understanding constitutes the vast majority of time, energy, and intellectual effort spent during scientific inquiry.
This is true across domains, whether data is the product of a computational simulation, a telescope observation, the synthesis of sensors distributed across the Earth, or a collection of images of the human brain.
Data, by themselves, do not reflect an understanding of the Universe or its underlying physical properties; rather, they are recordings, or measurements, of the state of systems as observed.
Even for computational simulations, such as simulations of star formation in the galaxy, this is true: these simulations encode information about a discretization of a model, rather than the model itself.</p>
<p>Bridging the gap between this discretization and the physical understanding requires accessing data, manipulating and interrogating this data, and then applying to this data a sense of understanding.
Somehow, bits stored on a disk must become, in our minds, a galaxy undergoing a starburst.</p>
<p>This process is both mediated and impeded by computational tools.
When those tools align with our mental model of how data exists, they can allow us to work more efficiently, asking questions of data and building sophisticated scientific inquiry.
However, when they do not, they can cause frustration, delays, and most worryingly, incorrect or misinterpreted results.
When viewing this from the perspective of the landscape of inquiry, the most startling realization is that the questions a computational tool enables individuals to ask shapes the questions they think to ask.</p>
<p>In <span class="citation" data-cites="1GOm01ggN">[<a href="#ref-1GOm01ggN" role="doc-biblioref">2</a>]</span>, the analysis platform <code>yt</code> was described.
At the time, <code>yt</code> was focused on analyzing and visualizing the output of grid-based adaptive mesh refinement hydrodynamic simulations; while these were used to study many different physical phenomena, they all were laid out in roughly the same way, in rectilinear meshes of data.
In this paper, we present the current version of <code>yt</code>, which enables identical scripts to analyze and visualize data stored as rectilinear grids as before, but additionally particle or discrete data, octree-based data, and data stored as unstructured meshes.
This has been the result of a large-scale effort to rewrite the underlying machinery within <code>yt</code> for accessing data, indexing that data, and providing it in efficient ways to higher-level routines, as discussed in Section Something.
While this was underway, <code>yt</code> has also been considerably reinstrumented with <a href="#sec:units">metadata-aware array infrastructure</a>, the <a href="#sec:vr">volume rendering infrastructure</a> has been rewritten to be more user-friendly and capable, and support for <a href="#sec:noncartesian">non-Cartesian geometries</a> has been added.</p>
<p>The single biggest change to <code>yt</code> since that paper was published has not been technical in nature.
In the intervening years, a directed and intense community-building effort has resulted in the contributions from over a hundred different individuals, many of them early-stage researchers, and a <a href="#sec:community">thriving community of both users and developers</a>.
This is the crowning achievement of development, as we have attempted to build <code>yt</code> into a tool that enables inquiry from a technical level as well as fosters a supportive, friendly community of individuals engaged in self-directed inquiry.</p>
<h2 id="sec:community">Community Building</h2>
<p>Choosing a software package for a particular purpose involves evaluating several differentiating factors; these factors include the functionality of a package, the performance of a package, the user-friendliness, and even the ability of an individual to find help, engage with others and feel a sense of participation.
<strong>cite something here</strong> The development, fostering and design of the community around <code>yt</code> is deemed to be both crucial to the success or failure of <code>yt</code>, and in many ways inseparable from its functionality.</p>
<h3 id="composition">Composition</h3>
<p>There are several rough categories of individuals engaged in development and utilization of <code>yt</code>.
As a result of its API-first design, there are few if any individuals who use <code>yt</code> that do not do so through the scripting interface; this means that the vast (if not exclusive) majority of individuals who interact with the functionality in <code>yt</code> are doing so by writing their own scripts, modules, and code, and arguably engaging in a value-added development process of their own.
The majority of individuals using <code>yt</code> at present are in astronomy and astrophysics, typically fields of simulation, although there is an increasing group of individuals from other domains that are participating in development and using <code>yt</code> for their own domain-specific problems.</p>
<p>Making the distinction somewhat more clearly, there are individuals who have built their own scripts and utilized them as well as individuals who have contributed changes or modules to the primary <code>yt</code> codebase.
In addition, there is an emerging set of projects that build on <code>yt</code> as infrastructure to conduct scientific analysis.
These developers are largely driven by their own pragmatic scientific needs, and they constitute the majority of developers (by number) that contribute to the code base.
The majority of these individuals are early- to mid-career researchers, typically graduate students, postdocs, and assistant professors.</p>
<p>In recent years, there has emerged a more coherent contingency of individuals who participate in both pragmatically-focused development of modules and functionality for their own benefit as well as modules or overall improvement that is supplemental or even external to their own research agenda.
These improvements include improvements to the unit handling, to the plotting code, to infrastructure for loading disparate datasets, and so on.
At this time we do not know of any individuals funded to work on <code>yt</code> completely independent of a scientific or scholarly goal.</p>
<p>The composition of the community, particularly with a mixture of timelines for goal-setting and completion, can at times cause frustrations and difficulties.
For instance, the response to “Can this feature be implemented?” often includes an invitation for the questioner to collaborate on developing that feature and submitting it to the codebase.
Developing a schedule of releases is an act of consensus building, both deciding what bugs are critical to fix in the timeline of a release as well as building consensus on what features should be considered blockers for a new release.
The intersection of this with academic deadlines (for instance job application season) requires balance and care.</p>
<h3 id="types-of-tasks">Types of Tasks</h3>
<p>When evaluating the level of engagement, we consider a few different classifications of tasks that are performed by individuals in the community, and evaluate these based on how they flow into greater engagement.</p>
<ul>
<li>Filing issues</li>
<li>Participating in mailing list discussions</li>
<li>Issuing a pull request</li>
<li>Writing documentation</li>
<li>Participating in code review</li>
<li>Drafting an enhancement proposal</li>
<li>Closing bug reports</li>
</ul>
<p>While there are other activities that individuals can participate in, these are the typical activities we see among participants in the community.
The order, flowing from the first to the last, is the typical flow we see for an individual coming to participate in the community.
The first step is typically to file an issue or bug report (occasionally these are requests for new features), followed by participating in development-focused discussion on mailing lists.
The next level of engagement typically involves the development of a new piece of functionality, refinement of existing code, or issuing a fix for a bug or issue.
These take the form of pull requests (described in greater detail <a href="#sec:development">here</a>) that can be reviewed and added to the code base.</p>
<p>The next level of engagement centers around tasks that are not fully-aligned with pragmatic, code-driven scientific inquiry.
The development of documentation is often viewed as orthogonal to the scientific process, and typically requires an iterative writing process.
Participation in code review, providing comments, feedback and suggestions to other authors, is another somewhat orthogonal task; it doesn’t necessarily directly benefit the developer doing the reviewing (although it might) and it does not necessarily result in academic rewards (citations, authorship, etc).
But, it does arise from a pragmatic (ensuring code reliability) or altruistic (the public good of the software) motivation, and is thus a deeper level of engagement.</p>
<p>The final two activities, drafting enhancement proposals and closing bug reports, are the most engaged, and often the most removed from the academic motivation structure.
Developing an <a href="#sec:ytep">enhancement proposal</a> for <code>yt</code> means iterating with other developers on the motivation behind and implementation of a large piece of functionality; it requires both motivation to engage with the community and the patience to build consensus among stakeholders.
Closing bug reports – and the development work associated with identifying, tracking and fixing bugs – requires patience and often repeated engagement with stakeholders.</p>
<h3 id="engagement-metrics">Engagement Metrics</h3>
<p>We include here plots of the level of engagement on mailing list discussions and the citation count of the original method paper.</p>
<h3 id="governance">Governance</h3>
<p>Between the publication of the first paper and this paper, the <code>yt</code> project instituted a form of governance involving a steering committee, a set of “members” of the project, and a defined process for developing improvements and enhancements (the YTEP, or <code>yt</code>-enhancement-proposal process).
YTEPs are discussed in [sec:ytep].
The systems developed account for a number of important procedures, mostly related to decision-making, but do not address pressing community needs such as community standards for conduct, changes in committee composition, sub-project coordination, or the transition of members and developers to “emeritus” status.</p>
<h2 id="sec:development">Development Procedure</h2>
<p><code>yt</code> is developed openly.
During the Spring of 2017, development transitioned from occurring on <a href="https://bitbucket.org/yt_analysis/">Bitbucket</a> to <a href="https://github.com/yt-project/">GitHub</a>, and the source code management system was changed from <a href="https://www.mercurial-scm.org/">Mercurial</a> to <a href="https://git-scm.org/">git</a>.
Development occurs through the “pull request” model, wherein changes to the codebase are made and then requested to be included in the primary repository.
Typically, there are two branches of development, and occasionally three. The first of these is the “stable” branch, which is much slower-paced, and typically only modified during the release periods.
The second is that of “master” (which is the conventional term in git terminology; the corresponding mercurial term would be “default”) which is where current development takes place.
The “master” branch is meant to be for development proceeding that does not drastically disrupt usage patterns.
Occasionally, such as during the development of <code>yt</code> 4.0, a third branch is included in the primary repository.
This development branch is open for large and potentially disruptive changes, but in order to centralize code review and developer attention it takes place there.
For instance, during the development of <code>yt</code> 4.0, the branch <code>yt-4.0</code> was where the global mesh was removed and where the units subsystem was removed and replaced with <code>unyt</code>.</p>
<p>This three-pronged approach generally has suited the community; the process of backporting changes from the “master” branch to the “stable” branch can be time-consuming.
However, balancing the needs of a community requiring stable methods for analyzing data against the ease of development suggests that this is a toll worth paying.</p>
<p>In general, the development of <code>yt</code> is reasonably top-heavy, with the majority of contributions coming from a core group of individuals.
We discuss the implications of this on sustainability in Section [sec:sustainability].</p>
<h3 id="sec:unit_testing">Unit Testing</h3>
<p>The <code>yt</code> codebase includes a number of unit tests; although extensive, their existence post-dates the initial development of the code, and they largely work around the extant APIs at the time of their creation.
Most modern recommendations for developing scientific software emphasize isolated components, well-structured interfaces, and few side effects.
While the development process attempts to emphasize development of isolated APIs and well-constrained unit tests, the balance struck between enabling contribution from junior developers and ensuring the (subjective) standards of the code base does not always fall on the side of rigid design.</p>
<p>Many of the <code>yt</code> APIs that are tested require the existence of a “dataset.”
For instance, the testing of whether objects are correctly selected by a sphere selector (which absolutely <em>could</em> be tested in isolation, were the APIs more separable) is done via creating several different sets of mock datasets of different organizations and shapes and testing whether or not they correctly choose the data points to be included.
To support these operations, the <code>yt</code> testing utilities provide helper functions for creating mock datasets that have different geometric configurations and different collections of “fields” included in their set of primitive values.
Many of the tests are parameterized against the types and organizations of the datasets, the decomposition across mock processors, and the underlying values of the fields.
This ensures that we check against errors and bugs that may depend on behavior that varies as the number of processors or the organization of the data changes.
One example of this would be in the selection of grid values for a single grid of size <span class="math inline">\(128^3\)</span>.
The values selected in this should match the values selected in the same grid decomposed into eight sets of <span class="math inline">\(64^3\)</span> cells, or 64 sets of <span class="math inline">\(32^3\)</span> cells.</p>
<p>The mechanism by which fields are tested is somewhat more extensive, touching on two different needs.
The first need is that of accuracy – fields with known answers, or fields that can be written to be decomposed into primitive, non-optimized operations, are tested for correctness.
The second need is that of dependency calculation; all fields should have their dependencies correctly detected.
For example, if a dataset has primitive fields for “mass” and “velocity,” the calculation of momentum should require both.
If the dataset includes a “momentum” field, then that should be detected as well.
This dependency calculation enables <code>yt</code> to consolidate IO tasks and read as much data as possible in each pass over the full dataset.
In addition to this, fields are tested to ensure that the values generated for them are independent of the organization of the dataset.
Like in the example above, the “momentum” field for a fixed set of values should be identical regardless of the decomposition of the individual cell elements.</p>
<p>Wherever possible, analytical solutions are preferred.
For processes like surface extraction, this might include ensuring that fixed radii extraction produce the correct spherical region.
For streamlines, it might include computing the analytical solution to an integration along a known vector field.
And for projections, it would mean that integrating the path with a weight of “one” should result in a uniform set of values equal to the path length across the domain.</p>
<p>At present, the unit tests in <code>yt</code> take a considerable amount of time to run, and are using the nosetests framework. Modern python practice is to use the newer pytest framework, and efforts are underway to port <code>yt</code> to utilize pytest, and in the process, attempt to reduce overall runtime.</p>
<h3 id="sec:answer_testing">Answer Testing</h3>
<p>The most time-consuming part of the testing process is what we refer to as “answer testing.”
Because so much of <code>yt</code> is focused on computing analysis results, and because some of these analysis results simultaneously depend on specific IO routines, selection routines, and many “frontend-specific” pieces of code, we have built a system for ensuring that for a given set of analysis operations, the result of a set of operations does not change beyond a fixed (typically quite small) tolerance.</p>
<h3 id="code-review">Code Review</h3>
<p>Code review in <code>yt</code> is conducted on a line-by-line basis, as well as on a higher-level regarding pull requests.
The workflow for code review roughly follows this outline:</p>
<ol type="1">
<li>A pull request is issued. When a new pull request is issued, a template is provided that includes a description of the change, requesting information about its compliance with coding standards, etc.</li>
<li>The label “triage” is automatically applied, and removed when a team member applies the correct component label.</li>
<li>Code is reviewed, line-by-line, and suggestions made for either stylistic or algorithmic reasons.</li>
<li>This process is iterated, ensuring that tests, style and accuracy are maintained.</li>
</ol>
<p>One increasing issue with the code review process is ensuring that changes are reviewed with appropriate urgency; larger pull requests tend to languish without review, as the requirements for review necessarily add burden to the maintainers.
“Bugfix” changes formally require only one reviewer, whereas the <code>yt</code> guidelines suggest that larger changes require review from three different team members.</p>
<h3 id="sec:ytep">YTEP Process</h3>
<p>YTEPs, or “<code>yt</code>-enhancement proposal” are vehicles for collaborative decision-making in the project.
Implemented shortly after the first paper on <code>yt</code> was released, the YTEP process experienced a fairly pronounced period of usage during the transition between versions 2.0 and 3.0 of <code>yt</code>, and has since been utilized considerably less.
During periods of rapid development, the needs of the community for stability have to be balanced against desires for change; the YTEP process was implemented to facilitate stakeholder feedback, allow for discussion of design decisions, and to prompt detailed thinking about how and why things should be implemented.
We have modeled this process against that used in the AstroPy community (“APE”).
To create a new proposal for a large change to <code>yt</code>, or to document a decision-making process, individuals prepare a description of the background, motivation for the change, the steps to implementation, and potential alternative approaches.
The proposal is discussed through the pull-request process, and once discussion has concluded it is added to the <a href="https://github.com/yt-project/ytep">repository</a> of YTEPs that is auto-built and <a href="https://ytep.readthedocs.org/">deployed</a>.
The accepted YTEPs have included implementing the chunking system, developing a units system, removing legacy components, and implementing a code of conduct.</p>
<p>Below, we include a table of current YTEPs as of this writing.</p>
<table>
<colgroup>
<col style="width: 6%" />
<col style="width: 35%" />
<col style="width: 12%" />
<col style="width: 44%" />
</colgroup>
<thead>
<tr class="header">
<th>Number</th>
<th>YTEP Title</th>
<th>Created</th>
<th>Authors</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0001</td>
<td>IO Chunking</td>
<td>November 26, 2012</td>
<td>Matthew Turk</td>
</tr>
<tr class="even">
<td>0002</td>
<td>Profile Plotter</td>
<td>December 5, 2012</td>
<td>Matthew Turk</td>
</tr>
<tr class="odd">
<td>0003</td>
<td>Standardizing field names</td>
<td>December 11, 2012</td>
<td>Casey Stark, Nathan Goldbaum, Matt Turk</td>
</tr>
<tr class="even">
<td>0005</td>
<td>Octrees for Fluids and Particles</td>
<td>December 24, 2012</td>
<td>Matthew Turk</td>
</tr>
<tr class="odd">
<td>0006</td>
<td>Periodicity</td>
<td>January 10, 2013</td>
<td>Matthew Turk, Nathan Goldbaum</td>
</tr>
<tr class="even">
<td>0007</td>
<td>Automatic Pull Requests’ validation</td>
<td>February 21, 2013</td>
<td>Kacper Kowalik</td>
</tr>
<tr class="odd">
<td>0008</td>
<td>Release Schedule</td>
<td>February 21, 2013</td>
<td>Matthew Turk</td>
</tr>
<tr class="even">
<td>0009</td>
<td>AMRKDTree for Data Sources</td>
<td>February 28, 2012</td>
<td>Sam Skillman</td>
</tr>
<tr class="odd">
<td>0010</td>
<td>Refactoring for Volume Rendering and Movie Generation</td>
<td>March 3, 2013</td>
<td>Cameron Hummels</td>
</tr>
<tr class="even">
<td>0011</td>
<td>Symbol units in yt</td>
<td>March 7, 2013</td>
<td></td>
</tr>
<tr class="odd">
<td>0012</td>
<td>Halo Redesign</td>
<td>March 7, 2013</td>
<td>Britton Smith, Cameron Hummels, Chris Moody, Mark Richardson, Yu Lu</td>
</tr>
<tr class="even">
<td>0013</td>
<td>Deposited Particle Fields</td>
<td>April 25, 2013</td>
<td>Chris Moody, Matthew Turk, Britton Smith, Doug Rudd, Sam Leitner</td>
</tr>
<tr class="odd">
<td>0014</td>
<td>Field Filters</td>
<td>July 2nd, 2013</td>
<td>Matthew Turk</td>
</tr>
<tr class="even">
<td>0015</td>
<td>Transfer Function Refactor</td>
<td>August 13, 2013</td>
<td>Sam Skillman</td>
</tr>
<tr class="odd">
<td>0016</td>
<td>Volume Traversal</td>
<td>September 10, 2013</td>
<td>Matthew Turk</td>
</tr>
<tr class="even">
<td>0017</td>
<td>Domain-Specific Output Types</td>
<td>September 18, 2013</td>
<td>Matthew Turk and Anthony Scopatz</td>
</tr>
<tr class="odd">
<td>0018</td>
<td>Changing dict-like access to Static Output</td>
<td>September 18, 2013</td>
<td>Matthew Turk</td>
</tr>
<tr class="even">
<td>0019</td>
<td>Reduce items in main import</td>
<td>October 2, 2013</td>
<td>Matthew Turk</td>
</tr>
<tr class="odd">
<td>0020</td>
<td>Removing PlotCollection</td>
<td>March 18, 2014</td>
<td>Matthew Turk</td>
</tr>
<tr class="even">
<td>0021</td>
<td>Particle-Only Plots</td>
<td>August 29, 2014</td>
<td>Andrew Myers</td>
</tr>
<tr class="odd">
<td>0022</td>
<td>Benchmarks</td>
<td>January 19, 2015</td>
<td>Matthew Turk</td>
</tr>
<tr class="even">
<td>0023</td>
<td>yt Community Code of Conduct</td>
<td>July 11, 2015</td>
<td>Britton Smith</td>
</tr>
<tr class="odd">
<td>0024</td>
<td>Alternative Smoothing Kernels</td>
<td>August 1, 2015</td>
<td>Bili Dong</td>
</tr>
<tr class="even">
<td>0025</td>
<td>The ytdata Frontend</td>
<td>August 31, 2015</td>
<td>Britton Smith</td>
</tr>
<tr class="odd">
<td>0026</td>
<td>NumPy-like Operations</td>
<td>September 21, 2015</td>
<td>Matthew Turk</td>
</tr>
<tr class="even">
<td>0027</td>
<td>Non-Spatial Data</td>
<td>December 1, 2015</td>
<td>Matthew Turk, Nathan Goldbaum, John ZuHone</td>
</tr>
<tr class="odd">
<td>0028</td>
<td>Alternative Unit Systems</td>
<td>December 8, 2015</td>
<td>John ZuHone, Nathan Goldbaum, Matthew Turk</td>
</tr>
<tr class="even">
<td>0029</td>
<td>Extension Packages</td>
<td>January 25, 2016</td>
<td>Matthew Turk</td>
</tr>
<tr class="odd">
<td>0031</td>
<td>Unstructured Mesh</td>
<td>December 18, 2014</td>
<td>Matthew Turk</td>
</tr>
<tr class="even">
<td>0032</td>
<td>Removing the global octree mesh for particle data</td>
<td>February 9 2017</td>
<td>Nathan Goldbaum, Meagan Lang, Matthew Turk</td>
</tr>
<tr class="odd">
<td>0033</td>
<td>Dropping Python2 Support</td>
<td>November 28, 2017</td>
<td>Nathan Goldbaum</td>
</tr>
<tr class="even">
<td>0034</td>
<td>yt FITS Image Standard</td>
<td>September 9, 2018</td>
<td>John ZuHone</td>
</tr>
<tr class="odd">
<td>0037</td>
<td>Code Styling</td>
<td>May 18, 2020</td>
<td>Clément Robert</td>
</tr>
<tr class="even">
<td>1000</td>
<td>GitHub Migration</td>
<td>March 25, 2017</td>
<td>Lots of folks</td>
</tr>
<tr class="odd">
<td>1776</td>
<td>Team Infrastructure</td>
<td>August 24, 2014</td>
<td>Britton Smith</td>
</tr>
<tr class="even">
<td>3000</td>
<td>Let’s all start using yt 3.0!</td>
<td>October 30, 2013</td>
<td>Matthew Turk</td>
</tr>
</tbody>
</table>
<h2 id="indexing-and-geometry">Indexing and Geometry</h2>
<p>yt is designed for analysis and visualization of datasets that describe “natural” or “physical” phenomena; more generally, yt is designed to analyze data that can be characterized by a metric of some type.
The most common use case, by far, is that of data that is described in a Cartesian space, by the orthogonal axes of x, y and z.
However, for reasons related to naturalness of coordinate systems and relevance to physical phenomena, datasets are also frequently organized in other coordinate systems, such as cylindrical polar (<span class="math inline">\(r\)</span>, <span class="math inline">\(z\)</span> and <span class="math inline">\(\theta\)</span>), spherical (<span class="math inline">\(r\)</span>, <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span>) and variants such as geographic (latitude, longitude and altitude).</p>
<p>Importantly, however, yt distinguishes between the <em>coordinate</em> space a dataset describes and the natural or <em>index</em> space by which its organization is described.
This distinction is the most relevant among datasets and data formats where the organization is <em>implicit</em>, rather than <em>explicit</em>; for instance, in a grid patch dataset, data variable locations are often only specified implicitly.
For a grid volume that covers a given region, the relationship between the “index” value of a cell (for instance, <span class="math inline">\(i,j,k\)</span>) and its position in space (for instance, <span class="math inline">\(x, y, z\)</span> or <span class="math inline">\(r, \theta, \phi\)</span>) requires transformation between a logically-Cartesian decomposition of the space and the potentially-non Cartesian space that it represents.</p>
<p>In Figure <a href="#fig:coordinate_space">1</a> we demonstrate one possible mapping.
We note that the specific data layout is not optimized for IO throughput, and is unlikely to be exactly replicated in real world formats.
In this case, the data points may be laid out sequentially on disk (or in memory) and a mapping function translates these into position and extent in the coordinate system, here cylindrical coordinates.
For instance, there may be a cell that spans <span class="math inline">\(r\)</span> from <span id="coordinate_info_r" style="font-family: monospace;">0.375 to 0.5</span> and
<span class="math inline">\(\theta\)</span> from <span id="coordinate_info_theta" style="font-family: monospace;">45.0 to 52.5</span>, which is defined by the array values defined in cell <span id="coordinate_info_ij" style="font-family: monospace;">1, 4</span>.</p>
<div id="fig:coordinate_space" class="fignos">
<figure>
<img src="images/indexing/coordinate_space.svg" alt="" /><figcaption><span>Figure 1:</span> Index space to coordinate space mapping. On the left is an example of how data points may be laid out on disk and on the right is how these points might be translated into a (cylindrical) coordinate space.</figcaption>
</figure>
</div>
<script>
document.addEventListener("SVGLoaded", function(event) { 
  d3.selectAll("svg#index_coord_figure .cell").classed("active");
  d3.selectAll("svg#index_coord_figure .cell")
    .on("mouseover", (event) => {
      dataset = event.target.dataset;
      d3.select("#coordinate_info_r").text(dataset["r-0"] + " to " + dataset["r-1"]);
      d3.select("#coordinate_info_theta").text(dataset["theta-0"] + " to " + dataset["theta-1"]);
      d3.select("#coordinate_info_ij").text(dataset["cellI"] + ", " + dataset["cellJ"]);
      d3.selectAll("svg#index_coord_figure .cell").classed("highlighted", (d, i, n) => (n[i].dataset["cell"] == dataset["cell"]));
    });
});
</script>
<h3 id="abstraction-of-coordinate-systems">Abstraction of Coordinate Systems</h3>
<p>yt provides a system for defining relationships between index-space and coordinate-space.
During instantiation of a <code>Dataset</code> object, a helper object (<code>coordinates</code>, a subclass of <code>CoordinateHandler</code>) is created.
This helper object tracks the correspondence between numerical axes and spatial axes (for instance, even in some Cartesian datasets, axis 0 corresponds to <span class="math inline">\(z\)</span> rather than <span class="math inline">\(x\)</span>), the names of axes, and the transformation and pixelization methods for visualization.
In addition to these helper functions, the coordinate handler provides definitions for derived fields that describe local cell width (and orthogonal path length), positions in coordinate space as computed by index space coordinates, volumes, and surface areas.
These coordinate handlers also provide transformations between different spaces, albeit using the somewhat undesirable method of conversion to reference cartesian frames and subsequent conversion to local coordinate frames.</p>
<p>At present, coordinate spaces are defined in the spaces enumerate in Table <a href="#tbl:coord-systems">1</a>.
While these are representative of the most common spatial representations, additional representations (such as those that include a non-trivial mapping between coordinates and index values) are possible to implement.</p>
<div id="tbl:coord-systems" class="tablenos">
<table>
<caption><span>Table 1:</span> Extant coordinate systems; in all cases, value ranges should be taken to describe extent rather than specific boundary points. </caption>
<colgroup>
<col style="width: 35%" />
<col style="width: 64%" />
</colgroup>
<thead>
<tr class="header">
<th>Coordinate system</th>
<th>Axes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Cartesian coordinates</td>
<td><span class="math inline">\(x, y, z\)</span></td>
</tr>
<tr class="even">
<td>Cylindrical polar coordinates</td>
<td>$r, z, $</td>
</tr>
<tr class="odd">
<td>Spherical coordinates</td>
<td><span class="math inline">\(r, \theta, \phi\)</span></td>
</tr>
<tr class="even">
<td>Geographic coordinates</td>
<td>latitude <span class="math inline">\(\in [0, 180]\)</span>, longitude <span class="math inline">\(\in [0, 360]\)</span>, altitude</td>
</tr>
<tr class="odd">
<td>Internal geographic coordinates</td>
<td>latitude, longitude, depth</td>
</tr>
<tr class="even">
<td>Spectral cube</td>
<td>Image <span class="math inline">\(x\)</span>, Image <span class="math inline">\(y\)</span> and <span class="math inline">\(\nu\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>Future developments may involve code generation for arbitrary coordinate systems, using SymPy or other libraries.
Independent of the visualization methods (which can often be reused), the development of coordinate systems is largely rote, applying straightforward mathematics to construct derived field definitions.
As such, using mechanisms in SymPy for construction of relationships between coordinate systems may be a feasible method of developing code-generation for coordinate system handlers in yt.</p>
<h2 id="sec:data_objects">Data Objects</h2>
<p>The basic principles by which <code>yt</code> operates are built on the notion of selecting data (through coarse and subsequent fine-grained indexing of data sources such as files), accessing that data in a memory-efficient fashion, and then processing that data into either a resultant set of quantitative data or a visualization.</p>
<p>Selections in <code>yt</code> are usually spatial in nature, although several non-spatial mechanisms focused on queries can be utilized as well.
These objects which conduct selection are selectors, and are designed to provide as small of an API as possible, to enable ease of development and deployment of new selectors.</p>
<p>Selectors require defining several functions, with the option of defining additional functions for optimization, that return true or false whether a given point is or is not included in the selected region.
These functions include selection of a rectilinear grid (or any point within that grid), selection of a point with zero extent and selection of a point with a non-zero spherical radius.</p>
<p>The base selector object utilizes these routines during a selection operation to maximize the amount of code reused between particle, patch, and octree selection of data.
These three types of data are selected through specific routines designed to minimize the number of times that the selection function must be called, as they can be quite expensive.</p>
<p>Selecting data from a grid is a two-step process.
The first step is identifying which grids intersect a given data selector; this is done through a sequence of bounding box intersection checks.
Within a given grid, the cells which are intersected are identified.
This results in the selection routine being called once for each grid object in the simulation and once for each cell located within an intersecting grid.
This can be conducted hierarchically, but due to implementation details around how the grid index is stored this is not yet cost effective.</p>
<p>Selecting data from an octree-organized dataset utilizes a recursive scheme that selects individual oct nodes, then for each cell within that oct, determining which cells must be selected or child nodes recursed into.
This system is designed to allow for having leaf nodes of varying cells-per-side, for instance 1, 2, 4, 8, etc.
However, the number of nodes is fixed at 8, with subdivision always occurring at the midplane.</p>
<p>The final mechanism by which data is selected is for discrete data points, typically particles in astrophysical simulations.
At present, this is done by first identifying which data files intersect with a given selector, then selecting individual points.
There is no hierarchical data selection conducted in this system, as we do not yet allow for re-ordering of data on disk or in-memory which would facilitate hierarchical selection through the use of operations such as morton indices.</p>
<h3 id="selection-routines">Selection Routines</h3>
<p>Given these set of hierarchical selection methods, all of which are designed to provide opportunities for early-termination, each <em>geometric</em> selector object is required to implement a small set of methods to expose its functionality to the hierarchical selection process.
Duplicative functions often result from attempts to avoid expensive calculations that take into account boundary conditions such as periodicity and reflectivity unless necessary.
Additionally, by providing some routines as options, we can in some instances specialize them for the specific geometric operation.</p>
<ul>
<li><code>select_cell(cell_center, cell_width)</code>: this function, which is somewhat degenerate with <code>select_bbox</code>, returns whether a given “cell,” defined by its center and its width along each dimension, is included within the selection. In situations where the cells are spaced logarithmically, rather than linearly, this may produce slightly reduced accuracy for near-misses and glancing-selections.</li>
<li><code>select_point(position)</code>: this function returns whether or not a point of zero-extent is included within the selection. This has some degeneracy with <code>select_sphere</code>.</li>
<li><code>select_sphere(position, radius)</code>: This is equivalent to the <code>select_point</code> function, except that any point within the specified radius is included within the selector object.</li>
<li><code>select_bbox(lower_left, upper_right)</code>: Determine overlap with an axis-aligned bounding box. Particularly for hierarchical selection methods, determining whether or not a bounding box overlaps with a geometric selector can lead to early-termination of some selection operations.<br />
</li>
<li><code>select_bbox_edge(lower_left, upper_right)</code>: This is a special-case of the bounding box routine that provides information as to whether or not the <em>entire</em> bounding box is included or just a <em>partial</em> portion of the bounding box.</li>
</ul>
<p>We demonstrate a handful of selection operations on a low-resolution dataset below.
In Figure <a href="#fig:reg2">2</a> we illustrate the selection of a rectangular prism (i.e., a <code>region</code>, like in Section [sec:dobj-region].
In Figure <a href="#fig:sp2">3</a>, we illustrate the selection of a sphere (i.e., a <code>sphere</code>, like in Section [sec:dobj-sphere].
And, to demonstrate the ability of yt to construct boolean selectors from these objects (i.e., Section [sec:dobj-bool] we show what the logical <code>NOT</code> of these two objects would produce in <a href="#fig:reg2_not_sp2">4</a>.</p>
<div id="fig:reg2" class="fignos">
<figure>
<img src="images/selectors/reg2.svg" alt="" /><figcaption><span>Figure 2:</span> A selection of data in a low-resolution simulation from a rectangular prism.</figcaption>
</figure>
</div>
<div id="fig:sp2" class="fignos">
<figure>
<img src="images/selectors/sp2.svg" alt="" /><figcaption><span>Figure 3:</span> A selection of data in a low-resolution simulation from a sphere.</figcaption>
</figure>
</div>
<div id="fig:reg2_not_sp2" class="fignos">
<figure>
<img src="images/selectors/reg2_not_sp2.svg" alt="" /><figcaption><span>Figure 4:</span> The logical <code>NOT</code> of the regions from Figures <a href="#fig:reg2">2</a> and <a href="#fig:sp2">3</a>.</figcaption>
</figure>
</div>
<h3 id="fast-and-slow-paths">Fast and Slow Paths</h3>
<p>Given an ensemble of objects, the simplest way of testing for inclusion in a selector is to call the operation <code>select_cell</code> on each individual object.
Where the objects are organized in a regular fashion, for instance a “grid” that contains many “cells,” we can apply both “first pass” and “second pass” fast-path operations.
The “first pass” checks whether or not the given ensemble of objects is included, and only iterates inward if there is partial or total inclusion.
The “second pass” fast pass is specialized to both the organization of the objects <em>and</em> the selector itself, and is used to determine whether either only a specific (and well-defined) subset of the objects is included or the entirety of them.</p>
<p>For instance, we can examine the specific case of selecting grid cells within a rectangular prism.
When we select a “grid” of cells within a rectangular prism, we can have either total inclusion, partial inclusion, or full exclusion.
In the case of full inclusion, where the entire grid is included within the selector, we simply sidestep the specific inclusion checks completely and return a full mask of cells to utilize.
In the case of partial inclusion, we can often determine the “start” and “end” indices of inclusion in the rectangular prism by examining the intersection volume.
This allows us to avoid many costly individual <code>select_cell</code> calls.</p>
<p>With discrete point selection (and for our purposes, often unstructured mesh falls into this category) we often do not have the same organizing principle on which we can rely.
However, utilizing hierarchical bitmap indexing we can often organize subsets of particles into collections of cells which may or may not be contiguous.
In this situation, we can check for full inclusion within data objects, although we are not able to identify start and stop indices as the data are not assumed to be organized spatially independent of how we have indexed them.</p>
<p>At present, the objects listed in <a href="#tbl:selection-objects">2</a> are provided as selectors in yt.
We do make a distinction between “selection” operations and “reduction” or “construction” operations (such as projections and smoothing/resampling), but have included both here for consistency.
Additionally, some have been marked as not “user-facing,” in the sense that they are not expected to be constructed directly by users, but instead are utilized internally for indexing purposes.
In columns to the right, we provide information as to whether there is an available “fast” path for grid objects.</p>
<div id="tbl:selection-objects" class="tablenos">
<table>
<caption><span>Table 2:</span> Selection objects and their types. </caption>
<thead>
<tr class="header">
<th>Object Name</th>
<th>Object Type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Arbitrary grid</td>
<td>Resampling</td>
</tr>
<tr class="even">
<td>Boolean object</td>
<td>Selection (Base Class)</td>
</tr>
<tr class="odd">
<td>Covering grid</td>
<td>Resampling</td>
</tr>
<tr class="even">
<td>Cut region</td>
<td>Selection</td>
</tr>
<tr class="odd">
<td>Cutting plane</td>
<td>Selection</td>
</tr>
<tr class="even">
<td>Data collection</td>
<td>Selection</td>
</tr>
<tr class="odd">
<td>Disk</td>
<td>Selection</td>
</tr>
<tr class="even">
<td>Ellipsoid</td>
<td>Selection</td>
</tr>
<tr class="odd">
<td>Intersection</td>
<td>Selection (Bool)</td>
</tr>
<tr class="even">
<td>Octree</td>
<td>Internal index</td>
</tr>
<tr class="odd">
<td>Orthogonal ray</td>
<td>Selection</td>
</tr>
<tr class="even">
<td>Particle projection</td>
<td>Reduction</td>
</tr>
<tr class="odd">
<td>Point</td>
<td>Selection</td>
</tr>
<tr class="even">
<td>Quadtree projection</td>
<td>Reduction</td>
</tr>
<tr class="odd">
<td>Ray</td>
<td>Selection</td>
</tr>
<tr class="even">
<td>Rectangular Prism</td>
<td>Selection</td>
</tr>
<tr class="odd">
<td>Slice</td>
<td>Selection</td>
</tr>
<tr class="even">
<td>Smoothed covering grid</td>
<td>Resampling</td>
</tr>
<tr class="odd">
<td>Sphere</td>
<td>Selection</td>
</tr>
<tr class="even">
<td>Streamline</td>
<td>Selection</td>
</tr>
<tr class="odd">
<td>Surface</td>
<td>Selection</td>
</tr>
<tr class="even">
<td>Union</td>
<td>Selection (Bool)</td>
</tr>
</tbody>
</table>
</div>
<h4 id="sec:dobj-arbitrary_grid">Arbitrary grid</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Left edge</li>
<li>Right edge</li>
<li>Active Dimensions</li>
</ul>
<p>A 3D region with arbitrary bounds and dimensions. In contrast to the
Covering Grid, this object accepts a left edge, a right edge, and
dimensions. This allows it to be used for creating 3D particle
deposition fields that are independent of the underlying mesh, whether
that is yt-generated or from the simulation data. For example,
arbitrary boxes around particles can be drawn and particle deposition
fields can be created. This object will refuse to generate any fluid
fields.</p>
<h4 id="sec:dobj-bool">Bool</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Operation</li>
<li>Data object 1</li>
<li>Data object 2</li>
</ul>
<p>This is a boolean operation, accepting AND, OR, XOR, and NOT for
combining multiple data objects. This object is not designed to be
created directly; it is designed to be created implicitly by using one
of the bitwise operations (&amp;, |, ^, ~) on one or two other data
objects. These correspond to the appropriate boolean operations, and
the resultant object can be nested.</p>
<h4 id="sec:dobj-covering_grid">Covering grid</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Level</li>
<li>Left edge</li>
<li>Active Dimensions</li>
</ul>
<p>A 3D region with all data extracted to a single, specified resolution.
Left edge should align with a cell boundary, but defaults to the
closest cell boundary.</p>
<h4 id="sec:dobj-cut_region">Cut region</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Base object</li>
<li>Conditionals</li>
</ul>
<p>This is a data object designed to allow individuals to apply logical
operations to fields and filter as a result of those cuts.</p>
<h4 id="sec:dobj-cutting">Cutting</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Normal</li>
<li>Center</li>
</ul>
<p>This is a data object corresponding to an oblique slice through the
simulation domain. This object is typically accessed through the
<code>cutting</code> object that hangs off of index objects. A cutting plane is
an oblique plane through the data, defined by a normal vector and a
coordinate. It attempts to guess an ‘north’ vector, which can be
overridden, and then it pixelizes the appropriate data onto the plane
without interpolation.</p>
<h4 id="sec:dobj-data_collection">Data collection</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Object List</li>
</ul>
<p>By selecting an arbitrary <em>object_list</em>, we can act on those grids.
Child cells are not returned.</p>
<h4 id="sec:dobj-disk">Disk</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Center</li>
<li>Normal vector</li>
<li>Radius</li>
<li>Height</li>
</ul>
<p>By providing a <em>center</em>, a <em>normal</em>, a <em>radius</em> and a <em>height</em> we can
define a cylinder of any proportion. Only cells whose centers are
within the cylinder will be selected.</p>
<h4 id="sec:dobj-ellipsoid">Ellipsoid</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Center</li>
<li>a</li>
<li>b</li>
<li>c</li>
<li>e0</li>
<li>tilt</li>
</ul>
<p>By providing a <em>center</em>,<em>A</em>,<em>B</em>,<em>C</em>,<em>e0</em>,<em>tilt</em> we can define a
ellipsoid of any proportion. Only cells whose centers are within the
ellipsoid will be selected.</p>
<h4 id="sec:dobj-intersection">Intersection</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Data objects</li>
</ul>
<p>This is a more efficient method of selecting the intersection of
multiple data selection objects. Creating one of these objects
returns the intersection of all of the sub-objects; it is designed to
be a faster method than chaining &amp; (“and”) operations to create a
single, large intersection.</p>
<h4 id="sec:dobj-minimal_sphere">Minimal sphere</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Center</li>
<li>Radius</li>
</ul>
<p>Build the smallest sphere that encompasses a set of points.</p>
<h4 id="sec:dobj-octree">Octree</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Left edge</li>
<li>Right edge</li>
<li>Particle count refinement criteria</li>
</ul>
<p>A 3D region with all the data filled into an octree. This container
will mean deposit particle fields onto octs using a kernel and SPH
smoothing.</p>
<h4 id="sec:dobj-ortho_ray">Ortho ray</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Axis</li>
<li>Coords</li>
</ul>
<p>This is an orthogonal ray cast through the entire domain, at a
specific coordinate. This object is typically accessed through the
<code>ortho_ray</code> object that hangs off of index objects. The resulting
arrays have their dimensionality reduced to one, and an ordered list
of points at an (x,y) tuple along <code>axis</code> are available.</p>
<h4 id="sec:dobj-particle_proj">Particle proj</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Axis</li>
<li>Field</li>
<li>Weight field</li>
</ul>
<p>A projection operation optimized for SPH particle data.</p>
<h4 id="sec:dobj-point">Point</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>P</li>
</ul>
<p>A 0-dimensional object defined by a single point</p>
<h4 id="sec:dobj-quad_proj">Quad proj</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Axis</li>
<li>Field</li>
<li>Weight field</li>
</ul>
<p>This is a data object corresponding to a line integral through the
simulation domain. This object is typically accessed through the
<code>proj</code> object that hangs off of index objects. YTQuadTreeProj is a
projection of a <code>field</code> along an <code>axis</code>. The field can have an
associated <code>weight_field</code>, in which case the values are multiplied by
a weight before being summed, and then divided by the sum of that
weight; the two fundamental modes of operating are direct line
integral (no weighting) and average along a line of sight (weighting.)
What makes <code>proj</code> different from the standard projection mechanism is
that it utilizes a quadtree data structure, rather than the old
mechanism for projections. It will not run in parallel, but serial
runs should be substantially faster. Note also that lines of sight
are integrated at every projected finest-level cell.</p>
<h4 id="sec:dobj-ray">Ray</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Start point</li>
<li>End point</li>
</ul>
<p>This is an arbitrarily-aligned ray cast through the entire domain, at
a specific coordinate. This object is typically accessed through the
<code>ray</code> object that hangs off of index objects. The resulting arrays
have their dimensionality reduced to one, and an ordered list of
points at an (x,y) tuple along <code>axis</code> are available, as is the <code>t</code>
field, which corresponds to a unitless measurement along the ray from
start to end.</p>
<h4 id="sec:dobj-region">Region</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Center</li>
<li>Left edge</li>
<li>Right edge</li>
</ul>
<p>A 3D region of data with an arbitrary center. Takes an array of three
<em>left_edge</em> coordinates, three <em>right_edge</em> coordinates, and a
<em>center</em> that can be anywhere in the domain. If the selected region
extends past the edges of the domain, no data will be found there,
though the object’s <code>left_edge</code> or <code>right_edge</code> are not modified.</p>
<h4 id="sec:dobj-slice">Slice</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Axis</li>
<li>Coord</li>
</ul>
<p>This is a data object corresponding to a slice through the simulation
domain. This object is typically accessed through the <code>slice</code> object
that hangs off of index objects. Slice is an orthogonal slice through
the data, taking all the points at the finest resolution available and
then indexing them. It is more appropriately thought of as a slice
‘operator’ than an object, however, as its field and coordinate can
both change.</p>
<h4 id="sec:dobj-smoothed_covering_grid">Smoothed covering grid</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Level</li>
<li>Left edge</li>
<li>Active Dimensions</li>
</ul>
<p>A 3D region with all data extracted and interpolated to a single,
specified resolution. (Identical to covering_grid, except that it
interpolates.) Smoothed covering grids start at level 0,
interpolating to fill the region to level 1, replacing any cells
actually covered by level 1 data, and then recursively repeating this
process until it reaches the specified <code>level</code>.</p>
<h4 id="sec:dobj-sphere">Sphere</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Center</li>
<li>Radius</li>
</ul>
<p>A sphere of points defined by a <em>center</em> and a <em>radius</em>.</p>
<h4 id="sec:dobj-streamline">Streamline</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Positions</li>
</ul>
<p>This is a streamline, which is a set of points defined as being
parallel to some vector field. This object is typically accessed
through the Streamlines.path function. The resulting arrays have
their dimensionality reduced to one, and an ordered list of points at
an (x,y) tuple along <code>axis</code> are available, as is the <code>t</code> field, which
corresponds to a unitless measurement along the ray from start to end.</p>
<h4 id="sec:dobj-surface">Surface</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Data source</li>
<li>Surface field</li>
<li>Field value</li>
</ul>
<p>This surface object identifies isocontours on a cell-by-cell basis,
with no consideration of global connectedness, and returns the
vertices of the Triangles in that isocontour. This object simply
returns the vertices of all the triangles calculated by the <code>marching cubes &lt;https://en.wikipedia.org/wiki/Marching_cubes&gt;</code>_ algorithm; for
more complex operations, such as identifying connected sets of cells
above a given threshold, see the extract_connected_sets function.
This is more useful for calculating, for instance, total isocontour
area, or visualizing in an external program (such as <code>MeshLab &lt;http://www.meshlab.net&gt;</code>_.) The object has the properties .vertices
and will sample values if a field is requested. The values are
interpolated to the center of a given face.</p>
<h4 id="sec:dobj-union">Union</h4>
<p><em>Arguments</em>:</p>
<ul>
<li>Data objects</li>
</ul>
<p>This is a more efficient method of selecting the union of multiple
data selection objects. Creating one of these objects returns the
union of all of the sub-objects; it is designed to be a faster method
than chaining | (or) operations to create a single, large union.</p>
<h2 id="processing-and-analysis-of-data">Processing and Analysis of Data</h2>
<h3 id="array-like-operations">Array-like Operations</h3>
<p>In <code>yt</code>, a newly-constructed data selector contains no data – this enables data selectors for large regions, in extremely large datasets, to be lightweight and cheap to construct.
By ensuring that these objects don’t immediately consume resources, they can be manipulated and operated on in a high-level fashion, without taxing the computational power.
While these data objects <em>can</em> return the full set of data they include, <code>yt</code> also provides array-like operations that do not require immediate access to the full set of numerical values, and which align with the mental-model for data processing that <code>yt</code> exposes.
As an example, consider the following two operations:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a>dd <span class="op">=</span> ds.all_data()</span>
<span id="cb1-2"><a href="#cb1-2"></a>dd[<span class="st">&quot;gas&quot;</span>, <span class="st">&quot;density&quot;</span>].<span class="bu">max</span>()</span></code></pre></div>
<p>and</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>dd <span class="op">=</span> ds.all_data()</span>
<span id="cb2-2"><a href="#cb2-2"></a>dd.<span class="bu">max</span>((<span class="st">&quot;gas&quot;</span>, <span class="st">&quot;density&quot;</span>))</span></code></pre></div>
<p>Both are available in <code>yt</code>.
As a side-effect of Python’s object model, the first will access the <code>("gas", "density")</code> item in the object <code>dd</code>, itself a concatenated numpy array, and then execute the <code>max</code> method on it.
The second will call the <code>max</code> method on the data object, supplying to it the name of the field.
This allows <code>yt</code> to decide how to decompose, parallelize and process the data in a memory-efficient way, and spread across multiple processors.
Additionally, by emphasizing that the “maximum” is being taken on the data object, rather than the numerical data, other operations can be exposed that build on the underlying data organization.
For instance, taking the maximum along a given (spatial) axis:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>sp <span class="op">=</span> ds.sphere(<span class="st">&quot;center&quot;</span>, (<span class="fl">10.0</span>, <span class="st">&quot;m&quot;</span>))</span>
<span id="cb3-2"><a href="#cb3-2"></a>sp.<span class="bu">max</span>((<span class="st">&quot;gas&quot;</span>, <span class="st">&quot;temperature&quot;</span>), axis<span class="op">=</span><span class="st">&quot;z&quot;</span>)</span></code></pre></div>
<p>This translates our meaning – find the maximum value along the z-axis – into a dimensionality reduction operation that uses <code>yt</code>’s built-in “projection” method.
These operations, on data objects (rather than the underlying arrays of values that are accessible through them) provide dataframe-like methods for querying very large, spatially registered data.</p>
<p>The array-like operations utilized in <code>yt</code> attempt to map to conceptually similar operations in numpy.
Unlike numpy, however, these utilize <code>yt</code>’s dataset-aware “chunking” operations, in a manner philosophically similar to the chunking operations used in dask.
Below, we outline the three classes of operations that are available, based on the type of their return value.</p>
<h4 id="sec:arrayops-scalar">Reduction to Scalars</h4>
<p>Traditional array operations that map from an array to a scalar are accessible utilizing familiar syntax. These include:</p>
<ul>
<li><code>min(field_specification)</code>, <code>max(field_specification)</code>, and <code>ptp(field_specification)</code></li>
<li><code>argmin(field_specification, axis)</code>, and <code>argmax(field_specification, axis)</code></li>
<li><code>mean(field_specification, weight)</code>, <code>std(field_specification, weight)</code>, and <code>sum(field_specification)</code></li>
</ul>
<p>In addition to the advantages of allowing the parallelism and memory management be handled by <code>yt</code>, these operations are also able to accept multiple fields.
This allows multiple fields to be queried in a single pass over the data, rather than multiple passes.
Additionally, the <code>min</code> and <code>max</code> operations will automatically cache the results during a single pass, which means that calling <code>max</code> immediately after <code>min</code> (and vice versa) on the same data object and field will not require a recomputation.</p>
<p>In the case of <code>argmin</code> and <code>argmax</code>, the default returned “axis” will be the spatial coordinates of the minimum or maximum field value (respectively).<br />
However, by specifying an axis or set of axes that correspond to fields, the field values will be queried at these minimum or maximum points.
This allows, for instance, to query the value of “density” at the minimum “temperature.”
The operations <code>mean</code> and <code>sum</code> are available here in a non-spatial form, where they simply compute the scalar reduction independent of the spatial registration of the dataset.</p>
<h4 id="sec:arrayops-vector">Reduction to Vectors</h4>
<ul>
<li><code>profile(axes, fields, profile_specification)</code></li>
</ul>
<p>The <code>profile</code> operation provides weighted or unweighted histogramming in one or two dimensions.
This function accepts the axes along which to compute the histogram as well as the fields to compute, and information about whether the binning should be an accumulation, an average, or a weighted average.
These operations are described in more detail in <strong>reference profile section</strong>.</p>
<h4 id="sec:arrayops-remap">Remapping Operations</h4>
<ul>
<li><code>mean(field_specification, weight, axis)</code></li>
<li><code>sum(field_specification, axis)</code></li>
<li><code>integrate(field_specification, weight, axis)</code></li>
</ul>
<p>These functions map directly to different methods used by the projection data object.
Both <code>mean</code> and <code>sum</code>, when supplied a spatial axis, will compute a dimensionally-reduced projection, remapped into a pixel coordinate plane.
Importantly, if the dataset is a finite-volume dataset (grid, octree, etc), the results of these operations will be a variable-resolution mesh, rather than a fixed resolution image buffer.</p>
<h2 id="abstracting-simulation-types">Abstracting Simulation Types</h2>
<h3 id="chunking-and-decomposition-strategies">Chunking and Decomposition Strategies</h3>
<p>Reading data, particularly data that will not be utilized in a computation, can incur susbtantial overhead, particularly if the data is spread over multiple files on a networked filesystem, where metadata queries can dominate the cost of IO.
<code>yt</code> takes the approach of building a coarse-grained index based on the discretization method of the data (particle, grid, octree, unstructured mesh), combining this with datapoint-level indexing for selection processes.</p>
<p>To supplement this, methods in <code>yt</code> that process data utilize a system of data “chunking,” whereby segments of data identified during coarse-grained indexing are subdivided by one of a few different schemes and yielded to the iterating function; these schemes can include a limited number of tuning parameters or arguments.
These three chunking methods are <code>all</code>, <code>spatial</code> and <code>io</code>.
The <code>all</code> method simply returns a single, one-dimensional array, and the number of chunks is always exactly one; this enables both non-parallel algorithms and simple access to small datasets.
<code>spatial</code> chunking yields three-dimensional arrays.
For grid-based datasets, these are the grids, while for particle and octree datasets they are leaf-by-leaf collections of particles or mesh values.
Optionally, the <code>spatial</code> chunking method can return “ghost zones” around regions, for computation of stencils.
The final type of chunking, <code>io</code>, is designed to iterate over sets of data in a manner that is most conducive to pipelined IO.
These will not always be load-balanced in size of the returned chunks, however.
In some cases, <code>io</code> chunking may return one file at a time (in the case of spreading items across many different files), while in others it may be returning sub-components of a single file.
This chunking type is the most common strategy for parallel-decomposition.</p>
<p>Necessarily, both indexing and selection methods must be implemented to expose these different chunking interfaces; <code>yt</code> utilizes specific methods for each of the primary data types that it can access.
We detail these below, specifically describing how they are implemented and how they can be improved in future iterations.</p>
<h3 id="grid-analysis">Grid Analysis</h3>
<p><code>yt</code> was originally written to support the Enzo code, which is a patch-based Adaptive Mesh Refinement (AMR) simulation platform.
Analysis of grid-based data is the most frequent application of <code>yt</code>.
While we discuss much of the techniques implemented for datasets consisting of multiple, potentially overlapping grids, <code>yt</code> also supports single-grid datasets (such as FITS cubes) and is able to decompose them for parallel analysis.</p>
<p><code>yt</code> also supports other grid patch codes <strong>insert list here</strong></p>
<p><code>yt</code> supports several different “features” of patch-based codes.
These include grids that span multiple parent objects, grids that overlap with coarser data (i.e., AMR), grids that overlap with other grids that provide the same level of resolution of data (i.e., grids at the same AMR level), refinement factors that vary based on level, and edge- and vertex-centered data.
For the cases of overlapping grids (either on the same or higher refinement levels) masks are generated that indicate which data is considered authoritative.</p>
<p>As noted in <a href="#sec:data_objects">Data Objects</a>, the process of selecting points is multi-step, starting at coarse selection that may be at the file level, and proceeding to selection of specific data points that are included in a selector.
For grid-based data, the coarse selection stage proceeds in an extremely simple fashion, by iterating over flat arrays of left and right grid edges and creating a bitmap of the selected grids.
Because this method – while not taking advantage of any data structures of even mild sophistication – is able to take advantage of pipelining and cache-optimization, we have found that it is sufficiently performant in most geometries up to approximately <span class="math inline">\(10^6\)</span> grid objects.
In those cases, the distinction between “wide and shallow” grid structures (where refinement occurs essentially everywhere, but not to a great degree) and “thin and deep” grid structures (where refinement occurs in essentially one location but to very high levels), as well as the specific selection process, impact the overall performance.
The second-stage selection occurs within individual grids, where points are selected based on the data point center.
In the case of cell-centered data, this returns an array of size <span class="math inline">\(N\)</span> where <span class="math inline">\(N\)</span> is the number of points selected; in the case of 3D vertex-centered data, this would be <span class="math inline">\((N,8)\)</span>.
<strong>Andrew Myers: check this?</strong></p>
<p>Indexing grid data in <code>yt</code> is optimized for systems of grids that tend to have larger grid patches, rather than smaller; specifically, in <code>yt</code> each grid patch consists of a Python object, which adds a bit of overhead.
In the limit of many more cells than grid objects, this overhead is small, but in cases where the number of grids is <span class="math inline">\(O(10^7)\)</span> this can become prohibitive.
These cases are becoming more common even for medium-scale simulations.</p>
<p>To address both the memory overhead and the python overhead, as well as more generally address potential scalability issues with grid selection, several tentative explorations have been made into an implementation of a more sophisticated “grid visitors” indexing and selection method, drawing on the approach used by the oct-visitors (described <a href="#sec:octree_analysis">below</a>).
These were an attempt to unify the selection methods between octrees and grids, to reduce the overall code duplication and implementation overhead.
Each process – selection, copying of data, generation of coordinates – is represented by an instance of a <code>GridVisitor</code> object.
The tree is recursively traversed, and for all selected points the object is called.
This allows grids, their relationships, and the data masks to be stored in structures and forms that are both optimized and compressed.
This method is essential for scaling to a large number of grid patches; the storage requirements of a single grid patch Python object are around 1K per object (about one gigabyte per million grids), whereas the optimized storage reduces this to approximately 140 bytes (about one gigabyte per eight million grids), with further reductions possible; for selection operations, we are also able to reduce the number of temporary arrays and utilize compressed mask representation, bringing peak memory usage down further.
The spatial-tree optimization substantially increases performance for “wide and shallow” dataset selection.
However, while such an implementation may be possible, the previous attempts were stymied by performance and maintenance considerations for the grid code, in particular related to the masking of “child” zones in an efficient and straightforward manner.
A spatial tree is constructed, wherein parent/child relationships are established between grids.</p>
<h3 id="sec:octree_analysis">Octree Analysis</h3>
<p><code>yt</code> supports octree-based AMR datasets (primarily RAMSES and ART, but also the output from the octree-based radiative transfer code Hyperion).
<code>yt</code> stores a copy of the octree using a pointer-based approach, where each oct points to its eight children (if refined).
The octs living at the coarsest level of the simulation are stored as a uniform grid. For domain-decomposed datasets, each domain is represented as a sparse octree, where the root octs are stored as a list and efficiently accessed using a binary search, ensuring each root oct is found in <span class="math inline">\(O(log(N))\)</span> time, where <span class="math inline">\(N\)</span> is the number of root octs in the domain.
Each oct is represented as structure that contains the on-file location of the oct (<code>file_ind</code>) and its in-memory location (<code>domain_ind</code>), the index of the domain it belongs to (<code>domain</code>) and a list of pointers to its children (up to eight in 3D). This requires at most 88 bytes per oct.</p>
<p>In order to load data within a given region, a two-step approach is followed.
First, the cells interesting with the region of interest, as described in <a href="#sec:data_objects">Data Objects</a> are selected. <code>yt</code> relies on an oct-visitor machinery combined with selection routines.
The tree is recursively traversed depth-first starting from the root grid, following only those branches that may intersect with the selected region.
At the tip of each branch, the up-to-eight leaf cells are visited.
In a first pass, the number of selected cells is computed and in a second pass, the on-file location of their parent oct is stored.
Second, <code>yt</code> relies on the on-file location obtained from the octree traversal to lazily read data from disk.
This ensures that only the minimal amount of data is being read and is particularly efficient when accessing a region spanning a small number of domains and/or a small number of refinement levels.</p>
<p>Recently, <code>yt</code> has been extended to fully supports accessing neighboring cells.
This is achieved by computing one-cell thick quantities around each oct, which emulates the “ghost zones” found in patch-based codes. This approach has the advantage of abstracting the octree structure and provides a common interface to create derived fields, as described in <strong>CC: any section describing this?</strong>.
The 56 neighbors (<span class="math inline">\(4^3 - 2^3\)</span>) surrounding each oct are found by performing a search in the octree, which finds any neighbor in <span class="math inline">\(O(\mathrm{level})\)</span>, where <span class="math inline">\(\mathrm{level}\)</span> is the level of the central oct.
The search is illustrated on Figure <a href="#fig:binary-search">5</a>.
Other optimizations are possible that trade computational time with memory, for example by storing the tree as a fully-threaded structure (i.e. store pointers to the 6 neighbors sharing a face with each oct), or by starting at a central oct and searching “upwards and outwards.”</p>
<div id="fig:binary-search" class="fignos">
<figure>
<embed src="images/octree/binary_tree_research_2D.pdf" /><figcaption><span>Figure 5:</span> Illustration of a binary search through a quadtree. The search starts at the root level (level = 1 here) and recursively selects the quad that contains the point until reaching a leaf.
The procedure is easily generalized in 3D.</figcaption>
</figure>
</div>
<div id="fig:octree-gradient" class="fignos">
<figure>
<embed src="images/octree/gradient_computation.pdf" /><figcaption><span>Figure 6:</span> Scheme of the AMR structure used to estimate the gradient of a quantity in the central oct (red). Octs are represented in thick lines, cells in thin lines and virtual cells in dashed lines. <em>Left panel:</em> The virtual cell values on a <span class="math inline">\(4^3\)</span> grid are interpolated from the nearest cell in the AMR grid. If the nearest cell is at the same level, its value is directly used. If the cell is at a coarser level, its value is directly used (for example <span class="math inline">\(f_{31}\)</span> and <span class="math inline">\(f_{32}\)</span> have the value of the green cell). If the cell is refined, the mean of its children is used (for example <span class="math inline">\(f_{20}\)</span> is the mean of all the blue cells). <em>Right panel:</em> Gradients are estimated using a first-order finite difference centered scheme on the <span class="math inline">\(4^3\)</span> virtual cells.</figcaption>
</figure>
</div>
<h3 id="sph-analysis">SPH Analysis</h3>
<h3 id="unstructured-mesh-analysis">Unstructured Mesh Analysis</h3>
<h3 id="sec:noncartesian">Non-Cartesian Coordinates</h3>
<h2 id="sec:point_indexing">Indexing Discrete-Point Datasets</h2>
<p>Advances in both hardware and software facilitate astrophysical datasets of growing complexity and size.
The datasets produced by numerical simulations can currently reach sizes of $$100 Tbytes split across hundreds of files <span class="citation" data-cites="xbCL1tS1">[<a href="#ref-xbCL1tS1" role="doc-biblioref">3</a>]</span>.
For even simple analysis tasks, the cost of incrementally reading datasets this large into memory is quite high.
This problem is not limited to theoretical work.
During operations the Large Synoptic Survey Telescope (LSST) will produce 15 Tbytes of data each night <span class="citation" data-cites="gw5rMEhN">[<a href="#ref-gw5rMEhN" role="doc-biblioref">4</a>]</span>.
In order to analyze such large datasets, we need innovative techniques for quickly indexing and selecting data without loading the entire dataset into memory.
We present a technique for using Morton bitmap indexes to map files and accelerate data analysis.</p>
<h3 id="sec:bitmap_theory">Theory and Background</h3>
<h4 id="domain-partitioning-between-files">Domain Partitioning Between Files</h4>
<p>A common analysis task is the selection of data within a subset of the full domain; we use the term "selector" to refer to the selection operator.
If the dataset is split across multiple files, either due to size constraints or to allow for parallel I/O, such selections require every file to be loaded and parsed in order to assemble all of the data within the selection criteria.
This process can be very costly in terms of both the memory required to store the data and the time required to read each file.
However, if the contents of the files are mapped in advanced, only the files touched by the selection will need to be loaded.
This is particularly effective for partitioning schemes that are localized within the domain.
If each file contains data that are localized to one part of the domain, selections of contiguous sub-sections within the domain will require fewer files to be loaded.
Figure <a href="#fig:files">7</a> shows four examples of possible partitions of a two-dimensional spatial domain split equally between 8 files.</p>
<div id="fig:files" class="fignos">
<figure>
<img src="images/bitmap/files.png" alt="" /><figcaption><span>Figure 7:</span> Examples of four different schemes for partitioning a 2D domain between 8 files.
Each color represents a different file.</figcaption>
</figure>
</div>
<p>Panel (a) is an example where random parts of the domain are contained within each file.
In such a case, many files will need to be loaded for contiguous selections within the domain.
In panel (b), the domain was split between the files along the <span class="math inline">\(x\)</span> dimension.
Fewer files will need to be loaded for queries along the <span class="math inline">\(y\)</span>-dimension, but contiguous selection in <span class="math inline">\(x\)</span> will still require a greater number of files since the partition is not well localized in that dimension.
Panels (c) and (d) are both examples of partitioning the domain between the files along a space filling curve <span class="citation" data-cites="PSH5f9xg oIYFC4kD">[<a href="#ref-PSH5f9xg" role="doc-biblioref">5</a>,<a href="#ref-oIYFC4kD" role="doc-biblioref">6</a>]</span>.
These partitions have the greatest chance of limiting the number of files that must be loaded for a contiguous selection with slightly improved localization for the Hilbert curve.
Consequently, Hilbert curves have also been used for load-balancing in parallel simulation codes like Gadget-2 <span class="citation" data-cites="I01oLUIj">[<a href="#ref-I01oLUIj" role="doc-biblioref">7</a>]</span> and RAMSES <span class="citation" data-cites="1D5nekPGx">[<a href="#ref-1D5nekPGx" role="doc-biblioref">8</a>]</span>.</p>
<p>Figure <a href="#fig:selector1">8</a> shows examples of three selections within the above domain partitions.</p>
<div id="fig:selector1" class="fignos">
<figure>
<img src="images/bitmap/selector1.png" alt="" /><figcaption><span>Figure 8:</span> Examples of file selection for four different domain partitions and three different shaded selectors.
The number of files above each images is the number of files that must be loaded in order to get all of the data within the selected region.</figcaption>
</figure>
</div>
<div id="fig:selector5" class="fignos">
<figure>
<img src="images/bitmap/selector5.png" alt="" /><figcaption><span>Figure 9:</span> Examples of file selection for four different domain partitions and three different shaded selectors.
The number of files above each images is the number of files that must be loaded in order to get all of the data within the selected region.</figcaption>
</figure>
</div>
<div id="fig:selectors4" class="fignos">
<figure>
<img src="images/bitmap/selector4.png" alt="" /><figcaption><span>Figure 10:</span> Examples of file selection for four different domain partitions and three different shaded selectors.
The number of files above each images is the number of files that must be loaded in order to get all of the data within the selected region.</figcaption>
</figure>
</div>
<p>For the smallest selector (first row), the random domain decomposition (a) already requires half of the files to be loaded while more localized schemes require much fewer.
Similarly, while the sliced domain partition (b), requires the fewest files to be loaded when the selector is oriented in the same direction as the slicing (second row), it requires <em>all</em> of the files when the selector is perpendicular to the slicing (third row).
While some datasets may have information on the domain range covered by each file, the partitioning scheme used for simulation output is often decided at runtime, can be system dependent, and may be imperfect.</p>
<p>Files are often partitioned for parallel I/O such that each processor outputs data on the portion of the domain it is responsible for processing.
To limit the cost of communication between processors, the domain will be split across processors such that neighboring processors are responsible for neighboring parts of the domain.
This means that, although the overall partitioning scheme may be known for a given dataset, the exact order of the files will be dependent on the configuration of the processors at runtime.</p>
<p>The partitioning can also be imperfect if the domain decomposition is not perfect at the time of output.
For instance, in astrophysical N-body simulations, it is possible for particles to travel from one processor’s domain to another.
In this case, the partition will only be perfect directly following an update to the domain decomposition.</p>
<p>In cases where the exact file organization is not known or imperfect, it is advantageous to map the files post-process in order to speed up selections for analysis.
Although the same result can be achieved by re-sorting the data itself, creating the map can be less computationally less expensive than re-sorting the data, can be saved for use with multiple selections, and does not required write access; this is typically not feasible, especially in the case of datasets shared by large, distributed communities.</p>
<h2 id="morton-indices">Morton Indices</h2>
<p>Morton ordering maps multidimensional data onto a one-dimensional space filling curve <span class="citation" data-cites="PSH5f9xg">[<a href="#ref-PSH5f9xg" role="doc-biblioref">5</a>]</span>.
This is done by breaking up the domain into cells where each cell’s position within the <span class="math inline">\(N\)</span>-dimensional domain can be described by <span class="math inline">\(N\)</span> integers.
The Morton index of the cell is then created by interleaving the bits of the <span class="math inline">\(N\)</span> integers to create a single integer that fully describes the cell’s position (see panel (b) Figure <a href="#fig:zorder">11</a>).
As seen in panel (a) of Figure <a href="#fig:zorder">11</a>, ordering of the cells by their Morton indices forms a space filling Z-curve.</p>
<div id="fig:zorder" class="fignos">
<figure>
<img src="images/bitmap/zorder.png" alt="" /><figcaption><span>Figure 11:</span> Example of 3rd order Morton curve in two dimensions.
The bits of the <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> indices are interleaved to generate a single integer that fully describes the cell’s location within the two-dimensional domain to within <span class="math inline">\(1/2^{3}\)</span>th of the domain in each dimension.</figcaption>
</figure>
</div>
<p>The precision of a single Morton index is only limited by the size of the integer used to store it.
For instance, 64-bit Morton indices in 3 dimensions can be localized to <span class="math inline">\(1/2^{21}\)</span>th of the domain in each dimension (<span class="math inline">\(3\times21\)</span> bits = 63 bits).
If the domain is binarily divided into subcells to some order <span class="math inline">\(k\)</span> in each dimension (i.e.
<span class="math inline">\(2^{Nk}\)</span> cells), coarser Morton indices can be obtained by simply masking lower bits.
Morton ordering has been used to speed up quadtree construction <span class="citation" data-cites="LpXfagAT">[<a href="#ref-LpXfagAT" role="doc-biblioref">9</a>]</span>, nearest neighbor searches <span class="citation" data-cites="12vJ72aHG">[<a href="#ref-12vJ72aHG" role="doc-biblioref">10</a>]</span>, and range queries <span class="citation" data-cites="4mimKxQe">[<a href="#ref-4mimKxQe" role="doc-biblioref">11</a>]</span>.
By recording the indices of the cells containing data from each file within a dataset, Morton indices can also be used to construct one-dimensional maps of an <span class="math inline">\(N\)</span>-dimensional dataset that can be represented as bitmaps.</p>
<h4 id="bitmaps-ewah-compression">Bitmaps &amp; EWAH Compression</h4>
<p>Bitmap indexes use the values of single bits within an array of bits to describe dataset properties.
This form requires minimal memory and can be filtered using computationally inexpensive boolean operations.
Bitmap indexes have long been popular for use with large data warehouses <span class="citation" data-cites="f1rS5tZk YV4eT8wZ DMkimxcD">[<a href="#ref-f1rS5tZk" role="doc-biblioref">12</a>,<a href="#ref-YV4eT8wZ" role="doc-biblioref">13</a>,<a href="#ref-DMkimxcD" role="doc-biblioref">14</a>]</span>.
However, as scientific datasets have become larger and more complex, they have also begun to gain traction in a diverse array of scientific fields including geosciences <span class="citation" data-cites="itaUSTKC">[<a href="#ref-itaUSTKC" role="doc-biblioref">15</a>]</span>, earth sciences, rocket science <span class="citation" data-cites="QMaCupmb mMJ3UeWp">[<a href="#ref-QMaCupmb" role="doc-biblioref">16</a>,<a href="#ref-mMJ3UeWp" role="doc-biblioref">17</a>]</span>, high-energy physics <span class="citation" data-cites="VzYAeBg3">[<a href="#ref-VzYAeBg3" role="doc-biblioref">18</a>]</span>, and combustion <span class="citation" data-cites="AFyCFou3">[<a href="#ref-AFyCFou3" role="doc-biblioref">19</a>]</span>.</p>
<p>In cases where data attributes can take on a finite set of values, one bitmap is constructed for each possible attribute value.
Within the bitmap each bit specifies whether or not the corresponding data point has that value.
In this way, queries for data with a single attribute value require consulting only one bitmap and queries of multiple attributes/values can be done using boolean AND operations on the corresponding bitmaps.
In the case of scientific data, which often contains floating point value attributes, the attributes must be binned prior to constructing the bitmaps <span class="citation" data-cites="Sju7gfgZ uibMnWfE pe5S32KG">[<a href="#ref-Sju7gfgZ" role="doc-biblioref">20</a>,<a href="#ref-uibMnWfE" role="doc-biblioref">21</a>,<a href="#ref-pe5S32KG" role="doc-biblioref">22</a>]</span>.
Here, Morton indices are used to bin N-dimensional floating point data onto one-dimension.
As a result, each file can be described by one bitmap.</p>
<p>For each file within a dataset, the Morton indices touched by the data within that file can then be stored in a bitmap index for future searches where the value of bit <span class="math inline">\(j\)</span> indicates whether or not Morton index <span class="math inline">\(j\)</span> is touched by the file in question.
For Morton indexing of order <span class="math inline">\(k\)</span>, this would result in a bitmap of length <span class="math inline">\(2^{Nk}\)</span> bits per file.
For large bitmaps, this can become costly in terms of memory and the time required to perform bitmap operations.
However, Enhanced Word-Aligned Hybrid (EWAH) compression can be used to limit these costs, particularly when the domain is densely or sparsely populated in localized regions <span class="citation" data-cites="yuSdhiDQ zXsFmNjY 2qfATif3">[<a href="#ref-yuSdhiDQ" role="doc-biblioref">23</a>,<a href="#ref-zXsFmNjY" role="doc-biblioref">24</a>,<a href="#ref-2qfATif3" role="doc-biblioref">25</a>]</span>.</p>
<p>An EWAH compressed bitmap will be smaller when there are long sequences, or “runs,” of identical values.
This means that an EWAH compressed bitmap will be smallest if either all or none of its bits are set.
An uncompressed bitmap would require the same, maximum, amount of memory in both of these cases.
The locality of Morton indices takes advantage of the EWAH compression.
If there are regions of the domain that are densely/sparsely populated, there Z-order space filling curve ensures that the bits denoting those regions will be adjacent, increasing the likelihood that there will be runs of identical (set/unset) bits and limiting the size of the compressed bitmaps.</p>
<h4 id="collisions">Collisions</h4>
<p>It is possible that two files will contain data within the same Morton cell.
This would mean that any time that cell is touched by a selection, both files would need to be loaded even if the selection only touches data from one of the files.
Figure <a href="#fig:collision">12</a> provides an example of collisions between two files.
In panel (a) of Figure <a href="#fig:collision">12</a>, purple cells are those that contain data from both files, a collision, for a 3rd order Morton index.
Any selector that contained one of those cells would need to load all of the data from both files, even if it only selected part of the cell.
Where the data is highly-concentrated in a central region (for instance, in a galaxy formation simulation with particles centrally-concentrated) this can mean that some regions suffer from worst-case scenario collision.</p>
<div id="fig:collision" class="fignos">
<figure>
<img src="images/bitmap/collisions.png" alt="" /><figcaption><span>Figure 12:</span> Examples of a collision between two files.
The red points and blue points are contained by two different files.
The larger grid in both panels denotes the boundaries of 3rd order Morton cells.
The cells containing points from either file are shaded accordingly such that cells containing points from both files are purple.
The smaller grids within these cells on the right are the boundaries of 2nd order Morton cells refining the collisions.</figcaption>
</figure>
</div>
<p>Collisions can be limited by either increasing the order of the index or allowing for multi-resolution indexes <span class="citation" data-cites="QMaCupmb mMJ3UeWp">[<a href="#ref-QMaCupmb" role="doc-biblioref">16</a>,<a href="#ref-mMJ3UeWp" role="doc-biblioref">17</a>]</span>.
Panel (b) of Figure <a href="#fig:collision">12</a> demonstrates an example of nesting a second index within cells that contain collisions.
In those cells which contained collisions, a 2nd order Morton index was added.
Those cells with collisions at the level of the refined index (purple cells in panel (b)) cover a much smaller portion of the domain than the cells with collisions at the level of the coarse index (purple cells in panel (a)).
This means that any given selection is less likely to contain a collision and it will be less likely for a selector to require both files to be loaded unless it actually touches data from both files.</p>
<p>Increasing the order of the coarse index has the same effect as nesting a second refined index within cells with collisions, but can also increases the size of the resulting map and the time it takes to identify files touched by a selection.
However, if the order of the coarse index is too small or the order of the refined index too large, this too can increase the cost of a selection in terms of memory and time.
Section [sec:test_order] discusses this tradeoff and how to choose index orders.</p>
<p>Collisions are more common for file partitioning schemes that are not localized.
Figure <a href="#fig:collision_files">13</a> shows an example of collisions for the different partitioning schemes discussed in Section [sec:decomp].</p>
<div id="fig:collision_files" class="fignos">
<figure>
<img src="images/bitmap/index.png" alt="" /><figcaption><span>Figure 13:</span> Examples of collisions for four different domain partitioning schemes.
The heavy black lines denote 1st order Morton cells.
The presence of more that one file (color) within a Morton cell indicates a collision.</figcaption>
</figure>
</div>
<p>For the random domain partition in panel (a), every cell within a 1st order Morton index will contain data from all 8 files.
This means that any selection using a 1st order bitmap index will require every file to be loaded.
For the more localized partitions in panels (c) and (d), only two files touch each Morton cell.</p>
<h4 id="ghost-zones">Ghost Zones</h4>
<p>It is often the case that, in selecting a region, additional padding around the region should be included in the selection.
This is particularly useful for algorithms that need information about neighboring points in the domain <span class="citation" data-cites="1C6sv2xA4 DQa79Dfo I01oLUIj">[<a href="#ref-1C6sv2xA4" role="doc-biblioref">26</a>,<a href="#ref-I01oLUIj" role="doc-biblioref">7</a>,<a href="#ref-DQa79Dfo" role="doc-biblioref">27</a>]</span>.
For Morton indices, this is straightforward as the indices neighboring Morton cells can be found by incrementing the bits corresponding to each dimension.
We have included the ability to pad selectors with some number of Morton cells referred to as ‘ghost zones’.
Those files that touch ghost zones, but not the selector itself are referred to below as ‘ghost files’.</p>
<p>Depending on how the domain is split between files, the inclusion of ghost zones may or may not increase the number of files that need to be loaded.
Figure <a href="#fig:ghosts">14</a> shows an example of a ghost zone around the first selector from Figure <a href="#fig:selector1">8</a>.</p>
<div id="fig:ghosts" class="fignos">
<figure>
<img src="images/bitmap/ghosts.png" alt="" /><figcaption><span>Figure 14:</span> Examples of a selector ghost zone with a width of one Morton cell at an index order of 3 for four different domain partitioning schemes.
The shaded circular region is the selector and the shaded box is the ghost zone.
Different partitioning schemes will lead to different numbers of ghost files.</figcaption>
</figure>
</div>
<p>The ghost zone has a width of one Morton cell at an index order of 3 and contains the same part of the domain in each case.
However, due to differences in how the domain was partitioned between the files in the four cases, the number of additional ghost files touched by the ghost zone in each case is different.
This will also depend on the order of the index to which ghost zones are added.
Ghost zones added at the order of the coarse index will be larger than those added at the order of the refined index and will have a higher probability of touching additional files.
While including ghost zones is advantageous when neighbor info is needed, it also increases the computational cost of identifying files (see Section [sec:tests]).</p>
<h3 id="sec:methods">Methods</h3>
<p>The basic procedure for constructing the bitmap index is as follows:</p>
<ol type="1">
<li><p><strong>Compute coarse indices.</strong> For each file in the data set, read in
the data and compute the indices of Morton cells at a given coarse
order that are touched by data contained within that file. These
coarse indices are then stored by setting the corresponding bits in
an EWAH compressed bitmap.</p></li>
<li><p><strong>Find collisions.</strong> The indices of coarse cells that are touched by
data in more than one file (collisions) are located using bitwise
operations on the file bitmaps. These indices are also stored in an
EWAH compressed bitmap.</p></li>
<li><p><strong>Compute refined indices.</strong> For each file in the data set, read in
the data and compute the indices of Morton cells at a given refined
order within coarse cells with collisions that are touched by that
file. These refined indices are stored in a map from coarse Morton
index to an EWAH compressed bitmap of refined Morton indices within
that cell.</p></li>
<li><p><strong>Output bitmaps.</strong> The EWAH compressed bitmaps for the coarse
indices, refined indices, and collisions are saved to an external
index file.</p></li>
</ol>
<p>For large datasets and/or high levels of refinement, this can be a time consuming process; fortunately, it must only be done once.
For future selections, the bitmap can be quickly loaded and used to identify files in less time than would be required to load and query each file within the dataset individually.
Selection using a loaded bitmap goes as follows:</p>
<ol type="1">
<li><p><strong>Construct selector bitmap.</strong> In the same way each file was mapped,
the indices of Morton cells touched by the selector are stored in a
bitmap. This is done by checking for intersection of the selector
with Morton cells at the order of the coarse bitmaps. For contiguous
selectors, this is done at lower order (parent) cells first and
continued recursively until the order of the coarse bitmap is
reached.</p>
<ul>
<li><p>If a cell is completely within the selector, all of its child
cells at the coarse order are added to the bitmap.</p></li>
<li><p>If a cell intersects the edge of the selector, child cells at
increasing orders are checked until the order of the coarse
bitmaps are reached. If the cell is at the coarse order and
there is a collision between two files, a refined bitmap is the
constructed for the selector in the same manner.</p></li>
</ul></li>
<li><p><strong>Find files intersecting the selector.</strong> Bitwise operations with
the coarse file bitmaps are then used to efficiently identify files
that intersect the selector within coarse cells. If the coarse cells
within the intersection with a file all have collisions with other
files, bitwise operations with the refined file bitmaps are then
used to determine if the file is selected at the order of the
refined index.</p></li>
</ol>
<p>If ghost zones are desired, the neighbors of cells that intersect the edge of the selector are added to a separate bitmap.
For cells without collisions, the neighbors are added at the coarse bitmap order.
If there are collisions, the neighbors are added at the refined bitmap order.</p>
<h3 id="sec:tests">Tests</h3>
<p>The utility of using Morton index bitmaps for mapping files to decrease query times was tested on artificial N-body simulation datasets containing <span class="math inline">\(1024^3\)</span> points in three dimensions, distributed between 512 files.
For each test a Morton index bitmap was constructed for the dataset and used to identify files touched by cube shaped three-dimensional selectors.
The performance is assessed in terms of the number of files identified and the average time required to identify them across 10 runs.
If fewer files are touched, fewer files will need to be loaded during analysis of a selected region and the overall fraction of time spent on I/O will be lower.
If less time is required to identify the files touched by a given selector, more selections can be made using the same computational resources.
This was done for varying index orders (Section [sec:test_order]), selector sizes (Section [sec:test_size]), and partitions of the domain between files (Section [sec:test_decomp]).</p>
<h4 id="sec:test_order">Index Order</h4>
<h4 id="sec:test_order1">Overall Refinement</h4>
<p>The order of the Morton indices used to map the files determines the time required to identify files and the number of collisions that will occur between files.
Higher order indices will result in fewer collisions, but will take longer to query, as seen in Figure <a href="#fig:test_order1">15</a> Six selectors of varying sizes and positions within the domain where used to identify files based on Morton index bitmaps of varying order.
The test dataset was split across the files using a Hilbert curve of order 6 with 10% scatter between Hilbert cells to simulate an imperfect domain decomposition as can occur if particle positions are updated and output prior to updating the domain decomposition.</p>
<div id="fig:test_order1" class="fignos">
<figure>
<img src="images/bitmap/vary_order1_or0.png" alt="" /><figcaption><span>Figure 15:</span> Dependence of query time (top), fraction of files selected/cells with collisions (middle), and index size (bottom) on the total refinement of the bitmap index.
The solid black lines correspond to the query times and files identified by just the selectors.
The dashed blue lines correspond to the query times and additional files selected when a ghost zone with the width of one Morton cell is added around the selectors.
The dash-dotted line in the middle panel shows the fraction of cells with collisions between files.</figcaption>
</figure>
</div>
<p>Below a bitmap index order of 4, there are collisions between multiple files within every cell, resulting in a larger number of files being identified.
However, as the order increases, the number of collisions drops and the file count plateaus at <span class="math inline">\(\sim25\)</span>%.
This translates to a <span class="math inline">\(\sim75\)</span>% reduction in the memory and time required for processing files, a significant increase in performance.
For a 7th order bitmap index, selection requires <span class="math inline">\(&gt;100\times\)</span> the time that the same selection took using a 6th order index, but there is no change in the number of files indicated.
A 6th order index is sufficient to identify the minimal set of files touched by the selectors in this case because the dataset was partitioned between the files along a 6th order Hilbert space filling curve.
While it is generally true that the time required to identify files using a bitmap index will increase exponentially with the size of the index, the order of the index that results in the minimal number of files for any dataset will depend upon how the domain is partitioned between files (see Section [sec:test_decomp]).
The memory required to store the index for the test dataset scales according to <span class="math inline">\(\propto2^{2k}\)</span>, for a <span class="math inline">\(k^{\mbox{th}}\)</span> order index.
If uncompressed bitmaps had been used instead of EWAH compressed bitmap, the memory would have scaled with the total number of cells contained within the 3-dimensional test domain (<span class="math inline">\(2^{3k}\)</span>).</p>
<h4 id="sec:test_order2">Collision Refinement</h4>
<p>Increasing the refinement of the primary index does so for the entire domain and, as seen in Section [sec:test_order1], can become costly in terms of the memory required to store the bitmap and the time required to perform operations.
However, it is also possible to increase refinement by nesting a second Morton bitmap index within those cells of the primary index that contain collisions.
As the nested indexes will contain a smaller portion of the domain and data, they will be less complex and can be compressed more efficiently than the primary index covering the entire domain.
This enhanced compression mean that, although a greater overall number of EWAH compressed bitmaps will need to be utilized (one for the coarse index and one for each collision within the coarse index), less space will be needed to store the bitmap and bitwise operations will be faster.
Figure <a href="#fig:test_order2">16</a> shows the results for adding a secondary index of varying order with the overall refinement order of the index (primary index order + secondary index order) held constant at 6.
The test dataset and selectors applied were the same as in Section [sec:test_order1].</p>
<div id="fig:test_order2" class="fignos">
<figure>
<img src="images/bitmap/vary_order2_to6.png" alt="" /><figcaption><span>Figure 16:</span> Dependence of query time (top), fraction of files selected/cells with collisions (middle), and memory required to store the index (bottom) on the order of the secondary index used to refine collisions.
In the middle panel, the solid black line corresponds with the fraction of files identified, the dash-dotted blue line is the fraction of cells at the first index level that have collisions, and the dotted red line is the fraction of cells at the second index level that have collisions.</figcaption>
</figure>
</div>
<p>When the order of the second refined index is low, the first index is larger resulting in fewer cells with collisions at the first index and more at the second.
The reverse is true when the order of second index is higher.
As the overall order is held constant, the same number of files are identified regardless of the orders of the first and second indexes.
The time required to identify the files is minimized when cells within the first index become saturated with collisions.
For secondary indexes of order 2 or lower, the large increase in performance offered for increases in the index order results from the reduction in the total complexity of the index which translates to shorter times for bitwise operations and less memory required for storage.
Above 2nd order, the overhead from storing and accessing more complex EWAH compressed bitmaps for each collision begins to flatten the memory scaling and increase the time required for queries.
However, selections using higher order secondary indices still require less time than in the case where only a single index is used.</p>
<p>The optimal value for the orders of the first and second indexes will depend upon the dataset in question.
The density of data points within the test dataset used here is relatively uniform throughout the domain and does not need a high level of refinement at collisions.
However, if a data set were less uniform with concentrations of points, the optimal order of the second index for performance may be higher.</p>
<h4 id="sec:test_size">Selector Size</h4>
<p>The time required to identify files touched by a selection will also depend upon the size of the region being selected.
Larger selectors will intersect more indices and more files, resulting in more bitmap operations.
Figure <a href="#fig:test_size">17</a> shows the result from varying the selector size.
The same test data set from Section [sec:test_order] was used.
A bitmap index with a 4th order primary Morton index and 2nd order secondary Morton index was used in all cases.
Each cube selector was placed at the center of the domain and scaled along each dimension to some fraction of the total domain.</p>
<div id="fig:test_size" class="fignos">
<figure>
<img src="images/bitmap/vary_selector.png" alt="" /><figcaption><span>Figure 17:</span> Dependence of query time (top) and number of files selected (bottom) on selector width in terms of the total domain width.
The solid black lines correspond to the query times and files identified by the selectors alone.
The dashed blue lines correspond the query times and additional files identified when a ghost zone with a width of one cell is added to the selector.</figcaption>
</figure>
</div>
<p>As the selector increases in size, it touches a greater number of files, resulting in longer query times.
The number of files touched increases in steps due to the way the test dataset was partitioned between files.
Using the Hilbert curve, the domain covered by any one file is localized and will have a rectangular shape.
This results in an ordered structure that is similar along all dimensions.
An increase in the number of files touched indicates that the selector has grown past a file boundary in all directions.
It is just prior to these jumps that ghost files are present.
If the selector edge is near a file boundary, ghost zones have the potential to overlap the domains contained by neighboring files that are not already touched by the selector.
For such a highly ordered dataset, the ghost zones will only identify additional files for selectors that are nearing the edges of file boundaries.
However, queries including ghost zones require slightly more time even when this is not the case.</p>
<h4 id="sec:test_decomp">Domain Partitioning</h4>
<p>As discussed in Section [sec:decomp], a bitmap index is more effective in cases where the domain is partitioned between files in a localized way.
If files contain non-contiguous parts of the domain, contiguous selections will require more files to be loaded.
Figure <a href="#fig:test_decomp">18</a> shows results for four different partitioning schemes.
All four data sets cover the same three-dimensional domain with <span class="math inline">\(1024^3\)</span> points split across 512 files.
The Hilbert dataset is the same one used in previous tests (see Section [sec:test_order] for a description).
The Morton dataset is constructed in a similar way to the Hilbert dataset with file partitions occurring along a 6th order Morton curve and including a 10% scatter of points between Morton cells.
The sliced dataset is partitioned in slices along one dimension with 10% scatter of points between adjacent slices.
Files in the random dataset contain a random sample of points, uniformly distributed across the domain.</p>
<div id="fig:test_decomp" class="fignos">
<figure>
<img src="images/bitmap/vary_decomp_to0.png" alt="" /><figcaption><span>Figure 18:</span> Dependence of query time (top), the number of files selected (middle), and the size of the index (bottom) on index order for different domain partitioning between files.
The dotted magenta lines are for a randomly partitioned dataset, the cyan dashed-dotted lines are a dataset partitioned by equal slices alone one dimension, the dashed red lines are a dataset partitioned along an 6th order Morton curve, and the solid blue lines are a dataset partitioned along a 6th order Hilbert curve.</figcaption>
</figure>
</div>
<p>Many more files are identified for the random dataset than those datasets with localized partitioning of the domain.
Above an order of 3, very few files could be excluded for the random dataset.
This was not true for the localized partitioning schemes.
At the highest order, only <span class="math inline">\(\sim20-30\)</span>% of the files within these datasets would need to be loaded in order to get all of the data within the selected regions, while <span class="math inline">\(\sim80\)</span>% of the files in the random dataset would be required.
The smallest fraction of files were identified for the Hilbert and Morton datasets, with a slightly greater fraction being identified for the sliced dataset.
For a 6th order index and below, queries on the Morton and Hilbert partitioned datasets are the fastest.
An index order of 7 provides refinement beyond the 6th order curves used to partition the dataset between the files and the required for queries on these datasets increases dramatically.
The sliced dataset performed particularly well in this case because the selectors used were cubes and did not preferentially select along any one dimension.</p>
<p>Overall, this technique offers a considerable improvement in performance over other methods that require reading, evaluating and discarding all of the particles.</p>
<h3 id="sec:discuss">Summary &amp; Discussion</h3>
<p>Mapping files using Morton bitmap indexes speeds up analysis of large datasets split across multiple files by reducing the number of files that need to be loaded in order to perform operations on a subset of the full domain.
The time required for making selections using the bitmap index is minimal for even large datasets and can be optimized by partitioning the domain between files in a localized way and using an index or indexes of appropriate order for the dataset.</p>
<p>Without an index, queries require loading the data contained in every file into memory and then searching the data for those points that are selected by the query.
With a bitmap index, queries require loading the index, using it to identify the files touched by the query, reading in the data contained within the identified files, and searching the data for points selected by the query.
In this way, the bitmap index can decrease the computational cost of reading in the data and selecting data points if it identifies a subset of the total number of files.
While using an existing bitmap index decreases the time required for queries in this case, constructing a bitmap index can be more computationally expensive than directly querying the data without a bitmap index.
Therefore, in the case where only a small number of selections need to be made, it will be more efficient to perform direct queries of the data than to construct and utilize the bitmap index.</p>
<p>Bitmap indexing is particularly useful in astronomy and astrophysics.
Output from N-body simulations is often split between multiple files to take advantage of parallel I/O and the domain decomposition generally leads to localized partitioning between files <span class="citation" data-cites="DQa79Dfo I01oLUIj 18bL4U0kM">[<a href="#ref-I01oLUIj" role="doc-biblioref">7</a>,<a href="#ref-DQa79Dfo" role="doc-biblioref">27</a>,<a href="#ref-18bL4U0kM" role="doc-biblioref">28</a>]</span>.</p>
<p>Currently, this technique is most useful for datasets split across multiple files.
However, it can also be applied to single files by dividing the file’s contents into chunks.
As in the multi-file case, the single file would need to be organized such that chunks were localized within the domain to take full advantage of the bitmaps.
In addition, while the current implementation of this method is designed for three-dimensional spatial datasets like those produced by astrophysical simulations, the same methods can be applied to non-spatial datasets with arbitrary dimensionality.</p>
<h3 id="sec:code">Code</h3>
<p>These procedures have been implemented as part of the yt python package <span class="citation" data-cites="GqCvYs0n">[<a href="#ref-GqCvYs0n" role="doc-biblioref">29</a>]</span> in order to facilitate the analysis of large astrophysical N-body simulations; currently undergoing review for inclusion in a future version of yt (3.4 or later), our implementation is available at https://bitbucket.org/langmm/yt-bitmap.
The open source EWAHBoolArray C++ package is used for implementing EWAH bitmaps <span class="citation" data-cites="zXsFmNjY 2qfATif3">[<a href="#ref-zXsFmNjY" role="doc-biblioref">24</a>,<a href="#ref-2qfATif3" role="doc-biblioref">25</a>]</span> and exposed to Python using Cython <span class="citation" data-cites="RNeSxk82">[<a href="#ref-RNeSxk82" role="doc-biblioref">30</a>]</span>.</p>
<h3 class="unnumbered" id="acknowledgment">Acknowledgment</h3>
<p>The authors would like to thank Daniel Lemire for his open source EWAH implementation.
yt is developed by a large number of independent researchers from numerous institutions around the world.
Their commitment to open science has helped make this work possible.</p>
<h2 id="sec:vr">Visualization and Volume Rendering</h2>
<p>The primary method by which researchers interact with their data in <code>yt</code> is via visualization; from the standpoint of the library, however, this is a side-effect of the various analysis, regularization and data-processing algorithms that are implemented within <code>yt</code>.
Nearly all of the visualization that is done using <code>yt</code> utilizes the matplotlib library for actual deposition of pixels into an image format, although all of the <em>input</em> to that deposition is conducted by <code>yt</code>.
Making this distinction is important, because it underscores the relationship between the different libraries and how they exist in the ecosystem of scientific software; <code>yt</code> does not replace matplotlib, but rather, augments it by providing a grammar of analysis of volumetric data and defining how that grammar is translated into visual representations as presented by matplotlib.</p>
<p><strong>CC: discuss ray traversal for patch-based datasets + oct-based datasets.</strong></p>
<h3 id="pixelizing-variable-mesh-objects">Pixelizing Variable-Mesh Objects</h3>
<p>The results of either projecting or slicing through a logically-cartesian finite volume dataset is represented in <code>yt</code> as a collection of pixel positions and widths.
These objects, hereafter referred to as exposing the “variable mesh” interface (as originated in HippoDraw), are not typically suitable for direct visualization.
Many visualization libraries, including matplotlib, would necessarily regard these as collections of patches of fixed size, supplying them to the underlying engine.
To optimize for repeated rendering, <code>yt</code> provides its own “pixelization” routines that take advantage of the input data structures.
These “pixelizers” (or “rasterizers”) can account for periodic data, variable resolution, overlapping and disjoint datasets, and non-Cartesian coordinate systems.</p>
<p>The pixelizers in <code>yt</code> are implemented in Cython, and they accept an input “image plane” buffer (with extent) as well as the variable mesh to be deposited.
Pixelizers exist for cartesian coordinates, cylindrical and spherical coordinates, off-axis cartesian planes, and for the Mollweide orthographic projection.
Each of these pixelizers follows a roughly identical process for depositing source pixels into the image plane.
The outer loop is over the input pixels, <span class="math inline">\(p_i\)</span>, composed of <span class="math inline">\(x_i, y_i, dx_i, dy_i, v_i\)</span>, where <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> refer to the coordinate system; in practice this means they may actually represent the <span class="math inline">\(r\)</span>, <span class="math inline">\(\theta\)</span>, <span class="math inline">\(\phi\)</span> or other coordinates.</p>
<ol type="1">
<li>Compute left and right edges of the bounding box for this pixel in the resolution of the image plane</li>
<li>Iterate over the first image plane coordinate from the left edge to the right edge of the bounding box</li>
<li>Iterate over the second image plane coordinate from the left edge to the right edge of the bounding box</li>
<li>Map from the coordinate system to the image plane and deposit <span class="math inline">\(v\)</span></li>
</ol>
<p>In practice, this is a fast operation, as long as the inner loops are sufficiently well determined; for instance, when depositing an input pixel with a width of <span class="math inline">\(w\)</span> into an image plane where the pixel width corresponds to a width of <span class="math inline">\(w/16\)</span>, only <span class="math inline">\(16^2\)</span> pixels (with a high-degree of sequential ordering) have to be iterated over.
The spherical and cylindrical pixelization routines operate similarly, but are somewhat degraded by a lower degree of locality in the final mapping from coordinate system to image plane.</p>
<p>Recent work has been done to port the pixelization routines to Rust and compiling these to WebAssembly, resulting in the development of the Widgyts project.
Widgyts provides a browser-side Jupyterlab interface to the pixelization routines, enabling extremely low-latency exploration of datasets.</p>
<h3 id="higher-order-unstructured-mesh-elements">Higher-Order Unstructured Mesh Elements</h3>
<h3 id="software-volume-rendering">Software Volume Rendering</h3>
<p>The volume rendering is based on classical concepts for rendering 3D objects, and relies on the notion of a scene, a camera and an object to render.
The object to render can be any data container of supported AMR datasets (either patch-based and octree-based datasets).
The implementation of the volume rendering is based on integrating a transfer function along the direction of ray.</p>
<h4 id="patch-based-ray-traversal">Patch-based ray traversal</h4>
<p>TODO</p>
<h4 id="octree-ray-traversal">Octree ray traversal</h4>
<p>Casting rays through an octree can be achieved efficiently by relying on the octree structure.
In order to abstract away the underlying layout of the data, we first construct an octree that contains all leaf cells in the data container.
We store all cells as octs with no children, and mark them with their position within the data container, going from <span class="math inline">\(0\)</span> to <span class="math inline">\(N_\mathrm{cell}-1\)</span>.
Octs that are inserted in the process of building the tree are not marked nor indexed.
We also compute the vertex-centered data for all cells in the container.
Note that, contrary to the octree utilized to index the data from octree datasets, this octree may span multiple domains and contains all levels from the root level (that contains a single oct the size of the simulation domain) all the way down to the leaf cells.
We then cast rays off the camera, and for each ray, we compute the ordered list of the <span class="math inline">\(N\)</span> cells it intersects with together with the intersection points along the ray <span class="citation" data-cites="FQhLVjwO">[<a href="#ref-FQhLVjwO" role="doc-biblioref">31</a>]</span>.
In the following, we will write the coordinate along the ray as <span class="math inline">\(t\)</span>, with the camera located at <span class="math inline">\(t=0\)</span>.
In general the tree may contain holes (this may happen if the data container is a region selector), so that the exit coordinate out of a cell may not coincide with the entry coordinate through the next cell. In practice, we solve this by storing for each cell both the entry and exit coordinates of the ray.</p>
<p>The algorithm relies on the fact that if a ray passes through an oct and intersects with its six faces at coordinate along the ray <span class="math inline">\(t_{xi}, t_{yi}, t_{zi}\)</span> (on entry) and <span class="math inline">\(t_{xo}, t_{yo}, t_{zo}\)</span> (on exit), then its intersection with the inner cells’ faces can be computed explicitly from these six values and their half point <span class="math inline">\((t_{xi}+t_{xo})/2, (t_{yi}+t_{yo})/2, (t_{zi}+t_{zo})/2\)</span>. This implies that each call to the algorithm only need computing one division and a few simple arithmetic comparisons.
It also uses the fact that for a given oct, we can compute which cell the ray will intersect with first, and from any given cell, which cell the the ray will intersect next.</p>
<p>The algorithm then works as follows. If the ray does not intersect with the root oct, then the algorithm returns an empty list of cell crossed and <span class="math inline">\(t\)</span> values.
Otherwise, initialize an empty list of cells traversed and <span class="math inline">\(t\)</span>-values. <em>a)</em> Find the intersection of the ray with all six faces of the oct. <em>b)</em> If the current oct is marked, store the entry and exit <span class="math inline">\(t\)</span>-values and the index of the oct in their respective list and return. <em>c)</em> If the current oct is not marked, find the first cell the ray intersects with and call the algorithm recursively (starting at step <em>a)</em> with the oct contained in the cell, if any). <em>d)</em> Find the next cell within the oct. If there is no next cell, return. Otherwise, call the algorithm recursively (starting at step <em>a)</em> with the oct contained in the cell, if any) then go back to <em>d)</em>.
On exit of the algorithm, we then have a list of cells and <span class="math inline">\(t\)</span>-values.
For each cell in the list, we then call the sampler with the vertex-centered values and the entry and exit coordinates.</p>
<p>An example of the volume rendering of a galaxy in a zoom-in cosmological simulation made with RAMSES is shown on Figure <a href="#fig:ramses-volume-rendering">19</a>.</p>
<div id="fig:ramses-volume-rendering" class="fignos">
<figure>
<img src="images/volume_rendering/ramses-volume-rendering-galaxy.png" alt="" /><figcaption><span>Figure 19:</span> Volume rendering of gas density isocontours around a galaxy in a cosmological zoom-in simulation performed with RAMSES. Adapted from <span class="citation" data-cites="zRE8zhVC">[<a href="#ref-zRE8zhVC" role="doc-biblioref">32</a>]</span>.</figcaption>
</figure>
</div>
<h4 id="sampling-functions">Sampling functions</h4>
<p>TODO</p>
<h3 id="hardware-accelerated-volume-rendering">Hardware-accelerated Volume Rendering</h3>
<h2 id="sec:units">Units and Quantities</h2>
<p>At a basic level, <code>yt</code> is an engine for converting data dumped to disk by a simulation code into a physically meaningful result.
Attaching units to simulation data makes it possible to perform dimensional analysis on the simulation data, adding additional opportunities for catching errors in a data processing pipeline.
In addition, it becomes straightforward to convert data from one unit system to another.</p>
<p>In <code>yt</code> 3.0 we handle units in a an automatic fashion, leveraging the symbolic math library <code>sympy</code>.
Instead of returning a NumPy <code>ndarray</code> when users query <code>yt</code> data objects for fields, return a <code>YTArray</code>, a subclass of <code>ndarray</code>.
<code>YTArray</code> preserves <code>ndarray</code>’s array operations, including deep and shallow copies, broadcasting, and views.
Augmenting <code>ndarray</code>, <code>YTArray</code> attaches unit metadata to the array data, enabling runtime checking of unit consistency in arithmetic operations between <code>YTArray</code> instances, and making it trivial to compose new units using algebraic operations.</p>
<p>As a trivial example, when one queries a data object (here given the generic name <code>dd</code>) for the density field, we get back a YTArray, including both the simulation data for the density field, and the units of the density field, in this case <span class="math inline">\(\rm{g}/\rm{cm}^3\)</span>:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="op">&gt;&gt;&gt;</span> dd[`density<span class="st">&#39;] </span></span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="st">YTArray([4.92e-31, 4.94e-31, 4.93e-31, ...,</span></span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="st">         1.12e-25, 1.59e-25, 1.09e-24]) g/cm**3</span></span></code></pre></div>
<p>One of the nicest aspects of this new unit system is that the symbolic algebra for unitful operations is performed automatically by sympy:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(dd[`cell_mass<span class="st">&#39;]/dd[`cell_volume&#39;</span>])</span>
<span id="cb5-2"><a href="#cb5-2"></a>  [<span class="fl">4.92e-31</span> <span class="fl">4.94e-31</span> <span class="fl">4.93e-31</span> ... </span>
<span id="cb5-3"><a href="#cb5-3"></a>   <span class="fl">1.12e-25</span> <span class="fl">1.59e-25</span> <span class="fl">1.09e-24</span>] g<span class="op">/</span>cm<span class="op">**</span><span class="dv">3</span></span></code></pre></div>
<p>YTArray is primarily useful for attaching units to NumPy <code>ndarray</code> instances.
For scalar data, we have created the new <code>YTQuantity</code> class.
<code>YTQuantity</code> is a subclass of <code>YTArray</code> with the requirement that the “array data” associated with the instance be limited to one element.
<code>YTQuantity</code> is primarily useful for physical constants and ensures that the units are propagated correctly when composing quantities from arrays, physical constants, and unitless scalars:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> yt.utilities.physical_constants <span class="im">import</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>        boltzmann_constant</span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(dd[`temperature<span class="st">&#39;]*boltzmann_constant)</span></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="st">[ 1.28e-12 1.29e-12 1.29e-12 ... </span></span>
<span id="cb6-5"><a href="#cb6-5"></a><span class="st">  1.63e-12 1.59e-12 1.40e-12] erg</span></span></code></pre></div>
<p>If a user needs the field in a different unit system, they can quickly convert using <code>convert_to_units</code> or <code>in_units</code>.</p>
<p>When a <code>Dataset</code> object is instantiated, it will its self instantiate and set up a <code>UnitRegistry</code> class that contains a full set of units that are defined for the simulation. This registry includes both concrete physical units like <code>cm</code> or <code>K</code> but also units symbols that correspond to the unit system used internally in the simulation.</p>
<p>The new unit systems lets us to encode the simulation coordinate system and scaling to physical coordinates directly into the unit system. We do this via “code units”.</p>
<p>Every <code>Dataset</code> has a <code>length_unit</code>, <code>time_unit</code>, and <code>mass_unit</code>, attribute that the user can quickly and easily query to discover the base units of the simulation. For example:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">import</span> yt</span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="op">&gt;&gt;&gt;</span> ds <span class="op">=</span> yt.load(<span class="st">&quot;Enzo_64/DD0043/data0043&quot;</span>)</span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(ds.length_unit)</span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="dv">128</span> Mpccm<span class="op">/</span>h</span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(ds.quan(<span class="fl">1.0</span>, <span class="st">&quot;code_length&quot;</span>).in_units(<span class="st">&quot;Mpccm/h&quot;</span>))</span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="dv">128</span> Mpccm<span class="op">/</span>h</span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(ds.length_unit.in_cgs())</span>
<span id="cb7-8"><a href="#cb7-8"></a><span class="fl">5.55517285026e+26</span> cm</span></code></pre></div>
<p>Optionally <code>velocity_unit</code>, <code>pressure_unit</code>, <code>temperature_unit</code>, and <code>density_unit</code> may be defined as well if the units for these fields cannot be inferred from the mass, length, and time units.</p>
<p>Additionally, we allow conversions to the simulation unit system.
Data in code units are available by converting to <code>code_length</code>, <code>code_mass</code>, <code>code_time</code>, <code>code_velocity</code>, <code>code_density</code>, <code>code_magnetic</code>, <code>code_pressure</code>, <code>code_metallicity</code>, or any combination of those units.
Code units preserve dimensionality: an array or quantity that has units of <code>cm</code> will be convertible to <code>code_length</code>, but not to <code>code_mass</code>.</p>
<p>On-disk data are also be available to the user, presented in unconverted code units.
To obtain on-disk data, a user need only query a data object using an on-disk field name:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">import</span> yt</span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="op">&gt;&gt;&gt;</span> ds <span class="op">=</span> yt.load(<span class="st">&quot;Enzo_64/DD0043/data0043&quot;</span>)</span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="op">&gt;&gt;&gt;</span> dd <span class="op">=</span> ds.all_data()</span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(dd[(<span class="st">&#39;enzo&#39;</span>, <span class="st">&#39;Density&#39;</span>)])</span>
<span id="cb8-5"><a href="#cb8-5"></a>[ <span class="fl">6.74e-02</span> <span class="fl">6.12e-02</span> <span class="fl">8.92e-02</span> ... </span>
<span id="cb8-6"><a href="#cb8-6"></a>  <span class="fl">9.09e+01</span> <span class="fl">5.66e+01</span> <span class="fl">4.27e+01</span>] code_mass<span class="op">/</span>code_length<span class="op">**</span><span class="dv">3</span></span>
<span id="cb8-7"><a href="#cb8-7"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(dd[(<span class="st">&#39;gas&#39;</span>, <span class="st">&#39;density&#39;</span>)])</span>
<span id="cb8-8"><a href="#cb8-8"></a>[ <span class="fl">1.92e-31</span> <span class="fl">1.74e-31</span> <span class="fl">2.54e-31</span> ... </span>
<span id="cb8-9"><a href="#cb8-9"></a>  <span class="fl">2.59e-28</span> <span class="fl">1.61e-28</span> <span class="fl">1.22e-28</span>] g<span class="op">/</span>cm<span class="op">**</span><span class="dv">3</span></span></code></pre></div>
<p>Here, the first data object query is returned in code units, while the second is returned in CGS units.
This is because <code>("enzo", "Density")</code> is an on-disk field, while <code>("gas", "density")</code> is an internal <code>yt</code> field.</p>
<h3 id="sec:units_implementation">Implementation}</h3>
<p>Our unit system has 6 base dimensions, <code>mass</code>, <code>length</code>, <code>time</code>, <code>temperature</code>, and <code>angle</code>.
The unitless <code>dimensionless</code> dimension, which we use to represent scalars is also technically a base dimension, although a trivial one.
For convenience, we also create dimensionless unit symbols to represent quantities like metallicity that are formally dimensionless, but it is convenient to represent in a unit system.</p>
<p>For each dimension, we choose a base unit.
Our system’s base units are grams, centimeters, seconds, Kelvin, and radian.
All units can be described as combinations of these base dimensions along with a conversion factor to equivalent base units.</p>
<p>The choice of CGS as the base unit system is somewhat arbitrary.
Most unit systems choose SI as the reference unit system.
We use CGS to stay consistent with the rest of the <code>yt</code> codebase and to reflect the standard practice in astrophysics.
In any case, using a <strong>physical</strong> coordinate system makes it possible to compare quantities and arrays produced by different datasets, possibly with different conversion factors to CGS and to code units.
We go into more detail on this point below.
In the future, we plan to make the preferred internal coordinate system a user-configurable option.</p>
<p>We provide sympy <code>Symbol</code> objects for the base dimensions.
The dimensionality of all other units should be <code>sympy</code> <code>Expr</code> objects made up of the base dimension objects and the <code>sympy</code> operation objects <code>Mul</code> and <code>Pow</code>.</p>
<p>Let’s use some common units as examples: gram (<code>g</code>), erg (<code>erg</code>), and solar mass per cubic megaparsec (<code>Msun / Mpc</code><span class="math inline">\(^3\)</span>).
<code>g</code> is an atomic, CGS base unit, <code>erg</code> is an atomic unit in CGS, but is not a base unit, and <code>Msun/Mpc</code><span class="math inline">\(^3\)</span> is a combination of atomic units, which are not in CGS, and one of them even has an SI prefix.
The dimensions of <code>g</code> are <code>mass</code> and the cgs factor is 1.
The dimensions of <code>erg</code> are <code>mass * length$^2</code>$ * <code>time</code><span class="math inline">\(^{-2}\)</span> and the cgs factor is 1.
The dimensions of <code>Msun/Mpc</code><span class="math inline">\(^3\)</span> are <code>mass / length</code><span class="math inline">\(^3\)</span> and the cgs factor is about 6.8e-41.</p>
<p>We use the <code>UnitRegistry</code> class to define all valid atomic units.
All unit registries contain a unit symbol lookup table (dict) containing the valid units’ dimensionality and cgs conversion factor.
Here is what it would look like with the above units:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a>{ <span class="st">&quot;g&quot;</span>:    (mass, <span class="fl">1.0</span>),</span>
<span id="cb9-2"><a href="#cb9-2"></a>  <span class="st">&quot;erg&quot;</span>:  (mass <span class="op">*</span> length<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> time<span class="op">**-</span><span class="dv">2</span>, <span class="fl">1.0</span>),</span>
<span id="cb9-3"><a href="#cb9-3"></a>  <span class="st">&quot;Msun&quot;</span>: (mass, <span class="fl">1.98892e+33</span>),</span>
<span id="cb9-4"><a href="#cb9-4"></a>  <span class="st">&quot;pc&quot;</span>:   (length, <span class="fl">3.08568e18</span>), }</span></code></pre></div>
<p>Note that we only define <strong>atomic</strong> units here.
There should be no operations in the registry symbol strings.
When we parse non-atomic units like <code>Msun/Mpc**3</code>, we use the registry to look up the symbols.
The unit system in yt knows how to handle units like <code>Mpc</code> by looking up unit symbols with and without prefixes and modify the conversion factor appropriately.</p>
<p>We construct a <code>Unit</code> object by providing a string containing atomic unit symbols, combined with operations in Python syntax, and the registry those atomic unit symbols are defined in.
We use sympy’s string parsing features to create the unit expression from the user-provided string.</p>
<p><code>Unit</code> objects are associated with four instance members, a unit <code>Expression</code> object, a dimensionality <code>Expression</code> object, a <code>UnitRegistry</code> instance, and a scalar conversion factor to CGS units.
These data are available for a <code>Unit</code> object by accessing the <code>expr</code>, <code>dimensions</code>, <code>registry</code>, and <code>cgs_value</code> attributes, respectively.</p>
<p><code>Unit</code> provides the methods <code>same_dimensions_as</code>, which returns True if passed a <code>Unit</code> object that has equivalent dimensions, <code>get_cgs_equivalent</code>, which returns the equivalent cgs base units of the <code>Unit</code>, and the <code>is_code_unit</code> property, which is <code>True</code> if the unit is composed purely of code units and <code>False</code> otherwise.
<code>Unit</code> also defines the <code>mul</code>, <code>div</code>, <code>pow</code>, and <code>eq</code> operations with other unit objects, making it easy to compose compound units algebraically.</p>
<p>The <code>UnitRegistry</code> class provides the <code>add</code>, <code>remove</code>, and <code>modify</code> methods which allows users to add, remove, and modify atomic unit definitions present in <code>UnitRegistry</code> objects.
A dictionary lookup table is also attached to the <code>UnitRegistry</code> object, providing an interface to look up unit symbols.
In general, unit registries should only be adjusted inside of a code frontend, since otherwise quantities and arrays might be created with inconsistent unit metadata.
Once a unit object is created, it will not receive updates if the original unit registry is modified.</p>
<h3 id="sec:creating-ytarray-and-ytquantity-instances">Creating YTArray and YTQuantity instances</h3>
<p>There are two ways to create new array and quantity objects: via a constructor, and by multiplying scalar data by a unit quantity.</p>
<h4 id="sec:class-constructor">Class Constructor</h4>
<p>The primary internal interface for creating new arrays and quantities is through the class constructor for YTArray.
The constructor takes three arguments.
The first argument is the input scalar data, which can be an integer, float, list, or array.
The second argument, <code>input_units</code>, is a unit specification which must be a string or <code>Unit</code> instance.
Last, users may optionally supply a UnitRegistry instance, which will be attached to the array.
If no UnitRegistry is supplied, a default unit registry is used instead.
Unit specification strings must be algebraic combinations of unit symbol names, using standard Python mathematical syntax (i.e.
<code>**</code> for the power function, not <code>^</code>).</p>
<p>Here is a simple example of <code>YTArray</code> creation:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> yt.units <span class="im">import</span> yt_array, YTQuantity </span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="op">&gt;&gt;&gt;</span> YTArray([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], `cm<span class="st">&#39;) </span></span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="st">YTArray([1, 2, 3]) cm</span></span>
<span id="cb10-4"><a href="#cb10-4"></a><span class="st">&gt;&gt;&gt; YTQuantity(3, `J&#39;</span>) </span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="dv">3</span> J</span></code></pre></div>
<p>In addition to the class constructor, we have also defined two convenience functions, <code>quan</code>, and <code>arr</code>, for quantity and array creation that are attached to the <code>Dataset</code> base class.
These were added to syntactically simplify the creation of arrays with the UnitRegistry instance associated with a dataset.
These functions work exactly like the <code>YTArray</code> and <code>YTQuantity</code> constructors, but pass the <code>UnitRegistry</code> instance attached to the dataset to the underlying constructor call.
For example:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">import</span> yt</span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="op">&gt;&gt;&gt;</span> ds <span class="op">=</span> yt.load(<span class="st">&quot;Enzo_64/DD0043/data0043&quot;</span>)</span>
<span id="cb11-3"><a href="#cb11-3"></a><span class="op">&gt;&gt;&gt;</span> ds.arr([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], `code_length<span class="st">&#39;).in_cgs() </span></span>
<span id="cb11-4"><a href="#cb11-4"></a><span class="st">YTArray([ 5.55e+26, 1.11e+27, 1.66e+27]) cm</span></span></code></pre></div>
<p>This example illustrates that the array is being created using <code>ds.unit_registry</code>, rather than the <code>default_unit_registry</code>, for which <code>code_length</code> is equivalent to <code>cm</code>.</p>
<h4 id="sec:multiplication">Multiplication</h4>
<p>New <code>YTArray</code> and <code>YTQuantity</code> instances can also be created by multiplying <code>YTArray</code> or <code>YTQuantity</code> instances by <code>float</code> or <code>ndarray</code> instances.
To make it easier to create arrays using this mechanism, we have populated the <code>yt.units</code> namespace with predefined <code>YTQuantity</code> instances that correspond to common unit symbol names.
For example:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> yt.units <span class="im">import</span> meter, gram, kilogram, second, joule </span>
<span id="cb12-2"><a href="#cb12-2"></a><span class="op">&gt;&gt;&gt;</span> kilogram <span class="op">*</span> meter<span class="op">**</span><span class="dv">2</span> <span class="op">==</span> joule </span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="va">True</span></span>
<span id="cb12-4"><a href="#cb12-4"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> yt.units <span class="im">import</span> m, kg, s, W </span>
<span id="cb12-5"><a href="#cb12-5"></a><span class="op">&gt;&gt;&gt;</span> kg<span class="op">*</span>m<span class="op">**</span><span class="dv">2</span><span class="op">/</span>s<span class="op">**</span><span class="dv">3</span> <span class="op">==</span> W</span>
<span id="cb12-6"><a href="#cb12-6"></a><span class="va">True</span></span>
<span id="cb12-7"><a href="#cb12-7"></a></span>
<span id="cb12-8"><a href="#cb12-8"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> yt.units <span class="im">import</span> kilometer </span>
<span id="cb12-9"><a href="#cb12-9"></a><span class="op">&gt;&gt;&gt;</span> three_kilometers <span class="op">=</span> <span class="dv">3</span><span class="op">*</span>kilometer </span>
<span id="cb12-10"><a href="#cb12-10"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(three_kilometers)</span>
<span id="cb12-11"><a href="#cb12-11"></a><span class="fl">3.0</span> km</span>
<span id="cb12-12"><a href="#cb12-12"></a></span>
<span id="cb12-13"><a href="#cb12-13"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> yt.units <span class="im">import</span> gram, kilogram </span>
<span id="cb12-14"><a href="#cb12-14"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(gram<span class="op">+</span>kilogram)</span>
<span id="cb12-15"><a href="#cb12-15"></a><span class="fl">1001.0</span> g </span>
<span id="cb12-16"><a href="#cb12-16"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(kilogram<span class="op">+</span>gram)</span>
<span id="cb12-17"><a href="#cb12-17"></a><span class="fl">1.001</span> kg </span>
<span id="cb12-18"><a href="#cb12-18"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(kilogram<span class="op">/</span>gram)</span>
<span id="cb12-19"><a href="#cb12-19"></a><span class="fl">1000.0</span> dimensionless</span></code></pre></div>
<h3 id="sec:handling-code-units">Handling code units</h3>
<p>Code units are tightly coupled to on-disk parameters.
To handle this fact of life, the <code>yt</code> unit system can modify, add, and remove unit symbols via the <code>UnitRegistry</code>.</p>
<h4 id="sec:associating-arrays-with-a-coordinate-system">Associating arrays with a coordinate system</h4>
<p>To create quantities and arrays in units defined by a simulation coordinate system, we associate a <code>UnitRegistry</code> instance with <code>Dataset</code> instances.
This unit registry contains the metadata necessary to convert the array to CGS from some other known unit system and is available via the <code>unit_registry</code> attribute that is attached to all <code>Dataset</code> instances.</p>
<p>We have modified the definition for <code>set_code_units</code> in the <code>StaticOutput</code> base class.
In this new implementation, the predefined <code>code_mass</code>, <code>code_length</code>, <code>code_time</code>, and <code>code_velocity</code> symbols are adjusted to the appropriate values and <code>length_unit</code>, <code>time_unit</code>, <code>mass_unit</code>, <code>velocity_unit</code> attributes are attached to the <code>StaticOutput</code> instance.
If there are frontend specific code units they should also be defined in subclasses by extending this function.</p>
<h4 id="sec:mixing-modified-unit-registries">Mixing modified unit registries</h4>
<p>It becomes necessary to consider mixing unit registries whenever data needs to be compared between disparate datasets.
The most straightforward example where this comes up is a cosmological simulation time series, where the code units evolve with time.
The problem is quite general — we want to be able to compare any two datasets, even if they are unrelated.</p>
<p>We have designed the unit system to refer to a physical coordinate system based on CGS conversion factors.
This means that operations on quantities with different unit registries will always agree since the final calculation is always performed in CGS.</p>
<p>The examples below illustrate the consistency of this choice:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">import</span> yt</span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="op">&gt;&gt;&gt;</span> ds1 <span class="op">=</span> yt.load(`Enzo_64<span class="op">/</span>DD0002<span class="op">/</span>data0002<span class="st">&#39;)</span></span>
<span id="cb13-3"><a href="#cb13-3"></a><span class="st">&gt;&gt;&gt; ds2 = yt.load(`Enzo_64/DD0043/data0043&#39;</span>)</span>
<span id="cb13-4"><a href="#cb13-4"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(ds1.length_unit, ds2.length_unit)</span>
<span id="cb13-5"><a href="#cb13-5"></a><span class="dv">128</span> Mpccm<span class="op">/</span>h, <span class="dv">128</span> Mpccm<span class="op">/</span>h</span>
<span id="cb13-6"><a href="#cb13-6"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(ds1.length_unit.in_cgs())</span>
<span id="cb13-7"><a href="#cb13-7"></a><span class="fl">6.26145538088e+25</span> cm</span>
<span id="cb13-8"><a href="#cb13-8"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(ds2.length_unit.in_cgs())</span>
<span id="cb13-9"><a href="#cb13-9"></a><span class="fl">5.55517285026e+26</span> cm </span>
<span id="cb13-10"><a href="#cb13-10"></a></span>
<span id="cb13-11"><a href="#cb13-11"></a></span>
<span id="cb13-12"><a href="#cb13-12"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(ds1.length_unit<span class="op">*</span>ds2.length_unit)</span>
<span id="cb13-13"><a href="#cb13-13"></a><span class="fl">145359.100149</span> Mpccm<span class="op">**</span><span class="dv">2</span></span>
<span id="cb13-14"><a href="#cb13-14"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(ds2.length_unit<span class="op">*</span>ds1.length_unit)</span>
<span id="cb13-15"><a href="#cb13-15"></a><span class="fl">1846.7055432</span> Mpccm<span class="op">**</span><span class="dv">2</span></span></code></pre></div>
<p>For the last two examples, the answer is not the seemingly trivial <span class="math inline">\(128^2=16384,\rm{Mpccm}^2/h^2\)</span>.
This is because the new quantity returned by the multiplication operation inherits the unit registry from the left object in binary operations.
This convention is enforced for all binary operations on two <code>YTarray</code> objects.
Results are always consistent when referencing an unambiguous physical coordinate system:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>((pf1.length_unit <span class="op">*</span> pf2.length_unit).in_cgs())</span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="fl">3.4783466935e+52</span> cm<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb14-3"><a href="#cb14-3"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(pf1.length_unit.in_cgs() <span class="op">*</span> pf2.length_unit.in_cgs())</span>
<span id="cb14-4"><a href="#cb14-4"></a><span class="fl">3.4783466935e+52</span> cm<span class="op">**</span><span class="dv">2</span></span></code></pre></div>
<h3 id="sec:handling-cosmological-units">Handling cosmological units</h3>
<p>If we detect that we are loading a cosmological simulation performed in comoving coordinates, extra comoving units are added to the dataset’s unit registry.
Comoving length unit symbols are still named following the pattern <code>&lt;length symbol&gt;cm</code>, i.e.
<code>Mpccm</code>.</p>
<p>The <span class="math inline">\(h\)</span> symbol is treated as a base unit, <code>h</code>, which defaults to unity.
The <code>Dataset.set_units</code> updates the <code>h</code> symbol to the correct value when loading a cosmological simulation.</p>
<h2 id="user-friendliness">User-Friendliness</h2>
<h3 id="publication-ready-figures">Publication-Ready Figures</h3>
<h3 id="jupyter-integration">Jupyter Integration</h3>
<h2 id="halo-finding-and-catalogs">Halo-Finding and Catalogs</h2>
<h2 id="scaling-and-parallelism">Scaling and Parallelism</h2>
<h3 id="performance-of-operations">Performance of Operations</h3>
<h3 id="inline-analysis">Inline Analysis</h3>
<h3 id="simple-parallelism">Simple Parallelism</h3>
<h2 id="analysis-modules">Analysis Modules</h2>
<h2 id="extensions-and-ecosystem">Extensions and Ecosystem</h2>
<h3 id="trident">Trident</h3>
<p>Trident <span class="citation" data-cites="1DgKJy4lE">[<a href="#ref-1DgKJy4lE" role="doc-biblioref">33</a>]</span> is a Python-based open-source tool for post-processing hydrodynamical simulations to produce synthetic absorption spectra and related data.
In many ways, Trident is the first external package that utilizes <code>yt</code> to provide data access and numerical operations, but then builds on those to develop detailed, astrophysically-aware systems for processing and analyzing that data.</p>
<h3 id="powderday">Powderday</h3>
<p><span class="citation" data-cites="1CgEbr6CQ">[<a href="#ref-1CgEbr6CQ" role="doc-biblioref">34</a>]</span></p>
<h3 id="ytree">ytree</h3>
<p>Building on <code>yt</code> for access to halo catalogs, and implementing a similar system for derived fields as applied to graph datasets, ytree <span class="citation" data-cites="VB3RIyxd">[<a href="#ref-VB3RIyxd" role="doc-biblioref">35</a>]</span> is a system for analyzing merger trees from analysis of dark matter halos in cosmological simulations.</p>
<p>ytree provides flexibility in determining the path that a given analysis takes through the graph of merger trees; for instance, it enables the user to select if they wish to follow the “most massive” progenitor halo backwards in time, or even to set their own criteria for this.
Connecting this to the raw, unprocessed data from the simulation (such as the unsampled particle or cell content that comprises the halos) allows researchers to deepen and guide their analysis based on the physical characteristics of the merger history.</p>
<h2 id="future-directions">Future Directions</h2>
<h2 id="sec:sustainability">Sustainability</h2>
<h2 class="page_break_before" id="references">References</h2>
<!-- Explicitly insert bibliography here -->
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-cTN2TQIL">
<p>1. <strong>manubot/manubot</strong> <br />
Manubot<br />
(2021-04-14) <a href="https://github.com/manubot/manubot">https://github.com/manubot/manubot</a></p>
</div>
<div id="ref-1GOm01ggN">
<p>2. <strong>yt: A MULTI-CODE ANALYSIS TOOLKIT FOR ASTROPHYSICAL SIMULATION DATA</strong> <br />
Matthew J. Turk, Britton D. Smith, Jeffrey S. Oishi, Stephen Skory, Samuel W. Skillman, Tom Abel, Michael L. Norman<br />
<em>The Astrophysical Journal Supplement Series</em> (2011-01-01) <a href="https://doi.org/ft6md2">https://doi.org/ft6md2</a> <br />
DOI: <a href="https://doi.org/10.1088/0067-0049/192/1/9">10.1088/0067-0049/192/1/9</a></p>
</div>
<div id="ref-xbCL1tS1">
<p>3. <strong>Petascale Cosmology: Simulations of Structure Formation</strong> <br />
Rupert Croft, Tiziana Di Matteo, Nishikanta Khandai<br />
<em>Comput. Sci. Eng.</em> (2015-03) <a href="http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7006381">http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7006381</a> <br />
DOI: <a href="https://doi.org/10.1109/MCSE.2015.5">10.1109/mcse.2015.5</a></p>
</div>
<div id="ref-gw5rMEhN">
<p>4. <strong>The LSST Data Management System</strong> <br />
Mario Jurić, Jeffrey Kantor, K-T Lim, Robert H. Lupton, Gregory Dubois-Felsmann, Tim Jenness, Tim S. Axelrod, Jovan Aleksić, Roberta A. Allsman, Yusra AlSayyad, … LSST Project<br />
<em>eprint arXiv:1512.07914</em> (2015) <a href="http://adsabs.harvard.edu/abs/2015arXiv151207914J">http://adsabs.harvard.edu/abs/2015arXiv151207914J</a></p>
</div>
<div id="ref-PSH5f9xg">
<p>5. <strong>A computer oriented geodetic data base and a new technique in file sequencing</strong> <br />
G. M. Morton<br />
<em>IBM Ltd.</em> (1996)</p>
</div>
<div id="ref-oIYFC4kD">
<p>6. <strong>Gesammelte Abhandlungen: Band III: Analysis - Grundlagen der Mathematik Physik - Verschiedenes Lebensgeschichte</strong> <br />
David Hilbert<br />
<em>Springer Berlin Heidelberg</em> (1970) <a href="http://dx.doi.org/10.1007/978-3-662-25726-5%7B\_%7D1">http://dx.doi.org/10.1007/978-3-662-25726-5{\_}1</a> <br />
DOI: <a href="https://doi.org/10.1007/978-3-662-25726-5_1">10.1007/978-3-662-25726-5_1</a> · ISBN: <a href="https://worldcat.org/isbn/978-3-662-25726-5">978-3-662-25726-5</a></p>
</div>
<div id="ref-I01oLUIj">
<p>7. <strong>The cosmological simulation code gadget-2</strong> <br />
Volker Springel<br />
<em>Mon. Not. R. Astron. Soc.</em> (2005-12) <a href="http://adsabs.harvard.edu/abs/2005MNRAS.364.1105S">http://adsabs.harvard.edu/abs/2005MNRAS.364.1105S</a> <br />
DOI: <a href="https://doi.org/10.1111/j.1365-2966.2005.09655.x">10.1111/j.1365-2966.2005.09655.x</a></p>
</div>
<div id="ref-1D5nekPGx">
<p>8. <strong>Cosmological Hydrodynamics with Adaptive Mesh Refinement: a new high resolution code called RAMSES</strong> <br />
Romain Teyssier<br />
<em>Astron. Astrophys. v.385, p.337-364</em> (2001-11) <a href="http://arxiv.org/abs/astro-ph/0111367%20http://dx.doi.org/10.1051/0004-6361:20011817">http://arxiv.org/abs/astro-ph/0111367 http://dx.doi.org/10.1051/0004-6361:20011817</a> <br />
DOI: <a href="https://doi.org/10.1051/0004-6361:20011817">10.1051/0004-6361:20011817</a></p>
</div>
<div id="ref-LpXfagAT">
<p>9. <strong>Speeding up construction of PMR quadtree-based spatial indexes</strong> <br />
Gisli R. Hjaltason, Hanan Samet<br />
<em>VLDB J. Int. J. Very Large Data Bases</em> (2002-10) <a href="http://link.springer.com/10.1007/s00778-002-0067-8">http://link.springer.com/10.1007/s00778-002-0067-8</a> <br />
DOI: <a href="https://doi.org/10.1007/s00778-002-0067-8">10.1007/s00778-002-0067-8</a></p>
</div>
<div id="ref-12vJ72aHG">
<p>10. <strong>Fast construction of k-nearest neighbor graphs for point clouds.</strong> <br />
Michael Connor, Piyush Kumar<br />
<em>IEEE Trans. Vis. Comput. Graph.</em> (2010-01) <a href="http://www.ncbi.nlm.nih.gov/pubmed/20467058">http://www.ncbi.nlm.nih.gov/pubmed/20467058</a> <br />
DOI: <a href="https://doi.org/10.1109/TVCG.2010.9">10.1109/tvcg.2010.9</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20467058">20467058</a></p>
</div>
<div id="ref-4mimKxQe">
<p>11. <strong>A class of data structures for associative searching</strong> <br />
J. A. Orenstein, T. H. Merrett<br />
<em>Proc. 3rd acm sigact-sigmod symp. Princ. Database syst. - pod. ’84</em> (1984-04) <a href="http://dl.acm.org/citation.cfm?id=588011.588037">http://dl.acm.org/citation.cfm?id=588011.588037</a> <br />
DOI: <a href="https://doi.org/10.1145/588011.588037">10.1145/588011.588037</a> · ISBN: <a href="https://worldcat.org/isbn/0897911288">0897911288</a></p>
</div>
<div id="ref-f1rS5tZk">
<p>12. <strong>Encoded bitmap indexing for data warehouses</strong> <br />
Ming-Chuan Wu, A. P. Buchmann<br />
<em>Proc. 14th int. Conf. Data eng.</em> (1998) <a href="http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=655780">http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=655780</a> <br />
DOI: <a href="https://doi.org/10.1109/ICDE.1998.655780">10.1109/icde.1998.655780</a> · ISBN: <a href="https://worldcat.org/isbn/0-8186-8289-2">0-8186-8289-2</a></p>
</div>
<div id="ref-YV4eT8wZ">
<p>13. <strong>Bitmap index design and evaluation</strong> <br />
Chee-Yong Chan, Yannis E. Ioannidis<br />
<em>ACM SIGMOD Rec.</em> (1998-06) <a href="http://dl.acm.org/citation.cfm?id=276305.276336">http://dl.acm.org/citation.cfm?id=276305.276336</a> <br />
DOI: <a href="https://doi.org/10.1145/276305.276336">10.1145/276305.276336</a> · ISBN: <a href="https://worldcat.org/isbn/0-89791-995-5">0-89791-995-5</a></p>
</div>
<div id="ref-DMkimxcD">
<p>14. <strong>An efficient bitmap encoding scheme for selection queries</strong> <br />
Chee-Yong Chan, Yannis E. Ioannidis<br />
<em>ACM SIGMOD Rec.</em> (1999-06) <a href="http://dl.acm.org/citation.cfm?id=304181.304201">http://dl.acm.org/citation.cfm?id=304181.304201</a> <br />
DOI: <a href="https://doi.org/10.1145/304181.304201">10.1145/304181.304201</a> · ISBN: <a href="https://worldcat.org/isbn/1-58113-084-8">1-58113-084-8</a></p>
</div>
<div id="ref-itaUSTKC">
<p>15. <strong>Evaluating Geospatial Geometry and Proximity Queries Using Distributed Hash Tables</strong> <br />
Matthew Malensek, Sangmi Pallickara, Shrideep Pallickara<br />
<em>Comput. Sci. Eng.</em> (2014-07) <a href="http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6785924">http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6785924</a> <br />
DOI: <a href="https://doi.org/10.1109/MCSE.2014.48">10.1109/mcse.2014.48</a></p>
</div>
<div id="ref-QMaCupmb">
<p>16. <strong>Bitmap indexes for large scientific data sets: a case study</strong> <br />
R. R. Sinha, S. Mitra, M. Winslett<br />
<em>Proc. 20th ieee int. Parallel distrib. Process. Symp.</em> (2006) <a href="http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1639304">http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1639304</a> <br />
DOI: <a href="https://doi.org/10.1109/IPDPS.2006.1639304">10.1109/ipdps.2006.1639304</a> · ISBN: <a href="https://worldcat.org/isbn/1-4244-0054-6">1-4244-0054-6</a></p>
</div>
<div id="ref-mMJ3UeWp">
<p>17. <strong>Multi-resolution bitmap indexes for scientific data</strong> <br />
Rishi Rakesh Sinha, Marianne Winslett<br />
<em>ACM Trans. Database Syst.</em> (2007-08) <a href="http://portal.acm.org/citation.cfm?doid=1272743.1272746">http://portal.acm.org/citation.cfm?doid=1272743.1272746</a> <br />
DOI: <a href="https://doi.org/10.1145/1272743.1272746">10.1145/1272743.1272746</a></p>
</div>
<div id="ref-VzYAeBg3">
<p>18. <strong>Improving the Performance of High-Energy Physics Analysis through Bitmap Indices</strong> <br />
Kurt Stockinger, Dirk Duellmann, Wolfgang Hoschek, Erich Schikuta<br />
<em>Database expert syst. Appl. 11th int. Conf. DEXA 2000 london, uk, sept. 4–8, 2000 proc.</em> (2000-06) <a href="http://link.springer.com/10.1007/3-540-44469-6">http://link.springer.com/10.1007/3-540-44469-6</a> <br />
DOI: <a href="https://doi.org/10.1007/3-540-44469-6">10.1007/3-540-44469-6</a> · ISBN: <a href="https://worldcat.org/isbn/978-3-540-67978-3">978-3-540-67978-3</a></p>
</div>
<div id="ref-AFyCFou3">
<p>19. <strong>Using bitmap index for interactive exploration of large datasets</strong> <br />
Kesheng Wu, W. Koegler, J. Chen, A. Shoshani<br />
<em>15th int. Conf. Sci. Stat. Database manag. 2003.</em> (2003) <a href="http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1214955">http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1214955</a> <br />
DOI: <a href="https://doi.org/10.1109/SSDM.2003.1214955">10.1109/ssdm.2003.1214955</a> · ISBN: <a href="https://worldcat.org/isbn/0-7695-1964-4">0-7695-1964-4</a></p>
</div>
<div id="ref-Sju7gfgZ">
<p>20. <strong>Range-based bitmap indexing for high cardinality attributes with skew</strong> <br />
P. S. Yu<br />
<em>Proceedings. Twenty-second annu. Int. Comput. Softw. Appl. Conf. (Compsac ’98) (cat. No.98CB 36241)</em> (1998) <a href="http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=716637">http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=716637</a> <br />
DOI: <a href="https://doi.org/10.1109/CMPSAC.1998.716637">10.1109/cmpsac.1998.716637</a> · ISBN: <a href="https://worldcat.org/isbn/0-8186-8585-9">0-8186-8585-9</a></p>
</div>
<div id="ref-uibMnWfE">
<p>21. <strong>Multidimensional indexing and query coordination for tertiary storage management</strong> <br />
A. Shoshani, L. M. Bernardo, H. Nordberg, D. Rotem, A. Sim<br />
<em>Proceedings. Elev. Int. Conf. Sci. Stat. Database manag.</em> (1999) <a href="http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=787637">http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=787637</a> <br />
DOI: <a href="https://doi.org/10.1109/SSDM.1999.787637">10.1109/ssdm.1999.787637</a> · ISBN: <a href="https://worldcat.org/isbn/0-7695-0046-3">0-7695-0046-3</a></p>
</div>
<div id="ref-pe5S32KG">
<p>22. <strong>Evaluation Strategies for Bitmap Indices with Binning</strong> <br />
Kurt Stockinger, Kesheng Wu, Arie Shoshani<br />
<em>Database expert syst. Appl. 15th int. Conf. DEXA 2004, zaragoza, spain, august 30-september 3, 2004. Proc.</em> (2004) <a href="http://dx.doi.org/10.1007/978-3-540-30075-5%7B\_%7D12">http://dx.doi.org/10.1007/978-3-540-30075-5{\_}12</a> <br />
DOI: <a href="https://doi.org/10.1007/978-3-540-30075-5_12">10.1007/978-3-540-30075-5_12</a> · ISBN: <a href="https://worldcat.org/isbn/978-3-540-30075-5">978-3-540-30075-5</a></p>
</div>
<div id="ref-yuSdhiDQ">
<p>23. <strong>Compressed bitmap indices for efficient query processing</strong> <br />
Kesheng Wu, Ekow Otoo, Arie Shoshani<br />
<em>Lawrence Berkeley Natl. Lab.</em> (2001-09) <a href="http://escholarship.org/uc/item/8k22w7q2">http://escholarship.org/uc/item/8k22w7q2</a></p>
</div>
<div id="ref-zXsFmNjY">
<p>24. <strong>Sorting improves word-aligned bitmap indexes</strong> <br />
Daniel Lemire, Owen Kaser, Kamel Aouiche<br />
<em>Data Knowl. Eng.</em> (2010-01) <a href="http://dl.acm.org/citation.cfm?id=1663645.1663682">http://dl.acm.org/citation.cfm?id=1663645.1663682</a> <br />
DOI: <a href="https://doi.org/10.1016/j.datak.2009.08.006">10.1016/j.datak.2009.08.006</a></p>
</div>
<div id="ref-2qfATif3">
<p>25. <strong>Compressed bitmap indexes: beyond unions and intersections</strong> <br />
Owen Kaser, Daniel Lemire<br />
<em>Softw. Pract. Exp.</em> (2016-02) <a href="http://doi.wiley.com/10.1002/spe.2289">http://doi.wiley.com/10.1002/spe.2289</a> <br />
DOI: <a href="https://doi.org/10.1002/spe.2289">10.1002/spe.2289</a></p>
</div>
<div id="ref-1C6sv2xA4">
<p>26. <strong>Smoothed Particle Hydrodynamics</strong> <br />
J. J. Monaghan<br />
<em>Annu. Rev. Astron. Astrophys.</em> (1992-09) <a href="http://adsabs.harvard.edu/abs/1992ARA%7B\&amp;%7DA..30..543M">http://adsabs.harvard.edu/abs/1992ARA{\&amp;}A..30..543M</a> <br />
DOI: <a href="https://doi.org/10.1146/annurev.aa.30.090192.002551">10.1146/annurev.aa.30.090192.002551</a></p>
</div>
<div id="ref-DQa79Dfo">
<p>27. <strong>GADGET: a code for collisionless and gasdynamical cosmological simulations</strong> <br />
Volker Springel, Naoki Yoshida, Simon D. M. White<br />
<em>New Astron.</em> (2001-04) <a href="http://adsabs.harvard.edu/abs/2001NewA....6...79S">http://adsabs.harvard.edu/abs/2001NewA....6...79S</a> <br />
DOI: <a href="https://doi.org/10.1016/S1384-1076(01)00042-2">10.1016/s1384-1076(01)00042-2</a></p>
</div>
<div id="ref-18bL4U0kM">
<p>28. <strong>A new class of accurate, mesh-free hydrodynamic simulation methods</strong> <br />
P. F. Hopkins<br />
<em>Mon. Not. R. Astron. Soc.</em> (2015-04) <a href="http://adsabs.harvard.edu/abs/2014arXiv1409.7395H">http://adsabs.harvard.edu/abs/2014arXiv1409.7395H</a> <br />
DOI: <a href="https://doi.org/10.1093/mnras/stv195">10.1093/mnras/stv195</a></p>
</div>
<div id="ref-GqCvYs0n">
<p>29. <strong>yt: A MULTI-CODE ANALYSIS TOOLKIT FOR ASTROPHYSICAL SIMULATION DATA</strong> <br />
Matthew J. Turk, Britton D. Smith, Jeffrey S. Oishi, Stephen Skory, Samuel W. Skillman, Tom Abel, Michael L. Norman<br />
<em>Astrophys. J. Suppl. Ser.</em> (2011-01) <a href="http://stacks.iop.org/0067-0049/192/i=1/a=9?key=crossref.ad58f4fc8c6272d93975507bf0238006">http://stacks.iop.org/0067-0049/192/i=1/a=9?key=crossref.ad58f4fc8c6272d93975507bf0238006</a> <br />
DOI: <a href="https://doi.org/10.1088/0067-0049/192/1/9">10.1088/0067-0049/192/1/9</a></p>
</div>
<div id="ref-RNeSxk82">
<p>30. <strong>Cython: The Best of Both Worlds</strong> <br />
Stefan Behnel, Robert Bradshaw, Craig Citro, Lisandro Dalcin, Dag Sverre Seljebotn, Kurt Smith<br />
<em>Comput. Sci. Eng.</em> (2011-03) <a href="http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5582062">http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5582062</a> <br />
DOI: <a href="https://doi.org/10.1109/MCSE.2010.118">10.1109/mcse.2010.118</a></p>
</div>
<div id="ref-FQhLVjwO">
<p>31. <strong>An Efficient Parametric Algorithm for Octree Traversal</strong> <br />
Jorge Revelles, Carlos Ureña, Miguel Lastra<br />
<em>Journal of WSCG</em> <a href="http://wscg.zcu.cz/wscg2000/Papers_2000/X31.pdf">http://wscg.zcu.cz/wscg2000/Papers_2000/X31.pdf</a></p>
</div>
<div id="ref-zRE8zhVC">
<p>32. <strong>Gravitational torques dominate the dynamics of angular momentum of the accreted gas at $z&gt;2$</strong> <br />
Corentin Cadiou, Yohan Dubois, Christophe Pichon<br />
<em>in prep.</em></p>
</div>
<div id="ref-1DgKJy4lE">
<p>33. <strong>Trident: A Universal Tool for Generating Synthetic Absorption Spectra from Astrophysical Simulations</strong> <br />
Cameron B. Hummels, Britton D. Smith, Devin W. Silvia<br />
<em>The Astrophysical Journal</em> (2017-09-20) <a href="https://doi.org/gcx4th">https://doi.org/gcx4th</a> <br />
DOI: <a href="https://doi.org/10.3847/1538-4357/aa7e2d">10.3847/1538-4357/aa7e2d</a></p>
</div>
<div id="ref-1CgEbr6CQ">
<p>34. <strong>The formation of submillimetre-bright galaxies from gas infall over a billion years</strong> <br />
Desika Narayanan, Matthew Turk, Robert Feldmann, Thomas Robitaille, Philip Hopkins, Robert Thompson, Christopher Hayward, David Ball, Claude-André Faucher-Giguère, Dušan Kereš<br />
<em>Nature</em> (2015-09-23) <a href="https://doi.org/f7r445">https://doi.org/f7r445</a> <br />
DOI: <a href="https://doi.org/10.1038/nature15383">10.1038/nature15383</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26399829">26399829</a></p>
</div>
<div id="ref-VB3RIyxd">
<p>35. <strong>Ytree: Merger-Tree Toolkit</strong> <br />
Britton Smith, Meagan Lang<br />
<em>Zenodo</em> (2018-02-16) <a href="https://doi.org/gcx4x2">https://doi.org/gcx4x2</a> <br />
DOI: <a href="https://doi.org/10.5281/zenodo.1174374">10.5281/zenodo.1174374</a></p>
</div>
</div>
<h2 id="conclusions">Conclusions</h2>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>The authors of this paper would like to extend their deepest gratitude to the many, many individual and institutions that have contributed, directly or indirectly, to the growth of both <code>yt</code> and the <code>yt</code> community.</p>
<p>We particularly thank KIPAC and SLAC at Stanford, the University of California at San Diego and Santa Cruz, the High-Performance Astro Computing Center, Columbia University, the University of Illinois, University of Colorado at Boulder, University of Edinburgh, the scientific python community, NumFOCUS,</p>
<!-- default theme -->

<style>
    /* import google fonts */
    @import url("https://fonts.googleapis.com/css?family=Open+Sans:400,600,700");
    @import url("https://fonts.googleapis.com/css?family=Source+Code+Pro");

    /* -------------------------------------------------- */
    /* global */
    /* -------------------------------------------------- */

    /* all elements */
    * {
        /* force sans-serif font unless specified otherwise */
        font-family: "Open Sans", "Helvetica", sans-serif;

        /* prevent text inflation on some mobile browsers */
        -webkit-text-size-adjust: none !important;
        -moz-text-size-adjust: none !important;
        -o-text-size-adjust: none !important;
        text-size-adjust: none !important;
    }

    @media only screen {
        /* "page" element */
        body {
            position: relative;
            box-sizing: border-box;
            font-size: 12pt;
            line-height: 1.5;
            max-width: 8.5in;
            margin: 20px auto;
            padding: 40px;
            border-radius: 5px;
            border: solid 1px #bdbdbd;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            background: #ffffff;
        }
    }

    /* when on screen < 8.5in wide */
    @media only screen and (max-width: 8.5in) {
        /* "page" element */
        body {
            padding: 20px;
            margin: 0;
            border-radius: 0;
            border: none;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05) inset;
            background: none;
        }
    }

    /* -------------------------------------------------- */
    /* headings */
    /* -------------------------------------------------- */

    /* all headings */
    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
        margin: 20px 0;
        padding: 0;
        font-weight: bold;
    }

    /* biggest heading */
    h1 {
        margin: 40px 0;
        text-align: center;
    }

    /* second biggest heading */
    h2 {
        margin-top: 30px;
        padding-bottom: 5px;
        border-bottom: solid 1px #bdbdbd;
    }

    /* heading font sizes */
    h1 {
        font-size: 2em;
    }
    h2 {
        font-size: 1.5em;
    }
    h3{
        font-size: 1.35em;
    }
    h4 {
        font-size: 1.25em;
    }
    h5 {
        font-size: 1.15em;
    }
    h6 {
        font-size: 1em;
    }

    /* -------------------------------------------------- */
    /* manuscript header */
    /* -------------------------------------------------- */

    /* manuscript title */
    header > h1 {
        margin: 0;
    }

    /* manuscript title caption text (ie "automatically generated on") */
    header + p {
        text-align: center;
        margin-top: 10px;
    }

    /* -------------------------------------------------- */
    /* text elements */
    /* -------------------------------------------------- */

    /* links */
    a {
        color: #2196f3;
        overflow-wrap: break-word;
    }

    /* normal links (not empty, not button link, not syntax highlighting link) */
    a:not(:empty):not(.button):not(.sourceLine) {
        padding-left: 1px;
        padding-right: 1px;
    }

    /* superscripts and subscripts */
    sub,
    sup {
        /* prevent from affecting line height */
        line-height: 0;
    }

    /* unordered and ordered lists*/
    ul,
    ol {
        padding-left: 20px;
    }

    /* class for styling text semibold */
    .semibold {
        font-weight: 600;
    }

    /* class for styling elements horizontally left aligned */
    .left {
        display: block;
        text-align: left;
        margin-left: auto;
        margin-right: 0;
        justify-content: left;
    }

    /* class for styling elements horizontally centered */
    .center {
        display: block;
        text-align: center;
        margin-left: auto;
        margin-right: auto;
        justify-content: center;
    }

    /* class for styling elements horizontally right aligned */
    .right {
        display: block;
        text-align: right;
        margin-left: 0;
        margin-right: auto;
        justify-content: right;
    }

    /* -------------------------------------------------- */
    /* section elements */
    /* -------------------------------------------------- */

    /* horizontal divider line */
    hr {
        border: none;
        height: 1px;
        background: #bdbdbd;
    }

    /* paragraphs, horizontal dividers, figures, tables, code */
    p,
    hr,
    figure,
    table,
    pre {
        /* treat all as "paragraphs", with consistent vertical margins */
        margin-top: 20px;
        margin-bottom: 20px;
    }

    /* -------------------------------------------------- */
    /* figures */
    /* -------------------------------------------------- */

    /* figure */
    figure {
        max-width: 100%;
        margin-left: auto;
        margin-right: auto;
    }

    /* figure caption */
    figcaption {
        padding: 0;
        padding-top: 10px;
    }

    /* figure image element */
    figure > img,
    figure > svg {
        max-width: 100%;
        display: block;
        margin-left: auto;
        margin-right: auto;
    }

    /* figure auto-number */
    img + figcaption > span:first-of-type,
    svg + figcaption > span:first-of-type {
        font-weight: bold;
        margin-right: 5px;
    }

    /* -------------------------------------------------- */
    /* tables */
    /* -------------------------------------------------- */

    /* table */
    table {
        border-collapse: collapse;
        border-spacing: 0;
        width: 100%;
        margin-left: auto;
        margin-right: auto;
        font-size: 10pt;
    }

    /* table cells */
    th,
    td {
        border: solid 1px #bdbdbd;
        padding: 10px;
        /* squash table if too wide for page by forcing line breaks */
        overflow-wrap: break-word;
        /* I am disabling this because the YTEP table gets a bit confused. */
        /*word-break: break-word;*/
    }

    /* header row and even rows */
    th,
    tr:nth-child(2n) {
        background-color: #fafafa;
    }

    /* odd rows */
    tr:nth-child(2n + 1) {
        background-color: #ffffff;
    }

    /* table caption */
    caption {
        text-align: left;
        padding: 0;
        padding-bottom: 10px;
    }

    /* table auto-number */
    table > caption > span:first-of-type,
    div.table_wrapper > table > caption > span:first-of-type {
        font-weight: bold;
        margin-right: 5px;
    }

    /* -------------------------------------------------- */
    /* code */
    /* -------------------------------------------------- */

    /* multi-line code block */
    pre {
        padding: 10px;
        background-color: #eeeeee;
        color: #000000;
        border-radius: 5px;
        break-inside: avoid;
        text-align: left;
    }

    /* inline code, ie code within normal text */
    :not(pre) > code {
        padding: 0 4px;
        background-color: #eeeeee;
        color: #000000;
        border-radius: 5px;
    }

    /* code text */
    /* apply all children, to reach syntax highlighting sub-elements */
    code,
    code * {
        /* force monospace font */
        font-family: "Source Code Pro", "Courier New", monospace;
    }

    /* -------------------------------------------------- */
    /* quotes */
    /* -------------------------------------------------- */

    /* quoted text */
    blockquote {
        margin: 0;
        padding: 0;
        border-left: 4px solid #bdbdbd;
        padding-left: 16px;
        break-inside: avoid;
    }

    /* -------------------------------------------------- */
    /* banners */
    /* -------------------------------------------------- */

    /* info banners */
    .banner {
        box-sizing: border-box;
        display: block;
        position: relative;
        width: 100%;
        margin-top: 20px;
        margin-bottom: 20px;
        padding: 20px;
        text-align: center;
    }

    /* paragraph in banner */
    .banner > p {
        margin: 0;
    }

    /* -------------------------------------------------- */
    /* highlight colors */
    /* -------------------------------------------------- */

    .white {
        background: #ffffff;
    }
    .lightgrey {
        background: #eeeeee;
    }
    .grey {
        background: #757575;
    }
    .darkgrey {
        background: #424242;
    }
    .black {
        background: #000000;
    }
    .lightred {
        background: #ffcdd2;
    }
    .lightyellow {
        background: #ffecb3;
    }
    .lightgreen {
        background: #dcedc8;
    }
    .lightblue {
        background: #e3f2fd;
    }
    .lightpurple {
        background: #f3e5f5;
    }
    .red {
        background: #f44336;
    }
    .orange {
        background: #ff9800;
    }
    .yellow {
        background: #ffeb3b;
    }
    .green {
        background: #4caf50;
    }
    .blue {
        background: #2196f3;
    }
    .purple {
        background: #9c27b0;
    }
    .white,
    .lightgrey,
    .lightred,
    .lightyellow,
    .lightgreen,
    .lightblue,
    .lightpurple,
    .orange,
    .yellow,
    .white a,
    .lightgrey a,
    .lightred a,
    .lightyellow a,
    .lightgreen a,
    .lightblue a,
    .lightpurple a,
    .orange a,
    .yellow a {
        color: #000000;
    }
    .grey,
    .darkgrey,
    .black,
    .red,
    .green,
    .blue,
    .purple,
    .grey a,
    .darkgrey a,
    .black a,
    .red a,
    .green a,
    .blue a,
    .purple a {
        color: #ffffff;
    }

    /* -------------------------------------------------- */
    /* buttons */
    /* -------------------------------------------------- */

    /* class for styling links like buttons */
    .button {
        display: inline-flex;
        justify-content: center;
        align-items: center;
        margin: 5px;
        padding: 10px 20px;
        font-size: 0.75em;
        font-weight: 600;
        text-transform: uppercase;
        text-decoration: none;
        letter-spacing: 1px;
        background: none;
        color: #2196f3;
        border: solid 1px #bdbdbd;
        border-radius: 5px;
    }

    /* buttons when hovered */
    .button:hover:not([disabled]),
    .icon_button:hover:not([disabled]) {
        cursor: pointer;
        background: #f5f5f5;
    }

    /* buttons when disabled */
    .button[disabled],
    .icon_button[disabled] {
        opacity: 0.35;
        pointer-events: none;
    }

    /* class for styling buttons containg only single icon */
    .icon_button {
        display: inline-flex;
        justify-content: center;
        align-items: center;
        text-decoration: none;
        margin: 0;
        padding: 0;
        background: none;
        border-radius: 5px;
        border: none;
        width: 20px;
        height: 20px;
        min-width: 20px;
        min-height: 20px;
    }

    /* icon button inner svg image */
    .icon_button > svg {
        height: 16px;
    }

    /* -------------------------------------------------- */
    /* icons */
    /* -------------------------------------------------- */

    /* class for styling icons inline with text */
    .inline_icon {
        height: 1em;
        position: relative;
        top: 0.125em;
    }

    /* -------------------------------------------------- */
    /* print control */
    /* -------------------------------------------------- */

    @media print {
        @page {
            /* suggested printing margin */
            margin: 0.5in;
        }

        /* document and "page" elements */
        html, body {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
        }

        /* "page" element */
        body {
            font-size: 11pt !important;
            line-height: 1.35;
        }

        /* all headings */
        h1,
        h2,
        h3,
        h4,
        h5,
        h6 {
            margin: 15px 0;
        }

        /* figures and tables */
        figure, table {
            font-size: 0.85em;
        }

        /* table cells */
        th,
        td {
            padding: 5px;
        }

        /* shrink font awesome icons */
        i.fas,
        i.fab,
        i.far,
        i.fal {
            transform: scale(0.85);
        }

        /* decrease banner margins */
        .banner {
            margin-top: 15px;
            margin-bottom: 15px;
            padding: 15px;
        }

        /* class for centering an element vertically on its own page */
        .page_center {
            margin: auto;
            width: 100%;
            height: 100%;
            display: flex;
            align-items: center;
            vertical-align: middle;
            break-before: page;
            break-after: page;
        }

        /* always insert a page break before the element */
        .page_break_before {
            break-before: page;
        }

        /* always insert a page break after the element */
        .page_break_after {
            break-after: page;
        }

        /* avoid page break before the element */
        .page_break_before_avoid {
            break-before: avoid;
        }

        /* avoid page break after the element */
        .page_break_after_avoid {
            break-after: avoid;
        }

        /* avoid page break inside the element */
        .page_break_inside_avoid {
            break-inside: avoid;
        }
    }

    /* -------------------------------------------------- */
    /* override pandoc css quirks */
    /* -------------------------------------------------- */

    .sourceCode {
        /* prevent unsightly overflow in wide code blocks */
        overflow: auto !important;
    }

    div.sourceCode {
        /* prevent background fill on top-most code block  container */
        background: none !important;
    }

    .sourceCode * {
        /* force consistent line spacing */
        line-height: 1.5 !important;
    }

    div.sourceCode {
        /* style code block margins same as <pre> element */
        margin-top: 20px;
        margin-bottom: 20px;
    }

    /* -------------------------------------------------- */
    /* tablenos */
    /* -------------------------------------------------- */

    /* tablenos wrapper */
    .tablenos {
        /* show scrollbar on tables if necessary to prevent overflow */
        width: 100%;
        margin: 20px 0;
    }

    .tablenos > table {
        /* move margins from table to table_wrapper to allow margin collapsing */
        margin: 0;
    }

    @media only screen {
        /* tablenos wrapper */
        .tablenos {
            /* show scrollbar on tables if necessary to prevent overflow */
            overflow-x: auto !important;
        }

        .tablenos th,
        .tablenos td {
            overflow-wrap: unset !important;
            word-break: unset !important;
        }

        /* table in wrapper */
        .tablenos table,
        .tablenos table * {
            /* don't break table words */
            overflow-wrap: normal !important;
        }
    }

    /* -------------------------------------------------- */
    /* mathjax */
    /* -------------------------------------------------- */

    /* mathjax containers */
    .math.display > span:not(.MathJax_Preview) {
        /* turn inline element (no dimensions) into block (allows fixed width and thus scrolling) */
        display: flex !important;
        overflow-x: auto !important;
        overflow-y: hidden !important;
        justify-content: center;
        align-items: center;
        margin: 0 !important;
    }

    /* right click menu */
    .MathJax_Menu {
        border-radius: 5px !important;
        border: solid 1px #bdbdbd !important;
        box-shadow: none !important;
    }

    /* equation auto-number */
    span[id^="eq:"] > span.math.display + span {
        font-weight: 600;
    }

    /* equation */
    span[id^="eq:"] > span.math.display > span {
        /* nudge to make room for equation auto-number and anchor */
        margin-right: 60px !important;
    }

    /* -------------------------------------------------- */
    /* anchors plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* anchor button */
        .anchor {
            opacity: 0;
            margin-left: 5px;
        }

        /* anchor buttons within <h2>'s */
        h2 .anchor {
            margin-left: 10px;
        }

        /* anchor buttons when hovered/focused and anything containing an anchor button when hovered */
        *:hover > .anchor,
        .anchor:hover,
        .anchor:focus {
            opacity: 1;
        }

        /* anchor button when hovered */
        .anchor:hover {
            cursor: pointer;
        }
    }

    /* always show anchor button on devices with no mouse/hover ability */
    @media (hover: none) {
        .anchor {
            opacity: 1;
        }
    }

    /* always hide anchor button on print */
    @media only print {
        .anchor {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* accordion plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* accordion arrow button */
        .accordion_arrow {
            margin-right: 10px;
        }

        /* arrow icon when <h2> data-collapsed attribute true */
        h2[data-collapsed="true"] > .accordion_arrow > svg {
            transform: rotate(-90deg);
        }

        /* all elements (except <h2>'s) when data-collapsed attribute true */
        *:not(h2)[data-collapsed="true"] {
            display: none;
        }

        /* accordion arrow button when hovered and <h2>'s when hovered */
        .accordion_arrow:hover,
        h2[data-collapsed="true"]:hover,
        h2[data-collapsed="false"]:hover {
            cursor: pointer;
        }
    }

    /* always hide accordion arrow button on print */
    @media only print {
        .accordion_arrow {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* tooltips plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* tooltip container */
        #tooltip {
            position: absolute;
            width: 50%;
            min-width: 240px;
            max-width: 75%;
            z-index: 1;
        }

        /* tooltip content */
        #tooltip_content {
            margin-bottom: 5px;
            padding: 20px;
            border-radius: 5px;
            border: solid 1px #bdbdbd;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            background: #ffffff;
            overflow-wrap: break-word;
        }

        /* tooltip copy of paragraphs and figures */
        #tooltip_content > p,
        #tooltip_content > figure {
            margin: 0;
            max-height: 320px;
            overflow-y: auto;
        }

        /* tooltip copy of <img> */
        #tooltip_content > figure > img,
        #tooltip_content > figure > svg {
            max-height: 260px;
        }

        /* navigation bar */
        #tooltip_nav_bar {
            margin-top: 10px;
            text-align: center;
        }

        /* navigation bar previous/next buton */
        #tooltip_nav_bar > .icon_button {
            position: relative;
            top: 3px;
        }

        /* navigation bar previous button */
        #tooltip_nav_bar > .icon_button:first-of-type {
            margin-right: 5px;
        }

        /* navigation bar next button */
        #tooltip_nav_bar > .icon_button:last-of-type {
            margin-left: 5px;
        }
    }

    /* always hide tooltip on print */
    @media only print {
        #tooltip {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* jump to first plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* jump button */
        .jump_arrow {
            position: relative;
            top: 0.125em;
            margin-right: 5px;
        }
    }

    /* always hide jump button on print */
    @media only print {
        .jump_arrow {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* link highlight plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* anything with data-highlighted attribute true */
        [data-highlighted="true"] {
            background: #ffeb3b;
        }

        /* anything with data-selected attribute true */
        [data-selected="true"] {
            background: #ff8a65 !important;
        }

        /* animation definition for glow */
        @keyframes highlight_glow {
            0% {
                background: none;
            }
            10% {
                background: #bbdefb;
            }
            100% {
                background: none;
            }
        }

        /* anything with data-glow attribute true */
        [data-glow="true"] {
            animation: highlight_glow 2s;
        }
    }

    /* -------------------------------------------------- */
    /* table of contents plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* toc panel */
        #toc_panel {
            box-sizing: border-box;
            position: fixed;
            top: 0;
            left: 0;
            background: #ffffff;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            z-index: 2;
        }

        /* toc panel when closed */
        #toc_panel[data-open="false"] {
            min-width: 60px;
            width: 60px;
            height: 60px;
            border-right: solid 1px #bdbdbd;
            border-bottom: solid 1px #bdbdbd;
        }

        /* toc panel when open */
        #toc_panel[data-open="true"] {
            min-width: 260px;
            max-width: 480px;
            /* keep panel edge consistent distance away from "page" edge */
            width: calc(((100vw - 8.5in) / 2) - 30px - 40px);
            bottom: 0;
            border-right: solid 1px #bdbdbd;
        }

        /* toc panel header */
        #toc_header {
            box-sizing: border-box;
            display: flex;
            flex-direction: row;
            align-items: center;
            height: 60px;
            margin: 0;
            padding: 20px;
        }

        /* toc panel header when hovered */
        #toc_header:hover {
            cursor: pointer;
        }

        /* toc panel header when panel open */
        #toc_panel[data-open="true"] > #toc_header {
            border-bottom: solid 1px #bdbdbd;
        }

        /* toc open/close header button */
        #toc_button {
            margin-right: 20px;
        }

        /* hide toc list and header text when closed */
        #toc_panel[data-open="false"] > #toc_header > *:not(#toc_button),
        #toc_panel[data-open="false"] > #toc_list {
            display: none;
        }

        /* toc list of entries */
        #toc_list {
            box-sizing: border-box;
            width: 100%;
            padding: 20px;
            position: absolute;
            top: calc(60px + 1px);
            bottom: 0;
            overflow: auto;
        }

        /* toc entry, link to section in document */
        .toc_link {
            display: block;
            padding: 5px;
            position: relative;
            font-weight: 600;
            text-decoration: none;
        }

        /* toc entry when hovered or when "viewed" */
        .toc_link:hover,
        .toc_link[data-viewing="true"] {
            background: #f5f5f5;
        }

        /* toc entry, level 1 indentation */
        .toc_link[data-level="1"] {
            margin-left: 0;
        }

        /* toc entry, level 2 indentation */
        .toc_link[data-level="2"] {
            margin-left: 20px;
        }

        /* toc entry, level 3 indentation */
        .toc_link[data-level="3"] {
            margin-left: 40px;
        }

        /* toc entry, level 4 indentation */
        .toc_link[data-level="4"] {
            margin-left: 60px;
        }

        /* toc entry bullets */
        #toc_panel[data-bullets="true"] .toc_link[data-level]:before {
            position: absolute;
            left: -15px;
            top: -1px;
            font-size: 1.5em;
        }

        /* toc entry, level 2 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="2"]:before {
            content: "\2022";
        }

        /* toc entry, level 3 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="3"]:before {
            content: "\25AB";
        }

        /* toc entry, level 4 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="4"]:before {
            content: "-";
        }
    }

    /* when on screen < 8.5in wide */
    @media only screen and (max-width: 8.5in) {
        /* push <body> ("page") element down to make room for toc icon */
        .toc_body_nudge {
            padding-top: 60px;
        }

        /* toc icon when panel closed and not hovered */
        #toc_panel[data-open="false"]:not(:hover) {
            background: rgba(255, 255, 255, 0.75);
        }
    }

    /* always hide toc panel on print */
    @media only print {
        #toc_panel {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* lightbox plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* regular <img> in document when hovered */
        img.lightbox_document_img:hover {
            cursor: pointer;
        }

        .body_no_scroll {
            overflow: hidden !important;
        }

        /* screen overlay */
        #lightbox_overlay {
            display: flex;
            flex-direction: column;
            position: fixed;
            left: 0;
            top: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.75);
            z-index: 3;
        }

        /* middle area containing lightbox image */
        #lightbox_image_container {
            flex-grow: 1;
            display: flex;
            justify-content: center;
            align-items: center;
            overflow: hidden;
            position: relative;
            padding: 20px;
        }

        /* bottom area containing caption */
        #lightbox_bottom_container {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100px;
            min-height: 100px;
            max-height: 100px;
            background: rgba(0, 0, 0, 0.5);
        }

        /* image number info text box */
        #lightbox_number_info {
            position: absolute;
            color: #ffffff;
            font-weight: 600;
            left: 2px;
            top: 0;
            z-index: 4;
        }

        /* zoom info text box */
        #lightbox_zoom_info {
            position: absolute;
            color: #ffffff;
            font-weight: 600;
            right: 2px;
            top: 0;
            z-index: 4;
        }

        /* copy of image caption */
        #lightbox_caption {
            box-sizing: border-box;
            display: inline-block;
            width: 100%;
            max-height: 100%;
            padding: 10px 0;
            text-align: center;
            overflow-y: auto;
            color: #ffffff;
        }

        /* navigation previous/next button */
        .lightbox_button {
            width: 100px;
            height: 100%;
            min-width: 100px;
            min-height: 100%;
            color: #ffffff;
        }

        /* navigation previous/next button when hovered */
        .lightbox_button:hover {
            background: none !important;
        }

        /* navigation button icon */
        .lightbox_button > svg {
            height: 25px;
        }

        /* figure auto-number */
        #lightbox_caption > span:first-of-type {
            font-weight: bold;
            margin-right: 5px;
        }

        /* lightbox image when hovered */
        #lightbox_img:hover {
            cursor: grab;
        }

        /* lightbox image when grabbed */
        #lightbox_img:active {
            cursor: grabbing;
        }
    }

    /* when on screen < 480px wide */
    @media only screen and (max-width: 480px) {
        /* make navigation buttons skinnier on small screens to make more room for caption text */
        .lightbox_button {
            width: 50px;
            min-width: 50px;
        }
    }

    /* always hide lightbox on print */
    @media only print {
        #lightbox_overlay {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* hypothesis (annotations) plugin */
    /* -------------------------------------------------- */

    /* hypothesis activation button */
    #hypothesis_button {
        box-sizing: border-box;
        position: fixed;
        top: 0;
        right: 0;
        width: 60px;
        height: 60px;
        background: #ffffff;
        border-radius: 0;
        border-left: solid 1px #bdbdbd;
        border-bottom: solid 1px #bdbdbd;
        box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
        z-index: 2;
    }

    /* hypothesis button svg */
    #hypothesis_button > svg {
        position: relative;
        top: -4px;
    }

    /* hypothesis annotation count */
    #hypothesis_count {
        position: absolute;
        left: 0;
        right: 0;
        bottom: 5px;
    }

    /* side panel */
    .annotator-frame {
        width: 280px !important;
    }

    /* match highlight color to rest of theme */
    .annotator-highlights-always-on .annotator-hl {
        background-color: #ffeb3b !important;
    }

    /* match focused color to rest of theme */
    .annotator-hl.annotator-hl-focused {
        background-color: #ff8a65 !important;
    }

    /* match bucket bar color to rest of theme */
    .annotator-bucket-bar {
        background: #f5f5f5 !important;
    }

    /* always hide button, toolbar, and tooltip on print */
    @media only print {
        #hypothesis_button {
            display: none;
        }

        .annotator-frame {
            display: none !important;
        }

        hypothesis-adder {
            display: none !important;
        }
    }
</style>
<!-- inline svg plugin -->

<script>
  (function() {
      // /////////////////////////
      // DESCRIPTION
      // /////////////////////////

      // This Manubot plugin fetches the text source code of SVGs in <img> tags,
      // and inserts it into the document in-place. This provides many
      // advantages, such as being able to style SVGs globally from the CSS
      // themes, and being able to make SVGs interactive with JavaScript and D3.
      // If you have a script that expects SVGs to be inlined, wait for an
      // "SVGLoaded" event before running it.

      // Note: This requires the page to be served from a server to work
      // See: https://stackoverflow.com/a/11063963/2180570
      // Tip: Use the manubot commands to open the page in a local webserver
      // See: https://github.com/manubot/rootstock#local-execution

      // /////////////////////////
      // SCRIPT
      // /////////////////////////

      // start script
      async function start() {
          // get all <img> tags that have "src" attributes that end with ".svg"
          const imgs = document.querySelectorAll('img[src$=".svg"]');
          const inlineSvgs = Array.from(imgs).map(inlineSvg);
          await Promise.all(inlineSvgs);

          // dispatch "inline finished" event
          document.dispatchEvent(new Event('SVGLoaded'));
      }

      // take an svg <img> tag, fetch its source code, and replace it 
      async function inlineSvg(img) {
          try {
              // fetch svg source code
              const response = await fetch(img.src);
              if (!response.ok) throw new Error('Couldn\'t get SVG source');
              const source = await response.text();
              if (!source.trim()) throw new Error('No SVG source');
              // parse specifically as svg, create new (hidden) dom node
              const svg = new DOMParser()
                  .parseFromString(source, 'image/svg+xml')
                  .querySelector('svg');
              if (!svg) throw new Error('Couldn\'t parse SVG');
              // transfer original img attributes into new svg
              for (const { name, value } of img.attributes)
                  svg.setAttribute(name, value);
              // replace original image with new svg
              img.outerHTML = svg.outerHTML;
          } catch (error) {
              console.log(error);
          }
      }

      // start script when document is finished loading
      window.addEventListener('load', start);
  })();
</script>
<!-- anchors plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin adds an anchor next to each of a certain type
        // of element that provides a human-readable url to that specific
        // item/position in the document (eg "manuscript.html#abstract"). It
        // also makes it such that scrolling out of view of a target removes
        // its identifier from the url.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'anchors';

        // default plugin options
        const options = {
            // which types of elements to add anchors next to, in
            // "document.querySelector" format
            typesQuery: 'h1, h2, h3, [id^="fig:"], [id^="tbl:"], [id^="eq:"]',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // add anchor to each element of specified types
            const elements = document.querySelectorAll(options.typesQuery);
            for (const element of elements)
                addAnchor(element);

            // attach scroll listener to window
            window.addEventListener('scroll', onScroll);
        }

        // when window is scrolled
        function onScroll() {
            // if url has hash and user has scrolled out of view of hash
            // target, remove hash from url
            const tolerance = 100;
            const target = getHashTarget();
            if (target) {
                if (
                    target.getBoundingClientRect().top >
                        window.innerHeight + tolerance ||
                    target.getBoundingClientRect().bottom < 0 - tolerance
                )
                    history.pushState(null, null, ' ');
            }
        }

        // add anchor to element
        function addAnchor(element) {
            let addTo; // element to add anchor button to

            // if figure or table, modify withId and addTo to get expected
            // elements
            if (element.id.indexOf('fig:') === 0) {
                addTo = element.querySelector('figcaption');
            } else if (element.id.indexOf('tbl:') === 0) {
                addTo = element.querySelector('caption');
            } else if (element.id.indexOf('eq:') === 0) {
                addTo = element.querySelector('.eqnos-number');
            }

            addTo = addTo || element;
            const id = element.id || null;

            // do not add anchor if element doesn't have assigned id.
            // id is generated by pandoc and is assumed to be unique and
            // human-readable
            if (!id)
                return;

            // create anchor button
            const anchor = document.createElement('a');
            anchor.innerHTML = document.querySelector('.icon_link').innerHTML;
            anchor.title = 'Link to this part of the document';
            anchor.classList.add('icon_button', 'anchor');
            anchor.dataset.ignore = 'true';
            anchor.href = '#' + id;
            addTo.appendChild(anchor);
        }

        // get element that is target of link or url hash
        function getHashTarget() {
            const hash = window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if figure or table, modify target to get expected element
            if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');
            if (id.indexOf('tbl:') === 0)
                target = target.querySelector('table');

            return target;
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- link icon -->

<template class="icon_link">
    <!-- modified from: https://fontawesome.com/icons/link -->
    <svg width="16" height="16" viewBox="0 0 512 512">
        <path
            fill="currentColor"
            d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"
        ></path>
    </svg>
</template>
<!-- accordion plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin allows sections of content under <h2> headings
        // to be collapsible.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'accordion';

        // default plugin options
        const options = {
            // whether to always start expanded ('false'), always start
            // collapsed ('true'), or start collapsed when screen small ('auto')
            startCollapsed: 'auto',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // run through each <h2> heading
            const headings = document.querySelectorAll('h2');
            for (const heading of headings) {
                addArrow(heading);

                // start expanded/collapsed based on option
                if (
                    options.startCollapsed === 'true' ||
                    (options.startCollapsed === 'auto' && isSmallScreen())
                )
                    collapseHeading(heading);
                else
                    expandHeading(heading);
            }

            // attach hash change listener to window
            window.addEventListener('hashchange', onHashChange);
        }

        // when hash (eg manuscript.html#introduction) changes
        function onHashChange() {
            const target = getHashTarget();
            if (target)
                goToElement(target);
        }

        // add arrow to heading
        function addArrow(heading) {
            // add arrow button
            const arrow = document.createElement('button');
            arrow.innerHTML = document.querySelector(
                '.icon_angle_down'
            ).innerHTML;
            arrow.classList.add('icon_button', 'accordion_arrow');
            heading.insertBefore(arrow, heading.firstChild);

            // attach click listener to heading and button
            heading.addEventListener('click', onHeadingClick);
            arrow.addEventListener('click', onArrowClick);
        }

        // determine if on mobile-like device with small screen
        function isSmallScreen() {
            return Math.min(window.innerWidth, window.innerHeight) < 480;
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // get element that is target of hash
        function getHashTarget(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if figure or table, modify target to get expected element
            if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');
            if (id.indexOf('tbl:') === 0)
                target = target.querySelector('table');

            return target;
        }

        // when <h2> heading is clicked
        function onHeadingClick(event) {
            // only collapse if <h2> itself is target of click (eg, user did
            // not click on anchor within <h2>)
            if (event.target === this)
                toggleCollapse(this);
        }

        // when arrow button is clicked
        function onArrowClick() {
            toggleCollapse(this.parentNode);
        }

        // collapse section if expanded, expand if collapsed
        function toggleCollapse(heading) {
            if (heading.dataset.collapsed === 'false')
                collapseHeading(heading);
            else
                expandHeading(heading);
        }

        // elements to exclude from collapse, such as table of contents panel,
        // hypothesis panel, etc
        const exclude = '#toc_panel, div.annotator-frame, #lightbox_overlay';

        // collapse section
        function collapseHeading(heading) {
            heading.setAttribute('data-collapsed', 'true');
            const children = getChildren(heading);
            for (const child of children)
                child.setAttribute('data-collapsed', 'true');
        }

        // expand section
        function expandHeading(heading) {
            heading.setAttribute('data-collapsed', 'false');
            const children = getChildren(heading);
            for (const child of children)
                child.setAttribute('data-collapsed', 'false');
        }

        // get list of elements between this <h2> and next <h2> or <h1>
        // ("children" of the <h2> section)
        function getChildren(heading) {
            return nextUntil(heading, 'h2, h1', exclude);
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get list of elements after a start element up to element matching
        // query
        function nextUntil(element, query, exclude) {
            const elements = [];
            while (element = element.nextElementSibling, element) {
                if (element.matches(query))
                    break;
                if (!element.matches(exclude))
                    elements.push(element);
            }
            return elements;
        }

        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- angle down icon -->

<template class="icon_angle_down">
    <!-- modified from: https://fontawesome.com/icons/angle-down -->
    <svg width="16" height="16" viewBox="0 0 448 512">
        <path
            fill="currentColor"
            d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"
        ></path>
    </svg>
</template>
<!-- tooltips plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when the user hovers or
        // focuses a link to a citation or figure, a tooltip appears with a
        // preview of the reference content, along with arrows to navigate
        // between instances of the same reference in the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'tooltips';

        // default plugin options
        const options = {
            // whether user must click off to close tooltip instead of just
            // un-hovering
            clickClose: 'false',
            // delay (in ms) between opening and closing tooltip
            delay: '100',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            const links = getLinks();
            for (const link of links) {
                // attach hover and focus listeners to link
                link.addEventListener('mouseover', onLinkHover);
                link.addEventListener('mouseleave', onLinkUnhover);
                link.addEventListener('focus', onLinkFocus);
                link.addEventListener('touchend', onLinkTouch);
            }

            // attach mouse, key, and resize listeners to window
            window.addEventListener('mousedown', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('keyup', onKeyUp);
            window.addEventListener('resize', onResize);
        }

        // when link is hovered
        function onLinkHover() {
            // function to open tooltip
            const delayOpenTooltip = function() {
                openTooltip(this);
            }.bind(this);

            // run open function after delay
            this.openTooltipTimer = window.setTimeout(
                delayOpenTooltip,
                options.delay
            );
        }

        // when mouse leaves link
        function onLinkUnhover() {
            // cancel opening tooltip
            window.clearTimeout(this.openTooltipTimer);

            // don't close on unhover if option specifies
            if (options.clickClose === 'true')
                return;

            // function to close tooltip
            const delayCloseTooltip = function() {
                // if tooltip open and if mouse isn't over tooltip, close
                const tooltip = document.getElementById('tooltip');
                if (tooltip && !tooltip.matches(':hover'))
                    closeTooltip();
            };

            // run close function after delay
            this.closeTooltipTimer = window.setTimeout(
                delayCloseTooltip,
                options.delay
            );
        }

        // when link is focused (tabbed to)
        function onLinkFocus(event) {
            openTooltip(this);
        }

        // when link is touched on touch screen
        function onLinkTouch(event) {
            // attempt to force hover state on first tap always, and trigger
            // regular link click (and navigation) on second tap
            if (event.target === document.activeElement)
                event.target.click();
            else {
                document.activeElement.blur();
                event.target.focus();
            }
            if (event.cancelable)
                event.preventDefault();
            event.stopPropagation();
            return false;
        }

        // when mouse is clicked anywhere in window
        function onClick(event) {
            closeTooltip();
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            switch (event.key) {
                // trigger click of prev button
                case 'ArrowLeft':
                    const prevButton = document.getElementById(
                        'tooltip_prev_button'
                    );
                    if (prevButton)
                        prevButton.click();
                    break;
                // trigger click of next button
                case 'ArrowRight':
                    const nextButton = document.getElementById(
                        'tooltip_next_button'
                    );
                    if (nextButton)
                        nextButton.click();
                    break;
                // close on esc
                case 'Escape':
                    closeTooltip();
                    break;
            }
        }

        // when window is resized or zoomed
        function onResize() {
            closeTooltip();
        }

        // get all links of types we wish to handle
        function getLinks() {
            const queries = [];
            // exclude buttons, anchor links, toc links, etc
            const exclude =
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            queries.push('a[href^="#ref-"]' + exclude); // citation links
            queries.push('a[href^="#fig:"]' + exclude); // figure links
            const query = queries.join(', ');
            return document.querySelectorAll(query);
        }

        // get links with same target, get index of link in set, get total
        // same links
        function getSameLinks(link) {
            const sameLinks = [];
            const links = getLinks();
            for (const otherLink of links) {
                if (
                    otherLink.getAttribute('href') === link.getAttribute('href')
                )
                    sameLinks.push(otherLink);
            }

            return {
                elements: sameLinks,
                index: sameLinks.indexOf(link),
                total: sameLinks.length
            };
        }

        // open tooltip
        function openTooltip(link) {
            // delete tooltip if it exists, start fresh
            closeTooltip();

            // make tooltip element
            const tooltip = makeTooltip(link);

            // if source couldn't be found and tooltip not made, exit
            if (!tooltip)
                return;

            // make navbar elements
            const navBar = makeNavBar(link);
            if (navBar)
                tooltip.firstElementChild.appendChild(navBar);

            // attach tooltip to page
            document.body.appendChild(tooltip);

            // position tooltip
            const position = function() {
                positionTooltip(link);
            };
            position();

            // if tooltip contains images, position again after they've loaded
            const imgs = tooltip.querySelectorAll('img');
            for (const img of imgs)
                img.addEventListener('load', position);
        }

        // close (delete) tooltip
        function closeTooltip() {
            const tooltip = document.getElementById('tooltip');
            if (tooltip)
                tooltip.remove();
        }

        // make tooltip
        function makeTooltip(link) {
            // get target element that link points to
            const source = getSource(link);

            // if source can't be found, exit
            if (!source)
                return;

            // create new tooltip
            const tooltip = document.createElement('div');
            tooltip.id = 'tooltip';
            const tooltipContent = document.createElement('div');
            tooltipContent.id = 'tooltip_content';
            tooltip.appendChild(tooltipContent);

            // make copy of source node and put in tooltip
            const sourceCopy = makeCopy(source);
            tooltipContent.appendChild(sourceCopy);

            // attach mouse event listeners
            tooltip.addEventListener('click', onTooltipClick);
            tooltip.addEventListener('mousedown', onTooltipClick);
            tooltip.addEventListener('touchstart', onTooltipClick);
            tooltip.addEventListener('mouseleave', onTooltipUnhover);

            // (for interaction with lightbox plugin)
            // transfer click on tooltip copied img to original img
            const sourceImg = source.querySelector('img');
            const sourceCopyImg = sourceCopy.querySelector('img');
            if (sourceImg && sourceCopyImg) {
                const clickImg = function() {
                    sourceImg.click();
                    closeTooltip();
                };
                sourceCopyImg.addEventListener('click', clickImg);
            }

            return tooltip;
        }

        // make carbon copy of html dom element
        function makeCopy(source) {
            const sourceCopy = source.cloneNode(true);

            // delete elements marked with ignore (eg anchor and jump buttons)
            const deleteFromCopy = sourceCopy.querySelectorAll(
                '[data-ignore="true"]'
            );
            for (const element of deleteFromCopy)
                element.remove();

            // delete certain element attributes
            const attributes = [
                'id',
                'data-collapsed',
                'data-selected',
                'data-highlighted',
                'data-glow'
            ];
            for (const attribute of attributes) {
                sourceCopy.removeAttribute(attribute);
                const elements = sourceCopy.querySelectorAll(
                    '[' + attribute + ']'
                );
                for (const element of elements)
                    element.removeAttribute(attribute);
            }

            return sourceCopy;
        }

        // when tooltip is clicked
        function onTooltipClick(event) {
            // when user clicks on tooltip, stop click from transferring
            // outside of tooltip (eg, click off to close tooltip, or eg click
            // off to unhighlight same refs)
            event.stopPropagation();
        }

        // when tooltip is unhovered
        function onTooltipUnhover(event) {
            if (options.clickClose === 'true')
                return;

            // make sure new mouse/touch/focus no longer over tooltip or any
            // element within it
            const tooltip = document.getElementById('tooltip');
            if (!tooltip)
                return;
            if (this.contains(event.relatedTarget))
                return;

            closeTooltip();
        }

        // make nav bar to go betwen prev/next instances of same reference
        function makeNavBar(link) {
            // find other links to the same source
            const sameLinks = getSameLinks(link);

            // don't show nav bar when singular reference
            if (sameLinks.total <= 1)
                return;

            // find prev/next links with same target
            const prevLink = getPrevLink(link, sameLinks);
            const nextLink = getNextLink(link, sameLinks);

            // create nav bar
            const navBar = document.createElement('div');
            navBar.id = 'tooltip_nav_bar';
            const text = sameLinks.index + 1 + ' of ' + sameLinks.total;

            // create nav bar prev/next buttons
            const prevButton = document.createElement('button');
            const nextButton = document.createElement('button');
            prevButton.id = 'tooltip_prev_button';
            nextButton.id = 'tooltip_next_button';
            prevButton.title =
                'Jump to the previous occurence of this item in the document [←]';
            nextButton.title =
                'Jump to the next occurence of this item in the document [→]';
            prevButton.classList.add('icon_button');
            nextButton.classList.add('icon_button');
            prevButton.innerHTML = document.querySelector(
                '.icon_caret_left'
            ).innerHTML;
            nextButton.innerHTML = document.querySelector(
                '.icon_caret_right'
            ).innerHTML;
            navBar.appendChild(prevButton);
            navBar.appendChild(document.createTextNode(text));
            navBar.appendChild(nextButton);

            // attach click listeners to buttons
            prevButton.addEventListener('click', function() {
                onPrevNextClick(link, prevLink);
            });
            nextButton.addEventListener('click', function() {
                onPrevNextClick(link, nextLink);
            });

            return navBar;
        }

        // get previous link with same target
        function getPrevLink(link, sameLinks) {
            if (!sameLinks)
                sameLinks = getSameLinks(link);
            // wrap index to other side if < 1
            let index;
            if (sameLinks.index - 1 >= 0)
                index = sameLinks.index - 1;
            else
                index = sameLinks.total - 1;
            return sameLinks.elements[index];
        }

        // get next link with same target
        function getNextLink(link, sameLinks) {
            if (!sameLinks)
                sameLinks = getSameLinks(link);
            // wrap index to other side if > total
            let index;
            if (sameLinks.index + 1 <= sameLinks.total - 1)
                index = sameLinks.index + 1;
            else
                index = 0;
            return sameLinks.elements[index];
        }

        // get element that is target of link or url hash
        function getSource(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if ref or figure, modify target to get expected element
            if (id.indexOf('ref-') === 0)
                target = target.querySelector('p');
            else if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');

            return target;
        }

        // when prev/next arrow button is clicked
        function onPrevNextClick(link, prevNextLink) {
            if (link && prevNextLink)
                goToElement(prevNextLink, window.innerHeight * 0.5);
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // determine position to place tooltip based on link position in
        // viewport and tooltip size
        function positionTooltip(link, left, top) {
            const tooltipElement = document.getElementById('tooltip');
            if (!tooltipElement)
                return;

            // get convenient vars for position/dimensions of
            // link/tooltip/page/view
            link = getRectInPage(link);
            const tooltip = getRectInPage(tooltipElement);
            const view = getRectInPage();

            // horizontal positioning
            if (left)
                // use explicit value
                left = left;
            else if (link.left + tooltip.width < view.right)
                // fit tooltip to right of link
                left = link.left;
            else if (link.right - tooltip.width > view.left)
                // fit tooltip to left of link
                left = link.right - tooltip.width;
            // center tooltip in view
            else
                left = (view.right - view.left) / 2 - tooltip.width / 2;

            // vertical positioning
            if (top)
                // use explicit value
                top = top;
            else if (link.top - tooltip.height > view.top)
                // fit tooltip above link
                top = link.top - tooltip.height;
            else if (link.bottom + tooltip.height < view.bottom)
                // fit tooltip below link
                top = link.bottom;
            else {
                // center tooltip in view
                top = view.top + view.height / 2 - tooltip.height / 2;
                // nudge off of link to left/right if possible
                if (link.right + tooltip.width < view.right)
                    left = link.right;
                else if (link.left - tooltip.width > view.left)
                    left = link.left - tooltip.width;
            }

            tooltipElement.style.left = left + 'px';
            tooltipElement.style.top = top + 'px';
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get position of element relative to page
        function getRectInPage(element) {
            const rect = getRectInView(element);
            const body = getRectInView(document.body);

            const newRect = {};
            newRect.left = rect.left - body.left;
            newRect.top = rect.top - body.top;
            newRect.right = rect.right - body.left;
            newRect.bottom = rect.bottom - body.top;
            newRect.width = rect.width;
            newRect.height = rect.height;

            return newRect;
        }

        // (for interaction with accordion plugin)
        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // (for interaction with accordion plugin)
        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // (for interaction with accordion plugin)
        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
    <!-- modified from: https://fontawesome.com/icons/caret-left -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
        ></path>
    </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
    <!-- modified from: https://fontawesome.com/icons/caret-right -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
        ></path>
    </svg>
</template>
<!-- jump to first plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin adds a button next to each reference entry,
        // figure, and table that jumps the page to the first occurrence of a
        // link to that item in the manuscript.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'jumpToFirst';

        // default plugin options
        const options = {
            // whether to add buttons next to reference entries
            references: 'true',
            // whether to add buttons next to figures
            figures: 'true',
            // whether to add buttons next to tables
            tables: 'true',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            if (options.references !== 'false')
                makeReferenceButtons();
            if (options.figures !== 'false')
                makeFigureButtons();
            if (options.tables !== 'false')
                makeTableButtons();
        }

        // when jump button clicked
        function onButtonClick() {
            const first = getFirstOccurrence(this.dataset.id);
            if (!first)
                return;

            // update url hash so navigating "back" in history will return
            // user to jump button
            window.location.hash = this.dataset.id;
            // scroll to link
            window.setTimeout(function() {
                goToElement(first, window.innerHeight * 0.5);
            }, 0);
        }

        // get first occurence of link to item in document
        function getFirstOccurrence(id) {
            let query = 'a';
            query += '[href="#' + id + '"]';
            // exclude buttons, anchor links, toc links, etc
            query +=
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            return document.querySelector(query);
        }

        // add button next to each reference entry
        function makeReferenceButtons() {
            const references = document.querySelectorAll('div[id^="ref-"]');
            for (const reference of references) {
                // get reference id and element to add button to
                const id = reference.id;
                const container = reference.firstElementChild;
                const first = getFirstOccurrence(id);

                // if can't find link to reference, ignore
                if (!first)
                    continue;

                // make jump button
                let button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this reference in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.innerHTML = button.outerHTML + container.innerHTML;
                button = container.firstElementChild;
                button.addEventListener('click', onButtonClick);
            }
        }

        // add button next to each figure
        function makeFigureButtons() {
            const figures = document.querySelectorAll('[id^="fig:"]');
            for (const figure of figures) {
                // get figure id and element to add button to
                const id = figure.id;
                const container = figure.querySelector('figcaption') || figure;
                const first = getFirstOccurrence(id);

                // if can't find link to figure, ignore
                if (!first)
                    continue;

                // make jump button
                const button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this figure in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.insertBefore(button, container.firstElementChild);
                button.addEventListener('click', onButtonClick);
            }
        }

        // add button next to each figure
        function makeTableButtons() {
            const tables = document.querySelectorAll('[id^="tbl:"]');
            for (const table of tables) {
                // get ref id and element to add button to
                const id = table.id;
                const container = table.querySelector('caption') || table;
                const first = getFirstOccurrence(id);

                // if can't find link to table, ignore
                if (!first)
                    continue;

                // make jump button
                const button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this table in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.insertBefore(button, container.firstElementChild);
                button.addEventListener('click', onButtonClick);
            }
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // (for interaction with accordion plugin)
        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- angle double up icon -->

<template class="icon_angle_double_up">
    <!-- modified from: https://fontawesome.com/icons/angle-double-up -->
    <svg width="16" height="16" viewBox="0 0 320 512">
        <path
            fill="currentColor"
            d="M177 255.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 351.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 425.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1zm-34-192L7 199.7c-9.4 9.4-9.4 24.6 0 33.9l22.6 22.6c9.4 9.4 24.6 9.4 33.9 0l96.4-96.4 96.4 96.4c9.4 9.4 24.6 9.4 33.9 0l22.6-22.6c9.4-9.4 9.4-24.6 0-33.9l-136-136c-9.2-9.4-24.4-9.4-33.8 0z"
        ></path>
    </svg>
</template>
<!-- link highlight plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when a user hovers or
        // focuses a link, other links that have the same target will be
        // highlighted. It also makes it such that when clicking a link, the
        // target of the link (eg reference, figure, table) is briefly
        // highlighted.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'linkHighlight';

        // default plugin options
        const options = {
            // whether to also highlight links that go to external urls
            externalLinks: 'false',
            // whether user must click off to unhighlight instead of just
            // un-hovering
            clickUnhighlight: 'false',
            // whether to also highlight links that are unique
            highlightUnique: 'true',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            const links = getLinks();
            for (const link of links) {
                // attach mouse and focus listeners to link
                link.addEventListener('mouseenter', onLinkFocus);
                link.addEventListener('focus', onLinkFocus);
                link.addEventListener('mouseleave', onLinkUnhover);
            }

            // attach click and hash change listeners to window
            window.addEventListener('click', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('hashchange', onHashChange);

            // run hash change on window load in case user has navigated
            // directly to hash
            onHashChange();
        }

        // when link is focused (tabbed to) or hovered
        function onLinkFocus() {
            highlight(this);
        }

        // when link is unhovered
        function onLinkUnhover() {
            if (options.clickUnhighlight !== 'true')
                unhighlightAll();
        }

        // when the mouse is clicked anywhere in window
        function onClick(event) {
            unhighlightAll();
        }

        // when hash (eg manuscript.html#introduction) changes
        function onHashChange() {
            const target = getHashTarget();
            if (target)
                glowElement(target);
        }

        // get element that is target of link or url hash
        function getHashTarget(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            return target;
        }

        // start glow sequence on an element
        function glowElement(element) {
            const startGlow = function() {
                onGlowEnd();
                element.dataset.glow = 'true';
                element.addEventListener('animationend', onGlowEnd);
            };
            const onGlowEnd = function() {
                element.removeAttribute('data-glow');
                element.removeEventListener('animationend', onGlowEnd);
            };
            startGlow();
        }

        // highlight link and all others with same target
        function highlight(link) {
            // force unhighlight all to start fresh
            unhighlightAll();

            // get links with same target
            if (!link)
                return;
            const sameLinks = getSameLinks(link);

            // if link unique and option is off, exit and don't highlight
            if (sameLinks.length <= 1 && options.highlightUnique !== 'true')
                return;

            // highlight all same links, and "select" (special highlight) this
            // one
            for (const sameLink of sameLinks) {
                if (sameLink === link)
                    sameLink.setAttribute('data-selected', 'true');
                else
                    sameLink.setAttribute('data-highlighted', 'true');
            }
        }

        // unhighlight all links
        function unhighlightAll() {
            const links = getLinks();
            for (const link of links) {
                link.setAttribute('data-selected', 'false');
                link.setAttribute('data-highlighted', 'false');
            }
        }

        // get links with same target
        function getSameLinks(link) {
            const results = [];
            const links = getLinks();
            for (const otherLink of links) {
                if (
                    otherLink.getAttribute('href') === link.getAttribute('href')
                )
                    results.push(otherLink);
            }
            return results;
        }

        // get all links of types we wish to handle
        function getLinks() {
            let query = 'a';
            if (options.externalLinks !== 'true')
                query += '[href^="#"]';
            // exclude buttons, anchor links, toc links, etc
            query +=
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            return document.querySelectorAll(query);
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>
<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin provides a "table of contents" (toc) panel on
        // the side of the document that allows the user to conveniently
        // navigate between sections of the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'tableOfContents';

        // default plugin options
        const options = {
            // which types of elements to add links for, in
            // "document.querySelector" format
            typesQuery: 'h1, h2, h3',
            // whether toc starts open. use 'true' or 'false', or 'auto' to
            // use 'true' behavior when screen wide enough and 'false' when not
            startOpen: 'false',
            // whether toc closes when clicking on toc link. use 'true' or
            // 'false', or 'auto' to use 'false' behavior when screen wide
            // enough and 'true' when not
            clickClose: 'auto',
            // if list item is more than this many characters, text will be
            // truncated
            charLimit: '50',
            // whether or not to show bullets next to each toc item
            bullets: 'false',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // make toc panel and populate with entries (links to document
            // sections)
            const panel = makePanel();
            if (!panel)
                return;
            makeEntries(panel);
            // attach panel to document after making entries, so 'toc' heading
            // in panel isn't included in toc
            document.body.insertBefore(panel, document.body.firstChild);

            // initial panel state
            if (
                options.startOpen === 'true' ||
                (options.startOpen === 'auto' && !isSmallScreen())
            )
                openPanel();
            else
                closePanel();

            // attach click, scroll, and hash change listeners to window
            window.addEventListener('click', onClick);
            window.addEventListener('scroll', onScroll);
            window.addEventListener('hashchange', onScroll);
            window.addEventListener('keyup', onKeyUp);
            onScroll();

            // add class to push document body down out of way of toc button
            document.body.classList.add('toc_body_nudge');
        }

        // determine if screen wide enough to fit toc panel
        function isSmallScreen() {
            // in default theme:
            // 816px = 8.5in = width of "page" (<body>) element
            // 260px = min width of toc panel (*2 for both sides of <body>)
            return window.innerWidth < 816 + 260 * 2;
        }

        // when mouse is clicked anywhere in window
        function onClick() {
            if (isSmallScreen())
                closePanel();
        }

        // when window is scrolled or hash changed
        function onScroll() {
            highlightViewed();
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            // close on esc
            if (event.key === 'Escape')
                closePanel();
        }

        // find entry of currently viewed document section in toc and highlight
        function highlightViewed() {
            const firstId = getFirstInView(options.typesQuery);

            // get toc entries (links), unhighlight all, then highlight viewed
            const list = document.getElementById('toc_list');
            if (!firstId || !list)
                return;
            const links = list.querySelectorAll('a');
            for (const link of links)
                link.dataset.viewing = 'false';
            const link = list.querySelector('a[href="#' + firstId + '"]');
            if (!link)
                return;
            link.dataset.viewing = 'true';
        }

        // get first or previous toc listed element in top half of view
        function getFirstInView(query) {
            // get all elements matching query and with id
            const elements = document.querySelectorAll(query);
            const elementsWithIds = [];
            for (const element of elements) {
                if (element.id)
                    elementsWithIds.push(element);
            }


            // get first or previous element in top half of view
            for (let i = 0; i < elementsWithIds.length; i++) {
                const element = elementsWithIds[i];
                const prevElement = elementsWithIds[Math.max(0, i - 1)];
                if (element.getBoundingClientRect().top >= 0) {
                    if (
                        element.getBoundingClientRect().top <
                        window.innerHeight / 2
                    )
                        return element.id;
                    else
                        return prevElement.id;
                }
            }
        }

        // make panel
        function makePanel() {
            // create panel
            const panel = document.createElement('div');
            panel.id = 'toc_panel';
            if (options.bullets === 'true')
                panel.dataset.bullets = 'true';

            // create header
            const header = document.createElement('div');
            header.id = 'toc_header';

            // create toc button
            const button = document.createElement('button');
            button.id = 'toc_button';
            button.innerHTML = document.querySelector('.icon_th_list').innerHTML;
            button.title = 'Table of Contents';
            button.classList.add('icon_button');

            // create header text
            const text = document.createElement('h4');
            text.innerHTML = 'Table of Contents';

            // create container for toc list
            const list = document.createElement('div');
            list.id = 'toc_list';

            // attach click listeners
            panel.addEventListener('click', onPanelClick);
            header.addEventListener('click', onHeaderClick);
            button.addEventListener('click', onButtonClick);

            // attach elements
            header.appendChild(button);
            header.appendChild(text);
            panel.appendChild(header);
            panel.appendChild(list);

            return panel;
        }

        // create toc entries (links) to each element of the specified types
        function makeEntries(panel) {
            const elements = document.querySelectorAll(options.typesQuery);
            for (const element of elements) {
                // do not add link if element doesn't have assigned id
                if (!element.id)
                    continue;

                // create link/list item
                const link = document.createElement('a');
                link.classList.add('toc_link');
                switch (element.tagName.toLowerCase()) {
                    case 'h1':
                        link.dataset.level = '1';
                        break;
                    case 'h2':
                        link.dataset.level = '2';
                        break;
                    case 'h3':
                        link.dataset.level = '3';
                        break;
                    case 'h4':
                        link.dataset.level = '4';
                        break;
                }
                link.title = element.innerText;
                let text = element.innerText;
                if (text.length > options.charLimit)
                    text = text.slice(0, options.charLimit) + '...';
                link.innerHTML = text;
                link.href = '#' + element.id;
                link.addEventListener('click', onLinkClick);

                // attach link
                panel.querySelector('#toc_list').appendChild(link);
            }
        }

        // when panel is clicked
        function onPanelClick(event) {
            // stop click from propagating to window/document and closing panel
            event.stopPropagation();
        }

        // when header itself is clicked
        function onHeaderClick(event) {
            togglePanel();
        }

        // when button is clicked
        function onButtonClick(event) {
            togglePanel();
            // stop header underneath button from also being clicked
            event.stopPropagation();
        }

        // when link is clicked
        function onLinkClick(event) {
            if (
                options.clickClose === 'true' ||
                (options.clickClose === 'auto' && isSmallScreen())
            )
                closePanel();
            else
                openPanel();
        }

        // open panel if closed, close if opened
        function togglePanel() {
            const panel = document.getElementById('toc_panel');
            if (!panel)
                return;

            if (panel.dataset.open === 'true')
                closePanel();
            else
                openPanel();
        }

        // open panel
        function openPanel() {
            const panel = document.getElementById('toc_panel');
            if (panel)
                panel.dataset.open = 'true';
        }

        // close panel
        function closePanel() {
            const panel = document.getElementById('toc_panel');
            if (panel)
                panel.dataset.open = 'false';
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- th list icon -->

<template class="icon_th_list">
    <!-- modified from: https://fontawesome.com/icons/th-list -->
    <svg width="16" height="16" viewBox="0 0 512 512" tabindex="-1">
        <path
            fill="currentColor"
            d="M96 96c0 26.51-21.49 48-48 48S0 122.51 0 96s21.49-48 48-48 48 21.49 48 48zM48 208c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm0 160c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm96-236h352c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"
            tabindex="-1"
        ></path>
    </svg>
</template>
<!-- lightbox plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when a user clicks on an
        // image, the image fills the screen and the user can pan/drag/zoom
        // the image and navigate between other images in the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'lightbox';

        // default plugin options
        const options = {
            // list of possible zoom/scale factors
            zoomSteps:
                '0.1, 0.25, 0.333333, 0.5, 0.666666, 0.75, 1,' +
                '1.25, 1.5, 1.75, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8',
            // whether to fit image to view ('fit'), display at 100% and shrink
            // if necessary ('shrink'), or always display at 100% ('100')
            defaultZoom: 'fit',
            // whether to zoom in/out toward center of view ('true') or mouse
            // ('false')
            centerZoom: 'false',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // run through each <img> element
            const imgs = document.querySelectorAll('figure > img');
            let count = 1;
            for (const img of imgs) {
                img.classList.add('lightbox_document_img');
                img.dataset.number = count;
                img.dataset.total = imgs.length;
                img.addEventListener('click', openLightbox);
                count++;
            }

            // attach mouse and key listeners to window
            window.addEventListener('mousemove', onWindowMouseMove);
            window.addEventListener('keyup', onKeyUp);
        }

        // when mouse is moved anywhere in window
        function onWindowMouseMove(event) {
            window.mouseX = event.clientX;
            window.mouseY = event.clientY;
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            switch (event.key) {
                // trigger click of prev button
                case 'ArrowLeft':
                    const prevButton = document.getElementById(
                        'lightbox_prev_button'
                    );
                    if (prevButton)
                        prevButton.click();
                    break;
                // trigger click of next button
                case 'ArrowRight':
                    const nextButton = document.getElementById(
                        'lightbox_next_button'
                    );
                    if (nextButton)
                        nextButton.click();
                    break;
                // close on esc
                case 'Escape':
                    closeLightbox();
                    break;
            }
        }

        // open lightbox
        function openLightbox() {
            const lightbox = makeLightbox(this);
            if (!lightbox)
                return;

            blurBody(lightbox);
            document.body.appendChild(lightbox);
        }

        // make lightbox
        function makeLightbox(img) {
            // delete lightbox if it exists, start fresh
            closeLightbox();

            // create screen overlay containing lightbox
            const overlay = document.createElement('div');
            overlay.id = 'lightbox_overlay';

            // create image info boxes
            const numberInfo = document.createElement('div');
            const zoomInfo = document.createElement('div');
            numberInfo.id = 'lightbox_number_info';
            zoomInfo.id = 'lightbox_zoom_info';

            // create container for image
            const imageContainer = document.createElement('div');
            imageContainer.id = 'lightbox_image_container';
            const lightboxImg = makeLightboxImg(
                img,
                imageContainer,
                numberInfo,
                zoomInfo
            );
            imageContainer.appendChild(lightboxImg);

            // create bottom container for caption and navigation buttons
            const bottomContainer = document.createElement('div');
            bottomContainer.id = 'lightbox_bottom_container';
            const caption = makeCaption(img);
            const prevButton = makePrevButton(img);
            const nextButton = makeNextButton(img);
            bottomContainer.appendChild(prevButton);
            bottomContainer.appendChild(caption);
            bottomContainer.appendChild(nextButton);

            // attach top middle and bottom to overlay
            overlay.appendChild(numberInfo);
            overlay.appendChild(zoomInfo);
            overlay.appendChild(imageContainer);
            overlay.appendChild(bottomContainer);

            return overlay;
        }

        // make <img> object that is intuitively draggable and zoomable
        function makeLightboxImg(
            sourceImg,
            container,
            numberInfoBox,
            zoomInfoBox
        ) {
            // create copy of source <img>
            const img = sourceImg.cloneNode(true);
            img.classList.remove('lightbox_document_img');
            img.removeAttribute('id');
            img.removeAttribute('width');
            img.removeAttribute('height');
            img.style.position = 'unset';
            img.style.margin = '0';
            img.style.padding = '0';
            img.style.width = '';
            img.style.height = '';
            img.style.minWidth = '';
            img.style.minHeight = '';
            img.style.maxWidth = '';
            img.style.maxHeight = '';
            img.id = 'lightbox_img';

            // build sorted list of unique zoomSteps, always including a 100%
            let zoomSteps = [];
            const optionsZooms = options.zoomSteps.split(/[^0-9.]/);
            for (const optionZoom of optionsZooms) {
                const newZoom = parseFloat(optionZoom);
                if (newZoom && !zoomSteps.includes(newZoom))
                    zoomSteps.push(newZoom);
            }
            if (!zoomSteps.includes(1))
                zoomSteps.push(1);
            zoomSteps = zoomSteps.sort(function sortNumber(a, b) {
                return a - b;
            });

            // <img> object property variables
            let zoom = 1;
            let translateX = 0;
            let translateY = 0;
            let clickMouseX = undefined;
            let clickMouseY = undefined;
            let clickTranslateX = undefined;
            let clickTranslateY = undefined;

            updateNumberInfo();

            // update image numbers displayed in info box
            function updateNumberInfo() {
                numberInfoBox.innerHTML =
                    sourceImg.dataset.number + ' of ' + sourceImg.dataset.total;
            }

            // update zoom displayed in info box
            function updateZoomInfo() {
                let zoomInfo = zoom * 100;
                if (!Number.isInteger(zoomInfo))
                    zoomInfo = zoomInfo.toFixed(2);
                zoomInfoBox.innerHTML = zoomInfo + '%';
            }

            // move to closest zoom step above current zoom
            const zoomIn = function() {
                for (const zoomStep of zoomSteps) {
                    if (zoomStep > zoom) {
                        zoom = zoomStep;
                        break;
                    }
                }
                updateTransform();
            };

            // move to closest zoom step above current zoom
            const zoomOut = function() {
                zoomSteps.reverse();
                for (const zoomStep of zoomSteps) {
                    if (zoomStep < zoom) {
                        zoom = zoomStep;
                        break;
                    }
                }
                zoomSteps.reverse();

                updateTransform();
            };

            // update display of <img> based on scale/translate properties
            const updateTransform = function() {
                // set transform
                img.style.transform =
                    'translate(' +
                    (translateX || 0) +
                    'px,' +
                    (translateY || 0) +
                    'px) scale(' +
                    (zoom || 1) +
                    ')';

                // get new width/height after scale
                const rect = img.getBoundingClientRect();
                // limit translate
                translateX = Math.max(translateX, -rect.width / 2);
                translateX = Math.min(translateX, rect.width / 2);
                translateY = Math.max(translateY, -rect.height / 2);
                translateY = Math.min(translateY, rect.height / 2);

                // set transform
                img.style.transform =
                    'translate(' +
                    (translateX || 0) +
                    'px,' +
                    (translateY || 0) +
                    'px) scale(' +
                    (zoom || 1) +
                    ')';

                updateZoomInfo();
            };

            // fit <img> to container
            const fit = function() {
                // no x/y offset, 100% zoom by default
                translateX = 0;
                translateY = 0;
                zoom = 1;

                // widths of <img> and container
                const imgWidth = img.naturalWidth;
                const imgHeight = img.naturalHeight;
                const containerWidth = parseFloat(
                    window.getComputedStyle(container).width
                );
                const containerHeight = parseFloat(
                    window.getComputedStyle(container).height
                );

                // how much zooming is needed to fit <img> to container
                const xRatio = imgWidth / containerWidth;
                const yRatio = imgHeight / containerHeight;
                const maxRatio = Math.max(xRatio, yRatio);
                const newZoom = 1 / maxRatio;

                // fit <img> to container according to option
                if (options.defaultZoom === 'shrink') {
                    if (maxRatio > 1)
                        zoom = newZoom;
                } else if (options.defaultZoom === 'fit')
                    zoom = newZoom;

                updateTransform();
            };

            // when mouse wheel is rolled anywhere in container
            const onContainerWheel = function(event) {
                if (!event)
                    return;

                // let ctrl + mouse wheel to zoom behave as normal
                if (event.ctrlKey)
                    return;

                // prevent normal scroll behavior
                event.preventDefault();
                event.stopPropagation();

                // point around which to scale img
                const viewRect = container.getBoundingClientRect();
                const viewX = (viewRect.left + viewRect.right) / 2;
                const viewY = (viewRect.top + viewRect.bottom) / 2;
                const originX = options.centerZoom === 'true' ? viewX : mouseX;
                const originY = options.centerZoom === 'true' ? viewY : mouseY;

                // get point on image under origin
                const oldRect = img.getBoundingClientRect();
                const oldPercentX = (originX - oldRect.left) / oldRect.width;
                const oldPercentY = (originY - oldRect.top) / oldRect.height;

                // increment/decrement zoom
                if (event.deltaY < 0)
                    zoomIn();
                if (event.deltaY > 0)
                    zoomOut();

                // get offset between previous image point and origin
                const newRect = img.getBoundingClientRect();
                const offsetX =
                    originX - (newRect.left + newRect.width * oldPercentX);
                const offsetY =
                    originY - (newRect.top + newRect.height * oldPercentY);

                // translate image to keep image point under origin
                translateX += offsetX;
                translateY += offsetY;

                // perform translate
                updateTransform();
            };

            // when container is clicked
            function onContainerClick(event) {
                // if container itself is target of click, and not other
                // element above it
                if (event.target === this)
                    closeLightbox();
            }

            // when mouse button is pressed on image
            const onImageMouseDown = function(event) {
                // store original mouse position relative to image
                clickMouseX = window.mouseX;
                clickMouseY = window.mouseY;
                clickTranslateX = translateX;
                clickTranslateY = translateY;
                event.stopPropagation();
                event.preventDefault();
            };

            // when mouse button is released anywhere in window
            const onWindowMouseUp = function(event) {
                // reset original mouse position
                clickMouseX = undefined;
                clickMouseY = undefined;
                clickTranslateX = undefined;
                clickTranslateY = undefined;

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('mouseup', onWindowMouseUp);
            };

            // when mouse is moved anywhere in window
            const onWindowMouseMove = function(event) {
                if (
                    clickMouseX === undefined ||
                    clickMouseY === undefined ||
                    clickTranslateX === undefined ||
                    clickTranslateY === undefined
                )
                    return;

                // offset image based on original and current mouse position
                translateX = clickTranslateX + window.mouseX - clickMouseX;
                translateY = clickTranslateY + window.mouseY - clickMouseY;
                updateTransform();
                event.preventDefault();

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('mousemove', onWindowMouseMove);
            };

            // when window is resized
            const onWindowResize = function(event) {
                fit();

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('resize', onWindowResize);
            };

            // attach the necessary event listeners
            img.addEventListener('dblclick', fit);
            img.addEventListener('mousedown', onImageMouseDown);
            container.addEventListener('wheel', onContainerWheel);
            container.addEventListener('mousedown', onContainerClick);
            container.addEventListener('touchstart', onContainerClick);
            window.addEventListener('mouseup', onWindowMouseUp);
            window.addEventListener('mousemove', onWindowMouseMove);
            window.addEventListener('resize', onWindowResize);

            // run fit() after lightbox atttached to document and <img> Loaded
            // so needed container and img dimensions available
            img.addEventListener('load', fit);

            return img;
        }

        // make caption
        function makeCaption(img) {
            const caption = document.createElement('div');
            caption.id = 'lightbox_caption';
            const captionSource = img.nextElementSibling;
            if (captionSource.tagName.toLowerCase() === 'figcaption') {
                const captionCopy = makeCopy(captionSource);
                caption.innerHTML = captionCopy.innerHTML;
            }

            caption.addEventListener('touchstart', function(event) {
                event.stopPropagation();
            });

            return caption;
        }

        // make carbon copy of html dom element
        function makeCopy(source) {
            const sourceCopy = source.cloneNode(true);

            // delete elements marked with ignore (eg anchor and jump buttons)
            const deleteFromCopy = sourceCopy.querySelectorAll(
                '[data-ignore="true"]'
            );
            for (const element of deleteFromCopy)
                element.remove();

            // delete certain element attributes
            const attributes = [
                'id',
                'data-collapsed',
                'data-selected',
                'data-highlighted',
                'data-glow'
            ];
            for (const attribute of attributes) {
                sourceCopy.removeAttribute(attribute);
                const elements = sourceCopy.querySelectorAll(
                    '[' + attribute + ']'
                );
                for (const element of elements)
                    element.removeAttribute(attribute);
            }

            return sourceCopy;
        }

        // make button to jump to previous image in document
        function makePrevButton(img) {
            const prevButton = document.createElement('button');
            prevButton.id = 'lightbox_prev_button';
            prevButton.title = 'Jump to the previous image in the document [←]';
            prevButton.classList.add('icon_button', 'lightbox_button');
            prevButton.innerHTML = document.querySelector(
                '.icon_caret_left'
            ).innerHTML;

            // attach click listeners to button
            prevButton.addEventListener('click', function() {
                getPrevImg(img).click();
            });

            return prevButton;
        }

        // make button to jump to next image in document
        function makeNextButton(img) {
            const nextButton = document.createElement('button');
            nextButton.id = 'lightbox_next_button';
            nextButton.title = 'Jump to the next image in the document [→]';
            nextButton.classList.add('icon_button', 'lightbox_button');
            nextButton.innerHTML = document.querySelector(
                '.icon_caret_right'
            ).innerHTML;

            // attach click listeners to button
            nextButton.addEventListener('click', function() {
                getNextImg(img).click();
            });

            return nextButton;
        }

        // get previous image in document
        function getPrevImg(img) {
            const imgs = document.querySelectorAll('.lightbox_document_img');

            // find index of provided img
            let index;
            for (index = 0; index < imgs.length; index++) {
                if (imgs[index] === img)
                    break;
            }


            // wrap index to other side if < 1
            if (index - 1 >= 0)
                index--;
            else
                index = imgs.length - 1;
            return imgs[index];
        }

        // get next image in document
        function getNextImg(img) {
            const imgs = document.querySelectorAll('.lightbox_document_img');

            // find index of provided img
            let index;
            for (index = 0; index < imgs.length; index++) {
                if (imgs[index] === img)
                    break;
            }


            // wrap index to other side if > total
            if (index + 1 <= imgs.length - 1)
                index++;
            else
                index = 0;
            return imgs[index];
        }

        // close lightbox
        function closeLightbox() {
            focusBody();

            const lightbox = document.getElementById('lightbox_overlay');
            if (lightbox)
                lightbox.remove();
        }

        // make all elements behind lightbox non-focusable
        function blurBody(overlay) {
            const all = document.querySelectorAll('*');
            for (const element of all)
                element.tabIndex = -1;
            document.body.classList.add('body_no_scroll');
        }

        // make all elements focusable again
        function focusBody() {
            const all = document.querySelectorAll('*');
            for (const element of all)
                element.removeAttribute('tabIndex');
            document.body.classList.remove('body_no_scroll');
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
    <!-- modified from: https://fontawesome.com/icons/caret-left -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
        ></path>
    </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
    <!-- modified from: https://fontawesome.com/icons/caret-right -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
        ></path>
    </svg>
</template>
<!-- attributes plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin allows arbitrary HTML attributes to be attached
        // to (almost) any element. Place an HTML comment inside or next to the
        // desired element in the format <!-- $attribute="value" -->

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'attributes';

        // default plugin options
        const options = {
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // get list of comments in document
            const comments = findComments();

            for(const comment of comments)
                if (comment.parentElement)
                    addAttributes(
                        comment.parentElement,
                        comment.nodeValue.trim()
                    );
        }

        // add html attributes to specified element based on string of 
        // html attributes and values
        function addAttributes(element, text) {
            // regex's for finding attribute/value pairs in the format of
            // attribute="value" or attribute='value
            const regex2 = /\$([a-zA-Z\-]+)?=\"(.+?)\"/;
            const regex1 = /\$([a-zA-Z\-]+)?=\'(.+?)\'/;

            // loop through attribute/value pairs
            let match;
            while(match = text.match(regex2) || text.match(regex1)) {
                // get attribute and value from regex capture groups
                let attribute = match[1];
                let value = match[2];

                // remove from string
                text = text.substring(match.index + match[0].length);

                if (!attribute || !value)
                    break;

                // set attribute of parent element
                try {
                    element.setAttribute(attribute, value);
                } catch(error) {
                    console.log(error);
                }

                // special case for colspan
                if (attribute === 'colspan')
                    removeTableCells(element, value);
            }
        }

        // get list of comment elements in document
        function findComments() {
            const comments = [];

            // iterate over comment nodes in document
            function acceptNode(node) {
                return NodeFilter.FILTER_ACCEPT;
            }
            const iterator = document.createNodeIterator(
                document.body,
                NodeFilter.SHOW_COMMENT,
                acceptNode
            );
            let node;
            while(node = iterator.nextNode())
                comments.push(node);

            return comments;
        }

        // remove certain number of cells after specified cell
        function removeTableCells(cell, number) {
            number = parseInt(number);
            if (!number)
                return;

            // remove elements
            for(; number > 1; number--) {
                if (cell.nextElementSibling)
                    cell.nextElementSibling.remove();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>
<!-- mathjax plugin configuration -->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        "CommonHTML": { linebreaks: { automatic: true } },
        "HTML-CSS": { linebreaks: { automatic: true } },
        "SVG": { linebreaks: { automatic: true } },
        "fast-preview": { disabled: true }
  });
</script>

<!-- mathjax plugin -->

<script
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
    integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A=="
    crossorigin="anonymous"
>
    // /////////////////////////
    // DESCRIPTION
    // /////////////////////////

    // This third-party plugin 'MathJax' allows the proper rendering of
    // math/equations written in LaTeX.

    // https://www.mathjax.org/
</script>
<!-- annotations plugin -->

<script>
    // /////////////////////////
    // DESCRIPTION
    // /////////////////////////

    // This third-party plugin 'Hypothesis' allows public annotation of the
    // manuscript.

    // https://web.hypothes.is/

    // plugin configuration
    window.hypothesisConfig = function() {
        return {
            branding: {
                accentColor: '#2196f3',
                appBackgroundColor: '#f8f8f8',
                ctaBackgroundColor: '#f8f8f8',
                ctaTextColor: '#000000',
                selectionFontFamily: 'Open Sans, Helvetica, sans serif',
                annotationFontFamily: 'Open Sans, Helvetica, sans serif'
            }
        };
    };

    // hypothesis client script
    const embed = 'https://hypothes.is/embed.js';
    // hypothesis annotation count query url
    const query = 'https://api.hypothes.is/api/search?limit=0&url='

    
    // start script
    function start() {
        const button = makeButton();
        document.body.insertBefore(button, document.body.firstChild);
        insertCount(button);
    }

    // make button
    function makeButton() {
        // create button
        const button = document.createElement('button');
        button.id = 'hypothesis_button';
        button.innerHTML = document.querySelector('.icon_hypothesis').innerHTML;
        button.title = 'Hypothesis annotations';
        button.classList.add('icon_button');

        function onClick(event) {
            onButtonClick(event, button);
        }

        // attach click listeners
        button.addEventListener('click', onClick);

        return button;
    }

    // insert annotations count
    async function insertCount(button) {
        // get annotation count from Hypothesis based on url
        let count = '-';
        try {
            const canonical = document.querySelector('link[rel="canonical"]');
            const location = window.location;
            const url = encodeURIComponent((canonical || location).href);
            const response = await fetch(query + url);
            const json = await response.json();
            count = json.total || '-';
        } catch(error) {
            console.log(error);
        }
        
        // put count into button
        const counter = document.createElement('span');
        counter.id = 'hypothesis_count';
        counter.innerHTML = count;
        button.title = 'View ' + count + ' Hypothesis annotations';
        button.append(counter);
    }

    // when button is clicked
    function onButtonClick(event, button) {
        const script = document.createElement('script');
        script.src = embed;
        document.body.append(script);
        button.remove();
    }

    window.addEventListener('load', start);
</script>

<!-- hypothesis icon -->

<template class="icon_hypothesis">
    <!-- modified from: https://simpleicons.org/icons/hypothesis.svg / https://git.io/Jf1VB -->
    <svg width="16" height="16" viewBox="0 0 24 24" tabindex="-1">
        <path
            fill="currentColor"
            d="M3.43 0C2.5 0 1.72 .768 1.72 1.72V18.86C1.72 19.8 2.5 20.57 3.43 20.57H9.38L12 24L14.62 20.57H20.57C21.5 20.57 22.29 19.8 22.29 18.86V1.72C22.29 .77 21.5 0 20.57 0H3.43M5.14 3.43H7.72V9.43S8.58 7.72 10.28 7.72C12 7.72 13.74 8.57 13.74 11.24V17.14H11.16V12C11.16 10.61 10.28 10.07 9.43 10.29C8.57 10.5 7.72 11.41 7.72 13.29V17.14H5.14V3.43M18 13.72C18.95 13.72 19.72 14.5 19.72 15.42A1.71 1.71 0 0 1 18 17.13A1.71 1.71 0 0 1 16.29 15.42C16.29 14.5 17.05 13.71 18 13.71Z"
            tabindex="-1"
        ></path>
    </svg>
</template>
<!-- analytics plugin -->

<!-- copy and paste code from Google Analytics or similar service here -->
</body>
</html>
