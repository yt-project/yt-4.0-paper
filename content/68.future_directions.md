## Future Directions

The development of `yt` has changed over time, as it has increasingly served as a stable platform for analysis of data and maintenance efforts have taken greater resources.
However, despite that, there are a number of exciting areas within `yt` that could serve as targets of future development.
In addition to these technical areas, expanding the user-base and developer-base of `yt` can serve to better support diverse use cases and applications.

### Improvements to Internal Systems {#sec:improvements_to_internal_systems}

**Optimization**

The internal systems that conduct selection, caching and IO optimization, data processing and parallel load distribution have been designed for general purpose application.
While this enables code reuse as well as consistent API patterns, the methods used to implement these systems internally in `yt` have not always kept up with the optimizations available.
For example, the data selection routines (described in @sec:selection_routines) are not uniformly optimized to take advantage of built-in organizational information from grid, octree and particle data.
A particular example is the [quad-tree projection](#sec:dobj-quad_proj).
This projection method can be optimized for octree datasets for some speedups and memory improvements (which would likely then be shared with grid patch datasets) but the maintenance and implementation costs are not currently balanced in favor of that change.
Future iterations on `yt` will necessarily need to take these possible optimizations into account in order to meet the needs of increasing dataset size and complexity.

Other, more mundane optimizations can also be applied.
While utilizing units for all array-based operations (see @sec:units) provides safety and clarity of the quantities being manipulated, it also introduces overhead from the symbolic manipulation of those units.
For example, typically the units used for position inside `yt` are all in the internal "index" space of the dataset.
For some cosmological simulations, these are normalized to 1.0; for other simulations, they may be in centimeters or kilometers.
(And often in cosmology there is some factor of the Hubble constant somewhere in the units, which is typically *also* an input parameter to the simulation.)
However, we cannot guarantee that all input coordinates to selection routines match this index space; in fact, doing so would render utilizing a unit library unnecessary.
As a result, `yt` conducts as regularization of units inside selection routines to ensure that they are the same in the quantities being compared or evaluated.
This requires symbolic math operations in SymPy, which can at times carry with them substantial overhead.
Often, even verifying that units are identical requires expensive operations to be conducted.
To alleviate this, providing some measure of immutable units or index-guaranteed units (and thus enabling the unit comparison process to be elided) would eliminate many expensive operations inside selection routines.
This would likely have the biggest impact on operations like ghost-zone generation, which can be quite expensive.

Another high-impact possible optimization is a conversion of the underlying infrastructure used for grids (@sec:grid_analysis) into a more compact and spatially-aware data structure.
Specifically, utilizing an approach that uses the inherent spatial organization of a patch-based grid dataset (often in the form of an R-tree) can reduce the memory overhead of grid storage.
While work has begun on this, modeling the grid-infrastructure after the "visitor" pattern used in the octree infrastructure, differences between the two (such as irregular sizes, different refinement patterns per level, etc) has presented some difficulties.
However, given a successful implementation, much of the code that provides access to IO and selection (i.e., @sec:chunking) should be able to be moved into optimized, tight-loop routines written in Cython, Rust or other lower-level languages.
Utilizing these data structures will also enable access to bitmap-arrays for caching of data selection results, reducing overall memory usage and improving performance.

**Testing infrastructure**

As dicussed in [[#sec:unit_testing]] and [[#sec:answer_testing]], the `yt` testing infrastructure is prone to time-consuming and memory-intense operations.
Additionally, the bifurcation between those tests executable using nose and those executable using pytest presents a challenge for new contributors.
Future development focused on unifying these two test suites, while also reducing the barriers to entry for executing a full test suite, will promote better test "hygiene" and enable contributors to rely on the underlying testing infrastructure run locally on their machines.

Reducing the requirements for running and examining answer tests, more specifically examining the *results* of answer tests, could take the form of comparisons against hashes, or application of locality-sensitive hashing techniques.
At present, comparing test results to a fixed "gold standard" requires downloading substantial amounts of data to local development workstations -- both the input data and the certified results.

### Quality of Life {#sec:quality_of_life}

Improving the "quality of life" of using `yt` can provide a more comfortable analysis environment and reduce friction between researchers and inquiry.
Since the development of `yt`, the Python language has enabled and expanded support for type "hinting," wherein the types of variables are indicated by the code itself in (non-binding) annotations.
For instance, declaring that the "center" argument to a constructing a sphere selector must be a 3-element tuple or the strings "c" can enable integrated development environments (IDEs) such as VS Code to supply helpful information when a user has incorrectly specified the argument.
This also helps with automated testing, where a properly type-hinted codebase can be examined for violations of these input and return types.
While much of `yt` has been annotated with type hints, there is still a considerable amount of the code base that has not.
Improving the coverage of type hinting could potentially improve the development experience as well as the experience of using `yt`.

As discussed in [[#sec:jupyter_integration]], objects in Python can be provided with special methods that enhance their visual representation in the Jupyter Notebook.
Other libraries, including Pandas, have leveraged this to provide nicer, more informative visual representations of datasets that facilitate at-a-glance understanding of their layout and contents.
At present, `yt` does not have an extensive set of objects that provide user-friendly representations in this way.
A reasonable amount of effort in this area could bring a great deal of additional information and orientation to users, particularly those that are new to the project.
For instance, visual representations of dataset layout, format, size, etc would be appropriate enhancements.

### New Features {#sec:new_features}

New feature development centers on two main areas: connecting with new and emerging ecosystems of libraries and packages, and development of features to support external communities of researchers.
The rapid evolution of toolchains and projects related to machine learning and AI has presented numerous, currently somewhat underexplored, opportunities for integration with `yt`.
Development of high-level and meaningful connections with libraries such as `pytorch-spatial` may unlock functionality and new discovery spaces for researchers seeking to apply AI techniques to simulation data from astronomy and other communities.

Additional high-priority areas of new feature development include deeper connections with _in situ_ analysis and visualization systems such as `libyt`.
`libyt`, while initially created as a `yt`-specific platform to connect MPI-parallel applications to `yt`, provides flexible, Python-centric means of communicating between simulation platforms and Python scripts as well as running Jupyter kernels.
Further developments in `yt` to better support flexible data decomposition and arrangement would benefit `libyt` as it scales to higher processor count and data volume.

Finally, the biggest realm of new feature development that is available to `yt` is the addition of algorithms and methods from different domains outside of astronomy.
While `yt` has been applied outside of astrophysical simulations, there is a wealth of algorithms and techniques that have not been made accessible.
These span tasks such as feature identification, visualization, dimensionality reduction, and other domain-specific techniques.
One of the most important goals we have with `yt` is to provide a platform that enables these domain-specific techniques to be applied more generally and to facilitate direct technology transfer between domains.

